\section{Experimental results}
Generally the first runs without tuning the hyperparameters gave us a broad idea
of the unoptimized solution quality on the used metrics.

Both LDA and ABAE actually had only a small boost in performance by tuning the parameters.

\paragraph{LDA}
At first another processing pipeline was applied for LDA which split sentences and filtered to have nouns only.
The approach was dropped as the loss of information was too high and the generated model was just unusable.

Hyperparameter tuning was therefore done on the two datasets: \textit{NOUN-only} and \textit{sentence}
with final best $K$s being 11 and 7 respectively.
As expected by the decreasing complexity of the dataset the NOUN models perform better in terms of coherence.

Evaluation results are reported in the table and so are the mapped gold aspects.



\paragraph{ABAE}
For ABAE as for LDA was run on the different datasets.
> cosa ho fatto con ABAE prima di tuning

For ABAE around 20 different configurations for hyperparameters were evaluated.
Some of these performed slightly better than others but, overall, there only was a minor gain in topic coherence with
w.r.t the standard configuration that was used during the first attempt.

new scaletta
- at first glance bad results
- finer analyis suggests that some aspects are bad cohernec while others good
- lda
- results first + tune + final
- infer table
- before after tuning results
- abae
- results first + tune + final
- infer table
- 80k better cohrence ->  unbalanced dataset
- on non relevant topics
- before after tuining results

- to finally compare performance of the models a new test set was developed

Results for the project were at first glance underwhelming.
Topic coherence was overall low.
This phenomena might be given by the locality and complexity that derives from the fine-grained aspects to identify.

% Table tuning reults
For ABAE around 20 different configurations for hyperparameters were evaluated.
Some of these performed slightly better than others but, overall, there only was a minor gain in topic coherence with
w.r.t the standard configuration that was used during the first attempt.

Measured values for LDA are a little better but still not in optimal ranges for topic modelling applications.
% todo devi fare coso
For LDA the best processing pipeline in terms of result did not yield the most interpretable model in fact,
the sentence model while performing worse returned a more valuable model.
The identified gold aspects mapped to the identified ones are reported in table. % todo ref table
From the inferred aspects we see that the model has a hard time distinguishing %todo quali
which might be given by the fact that the dataset is not balanced well enough.

The reviews obtained from BGG mostly talk about complexity and components and less about % vbedi se  qualcosa
this unbalance in the data could have led to a bad identification of some required aspects.

ABAE results are reported in table.
The results are less promising in terms of coherence but the found aspects map well to the domain requested
ones.
As expected ABAE is able to better extract underlying associations that allows it to recognize more complex relationships
between potential aspects.

Another possible remark on the results is the processing pipeline while starting directly from the same
seed and sampling the same reviews works differently than the sentence level.

The splitting procedure produces more records from a more similar context thus probably reducing the
quality of the reviews.



Final classification on the dataset are reported in table.
\begin{center}
    \begin{table}
        \begin{tabular}{|c l|}
            \hline
            Component & Model \\ [0.5ex]
            \hline\hline
            GPU       & NVIDIA GeForce RTX3070Ti \\
            \hline
            CPU       & AMD Ryzen 7 5800x        \\
            \hline
            RAM       & 32 GB (2x16GB) DDR4      \\
            \hline
            OS        & Windows 11               \\
            \hline
        \end{tabular}
        \caption{Brief overview of the machine specs}
        \label{specs}

    \end{table}

\end{center}
