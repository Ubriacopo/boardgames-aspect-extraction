\section{Concluding remarks}

The quality of the generated models in performance perspective aren't possibly known without a test set.

By our measures the coherence is good enough.


Some possible issues in the approach were most probably in the processing of the data.
At posterior analysis maybe mapping the numbers all to a single num tag might have hurt the model.
This could mean that the processing pipeline may be too aggressive and degraded the data.


data is enoug but the quality and refinement has to be increased

better identification between various review types
using data from the boardgame is anyways not a feasible approach as these topics should
be cited in any game that has a value in the spectrum (luck is cited both in games with no luck and with)
maybe it was applciable to complexity and take only reviews from games with a very high / low complexity total rating

also bgg is biased towards complex games an the most popular are those with a huge
attention requirment spn

nota che molte reviews fanno riferiemnto alla qualita dei componenti essendo piattaforma di review
utlimatively to really draw any conclusions a test set should be developed but I'd work on
better heuristics to sample significant data exploting some caracteritics of the games.
