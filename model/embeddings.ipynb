{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:13:48.405092Z",
     "start_time": "2024-11-05T17:13:48.403054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "id": "448c9236eeb58cd9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:13:52.319646Z",
     "start_time": "2024-11-05T17:13:52.316783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import embeddings\n",
    "import keras\n",
    "\n",
    "target_file = \"./../data/embeddings-target.model\"\n",
    "corpus_file = \"./../data/corpus.preprocessed.csv\""
   ],
   "id": "49ef8c8f39954eee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vocabulary size and relevant words\n",
    "It is of benefit keeping in the model words with a minimum occurrence as:\n",
    "\n",
    "> Yes, generally, removing very infrequent words when building embeddings models (like Word2Vec or GloVe) is standard practice. Rare words, appearing only a few times in a large corpus, donâ€™t have enough context to generate meaningful embeddings, which can dilute the quality of the learned representations.\n",
    "\n",
    ">However, if your corpus is specialized and every rare word holds unique domain significance, you might choose a lower frequency threshold. But typically, for more general embeddings, filtering out low-frequency words leads to cleaner, more efficient embeddings without much loss in semantic quality.\n",
    "\n",
    "Therefore we keep a minimum frequency threshold of 4 (a small value, usually 5 is a good starter\n",
    "but considering our task is very specialized we do it like this).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "d213b7bbb8ace597"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gensim Word2Vec",
   "id": "c8451a02b548564e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:13:55.342346Z",
     "start_time": "2024-11-05T17:13:54.829114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# TODO: Correctly parametrize: STUDY THE BEST PARAMETERS?\n",
    "emb_model = embeddings.WordEmbedding(10000, 128, target_file=target_file, corpus_file=corpus_file)\n",
    "emb_model.load_model()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:16:11.248858Z",
     "start_time": "2024-11-05T17:16:11.241338Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv.most_similar([\"wingspan\", \"dragon\"])",
   "id": "682b67f574e46c7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wyrmspan', 0.5756521224975586),\n",
       " ('everdell', 0.5665486454963684),\n",
       " ('bird', 0.4801858365535736),\n",
       " ('photosynthesis', 0.47118669748306274),\n",
       " ('viticulture', 0.46620768308639526),\n",
       " ('splendor', 0.46151286363601685),\n",
       " ('scythe', 0.4478973150253296),\n",
       " ('enchantment', 0.44542452692985535),\n",
       " ('bitoku', 0.44291630387306213),\n",
       " ('lords', 0.43769797682762146)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:13:58.687090Z",
     "start_time": "2024-11-05T17:13:58.684114Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"We have a total of words: {len(emb_model.model.wv.key_to_index)}\")",
   "id": "33f01282f3abdeb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of words: 65055\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:13:59.665645Z",
     "start_time": "2024-11-05T17:13:59.661775Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv[0]",
   "id": "28bca156dd38a754",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5029165 ,  2.3624861 ,  2.2939138 , -0.13856713,  0.18078902,\n",
       "       -1.0472201 , -0.56067294,  1.1422796 , -0.49811956, -0.2217462 ,\n",
       "       -1.1803151 ,  0.15797569,  0.31748328,  1.8089781 , -1.3316301 ,\n",
       "       -0.7281514 ,  0.22855756, -0.5512726 , -0.24345373, -0.65646636,\n",
       "        0.4133309 , -0.66919994,  2.3773947 , -0.22472824,  0.13201578,\n",
       "       -0.4081477 ,  0.70655   , -0.14592205, -1.2804753 ,  0.09212334,\n",
       "        0.8463506 , -0.04296552,  1.5006573 ,  0.45384318,  0.30417955,\n",
       "       -0.9204467 ,  1.1173109 ,  0.16690648,  1.4310523 ,  0.5637191 ,\n",
       "        0.4042798 , -0.5923682 , -1.0711784 , -0.7060842 , -0.41067874,\n",
       "        1.0436958 , -0.1179394 ,  1.968886  , -0.47020712,  1.7497754 ,\n",
       "       -0.88896435,  0.47999144,  0.28804758, -1.5539659 ,  1.3963755 ,\n",
       "        0.66093767,  0.43946657,  1.8425758 ,  0.00559428,  0.02443716,\n",
       "       -0.48243096, -0.24423185, -0.896593  ,  0.34101382, -0.45089987,\n",
       "       -0.29079002, -0.88843846, -1.3316691 , -0.20916806,  2.7049892 ,\n",
       "        0.81882274,  0.6475781 ,  2.47842   , -1.3068724 ,  1.6552566 ,\n",
       "       -0.9247927 ,  1.347716  ,  0.45102474, -0.15648043, -0.5708179 ,\n",
       "       -0.20596266,  0.13168575, -1.3147814 ,  0.36671317, -1.787022  ,\n",
       "        1.3844861 ,  0.09831042,  0.97062194, -1.4111079 ,  0.74676806,\n",
       "        0.3822883 ,  0.96068573,  0.09427628, -0.85549885, -0.6474766 ,\n",
       "       -0.74994373, -0.7993263 , -3.0169463 ,  0.65358377,  0.1869138 ,\n",
       "       -0.6071342 , -0.41574234,  0.90917224,  0.6529315 , -0.6410854 ,\n",
       "       -0.6888141 , -0.48223653, -1.4823757 ,  0.5659841 , -0.14537835,\n",
       "       -1.125477  , -0.26668882,  0.15876219, -0.6099996 ,  0.84965926,\n",
       "        0.8498535 , -1.2570179 ,  1.0109869 , -0.5447394 , -0.98723   ,\n",
       "       -1.1441816 ,  0.09049842,  1.5296092 , -0.43746614,  0.06756658,\n",
       "        1.7115911 , -0.26752937,  0.6934554 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:14:01.630554Z",
     "start_time": "2024-11-05T17:14:01.627136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Never resort the words: There is a bug in the Word2Vec model (seems like at least)\n",
    "# https://stackoverflow.com/questions/68451937/gensim-sort-by-descending-frequency-changes-most-similar-results\n",
    "# emb_model.model.wv.sort_by_descending_frequency() # Simpler tests\n",
    "\n",
    "last_index = len(emb_model.model.wv.key_to_index) - 1\n",
    "frequency = emb_model.model.wv.get_vecattr(last_index, 'count')\n",
    "most_frequency = emb_model.model.wv.get_vecattr(0, 'count')\n",
    "\n",
    "print(f\"One of the least frequent word is '{emb_model.model.wv.index_to_key[last_index]}'x({frequency})\")\n",
    "print(f\"The most frequent word is '{emb_model.model.wv.index_to_key[0]}' x({most_frequency})\")"
   ],
   "id": "db1b269d4fbba93e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the least frequent word is 'redundantly'x(4)\n",
      "The most frequent word is 'game' x(2241403)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As the reviews explain the games and give some insight I also have some words that have little to do with the gameplay like Darth Vader that",
   "id": "599c326a73ba3854"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:47:19.921448Z",
     "start_time": "2024-11-05T16:47:19.918365Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv.get_vecattr(\"b]complexity:[/b\", 'count')",
   "id": "9cf54e21e62c9c8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:14:04.077543Z",
     "start_time": "2024-11-05T17:14:04.069075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_model.model.wv.most_similar([\"root\", \"pirate\"] ,[], topn=20)\n",
    "# Root + Pirates = Ahoy as they are manufactured and designed by the same company and often referenced together"
   ],
   "id": "64a019c21ca8d578",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ahoy', 0.5687939524650574),\n",
       " ('marauder', 0.5133765339851379),\n",
       " ('caribbean', 0.5094255208969116),\n",
       " ('swashbuckling', 0.5034607648849487),\n",
       " ('oath', 0.4972757399082184),\n",
       " ('xia', 0.4971827268600464),\n",
       " ('cove', 0.4962853193283081),\n",
       " ('firefly', 0.4872472882270813),\n",
       " ('shark', 0.47869935631752014),\n",
       " ('jamaica', 0.4708572030067444),\n",
       " ('plunder', 0.47066861391067505),\n",
       " ('godfather', 0.46718424558639526),\n",
       " ('merchant', 0.46024590730667114),\n",
       " ('smuggler', 0.45988139510154724),\n",
       " ('blackbeard', 0.45532387495040894),\n",
       " ('gangster', 0.45510271191596985),\n",
       " ('mobster', 0.4525229036808014),\n",
       " ('explorer', 0.44635242223739624),\n",
       " ('colonial', 0.4418928921222687),\n",
       " ('spartacus', 0.4414701461791992)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Should I keep title names?\n",
    "Yes I should. Game names can bring meaning as most frequently games with similar mechanics or general feeling are referenced in reviews. Keeping them in my corpus I make sure to associate a significance to these comparisons. "
   ],
   "id": "21754a345d0624b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f419b84c914341a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:15:23.218988Z",
     "start_time": "2024-11-05T17:15:23.215472Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv[0]",
   "id": "20ead3381bc7bdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5029165 ,  2.3624861 ,  2.2939138 , -0.13856713,  0.18078902,\n",
       "       -1.0472201 , -0.56067294,  1.1422796 , -0.49811956, -0.2217462 ,\n",
       "       -1.1803151 ,  0.15797569,  0.31748328,  1.8089781 , -1.3316301 ,\n",
       "       -0.7281514 ,  0.22855756, -0.5512726 , -0.24345373, -0.65646636,\n",
       "        0.4133309 , -0.66919994,  2.3773947 , -0.22472824,  0.13201578,\n",
       "       -0.4081477 ,  0.70655   , -0.14592205, -1.2804753 ,  0.09212334,\n",
       "        0.8463506 , -0.04296552,  1.5006573 ,  0.45384318,  0.30417955,\n",
       "       -0.9204467 ,  1.1173109 ,  0.16690648,  1.4310523 ,  0.5637191 ,\n",
       "        0.4042798 , -0.5923682 , -1.0711784 , -0.7060842 , -0.41067874,\n",
       "        1.0436958 , -0.1179394 ,  1.968886  , -0.47020712,  1.7497754 ,\n",
       "       -0.88896435,  0.47999144,  0.28804758, -1.5539659 ,  1.3963755 ,\n",
       "        0.66093767,  0.43946657,  1.8425758 ,  0.00559428,  0.02443716,\n",
       "       -0.48243096, -0.24423185, -0.896593  ,  0.34101382, -0.45089987,\n",
       "       -0.29079002, -0.88843846, -1.3316691 , -0.20916806,  2.7049892 ,\n",
       "        0.81882274,  0.6475781 ,  2.47842   , -1.3068724 ,  1.6552566 ,\n",
       "       -0.9247927 ,  1.347716  ,  0.45102474, -0.15648043, -0.5708179 ,\n",
       "       -0.20596266,  0.13168575, -1.3147814 ,  0.36671317, -1.787022  ,\n",
       "        1.3844861 ,  0.09831042,  0.97062194, -1.4111079 ,  0.74676806,\n",
       "        0.3822883 ,  0.96068573,  0.09427628, -0.85549885, -0.6474766 ,\n",
       "       -0.74994373, -0.7993263 , -3.0169463 ,  0.65358377,  0.1869138 ,\n",
       "       -0.6071342 , -0.41574234,  0.90917224,  0.6529315 , -0.6410854 ,\n",
       "       -0.6888141 , -0.48223653, -1.4823757 ,  0.5659841 , -0.14537835,\n",
       "       -1.125477  , -0.26668882,  0.15876219, -0.6099996 ,  0.84965926,\n",
       "        0.8498535 , -1.2570179 ,  1.0109869 , -0.5447394 , -0.98723   ,\n",
       "       -1.1441816 ,  0.09049842,  1.5296092 , -0.43746614,  0.06756658,\n",
       "        1.7115911 , -0.26752937,  0.6934554 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T17:15:07.787727Z",
     "start_time": "2024-11-05T17:15:07.729760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "layer = emb_model.build_embedding_layer()\n",
    "layer(torch.tensor([0]))"
   ],
   "id": "e1df39ea47f31b52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5029,  2.3625,  2.2939, -0.1386,  0.1808, -1.0472, -0.5607,  1.1423,\n",
       "         -0.4981, -0.2217, -1.1803,  0.1580,  0.3175,  1.8090, -1.3316, -0.7282,\n",
       "          0.2286, -0.5513, -0.2435, -0.6565,  0.4133, -0.6692,  2.3774, -0.2247,\n",
       "          0.1320, -0.4081,  0.7066, -0.1459, -1.2805,  0.0921,  0.8464, -0.0430,\n",
       "          1.5007,  0.4538,  0.3042, -0.9204,  1.1173,  0.1669,  1.4311,  0.5637,\n",
       "          0.4043, -0.5924, -1.0712, -0.7061, -0.4107,  1.0437, -0.1179,  1.9689,\n",
       "         -0.4702,  1.7498, -0.8890,  0.4800,  0.2880, -1.5540,  1.3964,  0.6609,\n",
       "          0.4395,  1.8426,  0.0056,  0.0244, -0.4824, -0.2442, -0.8966,  0.3410,\n",
       "         -0.4509, -0.2908, -0.8884, -1.3317, -0.2092,  2.7050,  0.8188,  0.6476,\n",
       "          2.4784, -1.3069,  1.6553, -0.9248,  1.3477,  0.4510, -0.1565, -0.5708,\n",
       "         -0.2060,  0.1317, -1.3148,  0.3667, -1.7870,  1.3845,  0.0983,  0.9706,\n",
       "         -1.4111,  0.7468,  0.3823,  0.9607,  0.0943, -0.8555, -0.6475, -0.7499,\n",
       "         -0.7993, -3.0169,  0.6536,  0.1869, -0.6071, -0.4157,  0.9092,  0.6529,\n",
       "         -0.6411, -0.6888, -0.4822, -1.4824,  0.5660, -0.1454, -1.1255, -0.2667,\n",
       "          0.1588, -0.6100,  0.8497,  0.8499, -1.2570,  1.0110, -0.5447, -0.9872,\n",
       "         -1.1442,  0.0905,  1.5296, -0.4375,  0.0676,  1.7116, -0.2675,  0.6935]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The embedding layer is loaded correctly with the weights I got from Word2Vec",
   "id": "5f1a93fbb9e94ca3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# My Word2Vec Implementation\n",
    "But is it worth it?"
   ],
   "id": "910aa77d32565eee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "my_word2vec = embeddings.MyWord2Vec(25000, 128, \"\")",
   "id": "ca5580db9a5a2ca1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-24T16:09:54.833888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = dataset.CommentDataset(corpus_file)\n",
    "\n",
    "training_dataloader = DataLoader(ds, batch_size=32, shuffle=True, collate_fn=lambda x: x)\n",
    "# TODO: Convert to numbers (indices of a vocabulary) as model doesnt do that by itself\n",
    "my_word2vec.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "my_word2vec.fit(training_dataloader, epochs=10)"
   ],
   "id": "5c67ca49134e2384",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1939904 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60bb78b335ee45f9b7696b0b33f611a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T15:36:31.311477Z",
     "start_time": "2024-10-24T15:36:31.295776Z"
    }
   },
   "cell_type": "code",
   "source": "ds.dataset.itertuples()",
   "id": "43e52beeb273f413",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mds\u001B[49m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mitertuples()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18338693f5d6b73e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
