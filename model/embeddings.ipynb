{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:44:56.856060Z",
     "start_time": "2024-11-05T16:44:56.853952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "id": "448c9236eeb58cd9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:44:57.027293Z",
     "start_time": "2024-11-05T16:44:57.024731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import embeddings\n",
    "import keras\n",
    "\n",
    "target_file = \"./../data/embeddings-target.model\"\n",
    "corpus_file = \"./../data/corpus.preprocessed.csv\""
   ],
   "id": "49ef8c8f39954eee",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vocabulary size and relevant words\n",
    "It is of benefit keeping in the model words with a minimum occurrence as:\n",
    "\n",
    "> Yes, generally, removing very infrequent words when building embeddings models (like Word2Vec or GloVe) is standard practice. Rare words, appearing only a few times in a large corpus, donâ€™t have enough context to generate meaningful embeddings, which can dilute the quality of the learned representations.\n",
    "\n",
    ">However, if your corpus is specialized and every rare word holds unique domain significance, you might choose a lower frequency threshold. But typically, for more general embeddings, filtering out low-frequency words leads to cleaner, more efficient embeddings without much loss in semantic quality.\n",
    "\n",
    "Therefore we keep a minimum frequency threshold of 4 (a small value, usually 5 is a good starter\n",
    "but considering our task is very specialized we do it like this).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "d213b7bbb8ace597"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gensim Word2Vec",
   "id": "c8451a02b548564e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:46:57.969296Z",
     "start_time": "2024-11-05T16:44:59.531118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# TODO: Correctly parametrize: STUDY THE BEST PARAMETERS?\n",
    "emb_model = embeddings.WordEmbedding(7200, 128, target_file=target_file, corpus_file=corpus_file)\n",
    "emb_model.load_model()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1939904 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3784ba8c453a41e380d20ca6fe12d208"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:47:01.566755Z",
     "start_time": "2024-11-05T16:47:01.550427Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv.most_similar(\"agency\")",
   "id": "682b67f574e46c7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('interaction', 0.6038694977760315),\n",
       " ('randomness', 0.5666834115982056),\n",
       " ('freedom', 0.5644192695617676),\n",
       " ('choice', 0.5464454889297485),\n",
       " ('interactivity', 0.5412836074829102),\n",
       " ('tension', 0.524446427822113),\n",
       " ('option', 0.5115113258361816),\n",
       " ('variance', 0.5098146796226501),\n",
       " ('uncertainty', 0.5078426599502563),\n",
       " ('drama', 0.49698948860168457)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:47:04.535992Z",
     "start_time": "2024-11-05T16:47:04.532697Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"We have a total of words: {len(emb_model.model.wv.key_to_index)}\")",
   "id": "33f01282f3abdeb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of words: 65055\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:47:07.280172Z",
     "start_time": "2024-11-05T16:47:07.274408Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv[0]",
   "id": "28bca156dd38a754",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5029165 ,  2.3624861 ,  2.2939138 , -0.13856713,  0.18078902,\n",
       "       -1.0472201 , -0.56067294,  1.1422796 , -0.49811956, -0.2217462 ,\n",
       "       -1.1803151 ,  0.15797569,  0.31748328,  1.8089781 , -1.3316301 ,\n",
       "       -0.7281514 ,  0.22855756, -0.5512726 , -0.24345373, -0.65646636,\n",
       "        0.4133309 , -0.66919994,  2.3773947 , -0.22472824,  0.13201578,\n",
       "       -0.4081477 ,  0.70655   , -0.14592205, -1.2804753 ,  0.09212334,\n",
       "        0.8463506 , -0.04296552,  1.5006573 ,  0.45384318,  0.30417955,\n",
       "       -0.9204467 ,  1.1173109 ,  0.16690648,  1.4310523 ,  0.5637191 ,\n",
       "        0.4042798 , -0.5923682 , -1.0711784 , -0.7060842 , -0.41067874,\n",
       "        1.0436958 , -0.1179394 ,  1.968886  , -0.47020712,  1.7497754 ,\n",
       "       -0.88896435,  0.47999144,  0.28804758, -1.5539659 ,  1.3963755 ,\n",
       "        0.66093767,  0.43946657,  1.8425758 ,  0.00559428,  0.02443716,\n",
       "       -0.48243096, -0.24423185, -0.896593  ,  0.34101382, -0.45089987,\n",
       "       -0.29079002, -0.88843846, -1.3316691 , -0.20916806,  2.7049892 ,\n",
       "        0.81882274,  0.6475781 ,  2.47842   , -1.3068724 ,  1.6552566 ,\n",
       "       -0.9247927 ,  1.347716  ,  0.45102474, -0.15648043, -0.5708179 ,\n",
       "       -0.20596266,  0.13168575, -1.3147814 ,  0.36671317, -1.787022  ,\n",
       "        1.3844861 ,  0.09831042,  0.97062194, -1.4111079 ,  0.74676806,\n",
       "        0.3822883 ,  0.96068573,  0.09427628, -0.85549885, -0.6474766 ,\n",
       "       -0.74994373, -0.7993263 , -3.0169463 ,  0.65358377,  0.1869138 ,\n",
       "       -0.6071342 , -0.41574234,  0.90917224,  0.6529315 , -0.6410854 ,\n",
       "       -0.6888141 , -0.48223653, -1.4823757 ,  0.5659841 , -0.14537835,\n",
       "       -1.125477  , -0.26668882,  0.15876219, -0.6099996 ,  0.84965926,\n",
       "        0.8498535 , -1.2570179 ,  1.0109869 , -0.5447394 , -0.98723   ,\n",
       "       -1.1441816 ,  0.09049842,  1.5296092 , -0.43746614,  0.06756658,\n",
       "        1.7115911 , -0.26752937,  0.6934554 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:47:15.156275Z",
     "start_time": "2024-11-05T16:47:15.151694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Never resort the words: There is a bug in the Word2Vec model (seems like at least)\n",
    "# https://stackoverflow.com/questions/68451937/gensim-sort-by-descending-frequency-changes-most-similar-results\n",
    "# emb_model.model.wv.sort_by_descending_frequency() # Simpler tests\n",
    "\n",
    "last_index = len(emb_model.model.wv.key_to_index) - 1\n",
    "frequency = emb_model.model.wv.get_vecattr(last_index, 'count')\n",
    "most_frequency = emb_model.model.wv.get_vecattr(0, 'count')\n",
    "\n",
    "print(f\"One of the least frequent word is '{emb_model.model.wv.index_to_key[last_index]}'x({frequency})\")\n",
    "print(f\"The most frequent word is '{emb_model.model.wv.index_to_key[0]}' x({most_frequency})\")"
   ],
   "id": "db1b269d4fbba93e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the least frequent word is 'redundantly'x(4)\n",
      "The most frequent word is 'game' x(2241403)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As the reviews explain the games and give some insight I also have some words that have little to do with the gameplay like Darth Vader that",
   "id": "599c326a73ba3854"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:47:19.921448Z",
     "start_time": "2024-11-05T16:47:19.918365Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv.get_vecattr(\"b]complexity:[/b\", 'count')",
   "id": "9cf54e21e62c9c8a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T16:53:29.654894Z",
     "start_time": "2024-11-05T16:53:29.648804Z"
    }
   },
   "cell_type": "code",
   "source": "emb_model.model.wv.most_similar([\"eagle\", \"vagabond\"], [\"root\"], topn=20)",
   "id": "64a019c21ca8d578",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fakir', 0.6225370764732361),\n",
       " ('buffalo', 0.596053421497345),\n",
       " ('dlp', 0.5904033780097961),\n",
       " ('pegasus', 0.5874199867248535),\n",
       " ('picket', 0.5857054591178894),\n",
       " ('inklusive', 0.5801913738250732),\n",
       " ('cholm', 0.5785760879516602),\n",
       " ('fred', 0.5751404166221619),\n",
       " ('krystallium', 0.5749009251594543),\n",
       " ('xo', 0.5703404545783997),\n",
       " ('fuego', 0.5692890286445618),\n",
       " ('spearman', 0.5690612196922302),\n",
       " ('preorder', 0.5670077800750732),\n",
       " ('talon', 0.5667649507522583),\n",
       " ('12/2023', 0.5640817284584045),\n",
       " ('moldy', 0.5608451962471008),\n",
       " ('ortskarten', 0.5601773858070374),\n",
       " ('claude', 0.5599327683448792),\n",
       " ('saxophone', 0.5594304800033569),\n",
       " ('sergeant', 0.5591108798980713)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Should I keep title names?\n",
    "Yes I should. Game names can bring meaning as most frequently games with similar mechanics or general feeling are referenced in reviews. Keeping them in my corpus I make sure to associate a significance to these comparisons. "
   ],
   "id": "21754a345d0624b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# My Word2Vec Implementation\n",
    "But is it worth it?"
   ],
   "id": "910aa77d32565eee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "my_word2vec = embeddings.MyWord2Vec(25000, 128, \"\")",
   "id": "ca5580db9a5a2ca1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-24T16:09:54.833888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = dataset.CommentDataset(corpus_file)\n",
    "\n",
    "training_dataloader = DataLoader(ds, batch_size=32, shuffle=True, collate_fn=lambda x: x)\n",
    "# TODO: Convert to numbers (indices of a vocabulary) as model doesnt do that by itself\n",
    "my_word2vec.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "my_word2vec.fit(training_dataloader, epochs=10)"
   ],
   "id": "5c67ca49134e2384",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1939904 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60bb78b335ee45f9b7696b0b33f611a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T15:36:31.311477Z",
     "start_time": "2024-10-24T15:36:31.295776Z"
    }
   },
   "cell_type": "code",
   "source": "ds.dataset.itertuples()",
   "id": "43e52beeb273f413",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mds\u001B[49m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mitertuples()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ds' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "18338693f5d6b73e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
