{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:49:43.534860Z",
     "start_time": "2024-11-08T17:49:43.532925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "id": "40757908fc8c86f8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Regularization\n",
    ">We hope to learn vector representations of the most representative aspects for a review dataset.\n",
    "However, the aspect embedding matrix T may suffer from redundancy problems during training. [...] \n",
    "> The regularization term encourages orthogonality among the rows of the aspect embedding matrix T and penalizes redundancy between different aspect vectors\n",
    "> ~ Ruidan\n",
    "\n",
    "We use an Orthogonal Regulizer definition of the method can be found here: https://paperswithcode.com/method/orthogonal-regularization. <br/>\n",
    "For the code we use the default implementation provided by Keras (https://keras.io/api/layers/regularizers/)"
   ],
   "id": "a67bb8c9beca9d72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T15:16:29.139543Z",
     "start_time": "2024-11-08T15:16:29.136554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import ops as K\n",
    "from keras import backend as B\n",
    "\n",
    "\n",
    "def ortho_reg(W):\n",
    "    ### Orthogonal regularization for aspect embedding matrix by Ruidan     ###\n",
    "    w_n = W / K.cast(B.epsilon() + K.sqrt(K.sum(K.square(W), axis=-1, keepdims=True)), B.floatx())\n",
    "    # sum(w_n * w_n_t - I) * factor\n",
    "    return K.sum(K.square(K.dot(w_n, K.transpose(w_n)) - K.eye(w_n.shape[0])))"
   ],
   "id": "737f112c30776188",
   "outputs": [],
   "execution_count": 219
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4910a79bdbc2a717"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO: Sarebbe da vedere come l'implementazione di Ruidan sia diversa da quella di Keras. Se effettivamente questa importa. A guardare i numeri sono effettivamente diversi!",
   "id": "62ccfe3be9499ddc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:49:45.444028Z",
     "start_time": "2024-11-08T17:49:45.442142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_file = \"./../data/corpus.preprocessed.csv\"  # It's this\n",
    "# TODO GET MAXLEN FROM EMBEDDINGS DATASET (Which is input shape)\n",
    "input_shape = (256,)"
   ],
   "id": "d70b9004cc53f3fc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Setup",
   "id": "52d8be30943c43e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:49:50.422158Z",
     "start_time": "2024-11-08T17:49:46.074305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import model.embeddings as embeddings\n",
    "\n",
    "embeddings_model = embeddings.WordEmbedding(\n",
    "    embeddings.LoadCorpusUtility(), max_vocab_size=10000, embedding_size=128,\n",
    "    target_model_file=\"./../data/word-embeddings.model\", corpus_file=corpus_file\n",
    ")\n",
    "aspect_embeddings_model = embeddings.AspectEmbedding(\n",
    "    aspect_size=4, embedding_size=128, base_embeddings=embeddings_model,\n",
    "    target_model_file=\"./../data/aspects-embedding.model\"\n",
    ")"
   ],
   "id": "eb3470aaa495a5cd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacopo/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/jacopo/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:49:50.445650Z",
     "start_time": "2024-11-08T17:49:50.422923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings_model.load_model()\n",
    "aspect_embeddings_model.load_model()"
   ],
   "id": "bfe27fa3b412d9ed",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T17:49:51.277701Z",
     "start_time": "2024-11-08T17:49:51.050155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model.model import ABAEModelGenerator\n",
    "\n",
    "generator = ABAEModelGenerator(input_shape, embeddings_model, aspect_embeddings_model)\n",
    "model = generator.make_model()"
   ],
   "id": "ea223a0ab512537",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling WeightedSumLayer.call().\n\n\u001B[1mCould not automatically infer the output shape / dtype of 'weighted_sum_layer' (of type WeightedSumLayer). Either the `WeightedSumLayer.call()` method is incorrect, or you need to implement the `WeightedSumLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\ntoo many values to unpack (expected 2)\u001B[0m\n\nArguments received by WeightedSumLayer.call():\n  • args=('<KerasTensor shape=(None, 256, 128), dtype=float32, sparse=False, name=keras_tensor>', '<KerasTensor shape=(None, 128), dtype=float32, sparse=False, name=keras_tensor_3>')\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ABAEModelGenerator\n\u001B[1;32m      3\u001B[0m generator \u001B[38;5;241m=\u001B[39m ABAEModelGenerator(input_shape, embeddings_model, aspect_embeddings_model)\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/model/model.py:18\u001B[0m, in \u001B[0;36mModelGenerator.make_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_model\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 18\u001B[0m     inputs, outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_layers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39minputs, outputs\u001B[38;5;241m=\u001B[39moutputs)\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/model/model.py:61\u001B[0m, in \u001B[0;36mABAEModelGenerator.make_layers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m attention_weights \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mMultiHeadAttention(num_heads\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, key_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m)(\n\u001B[1;32m     58\u001B[0m     query\u001B[38;5;241m=\u001B[39mavg, key\u001B[38;5;241m=\u001B[39membeddings, value\u001B[38;5;241m=\u001B[39membeddings\n\u001B[1;32m     59\u001B[0m )\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# attention_weights = keras.layers.MultiHeadAttention(num_heads=4, key_dim=32)([avg, embeddings])\u001B[39;00m\n\u001B[0;32m---> 61\u001B[0m weighted_positive \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mWeightedSumLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_weights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Negative representation for negative feedback\u001B[39;00m\n\u001B[1;32m     64\u001B[0m negative_input_layer \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_shape, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative_input\u001B[39m\u001B[38;5;124m'\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/model/layer.py:35\u001B[0m, in \u001B[0;36mWeightedSumLayer.call\u001B[0;34m(self, input_data, mask)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_data: \u001B[38;5;28mlist\u001B[39m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 35\u001B[0m     x, w \u001B[38;5;241m=\u001B[39m input_data\n\u001B[1;32m     36\u001B[0m     w \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mexpand_dims(w, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m keras\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39msum(x \u001B[38;5;241m*\u001B[39m w, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling WeightedSumLayer.call().\n\n\u001B[1mCould not automatically infer the output shape / dtype of 'weighted_sum_layer' (of type WeightedSumLayer). Either the `WeightedSumLayer.call()` method is incorrect, or you need to implement the `WeightedSumLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\ntoo many values to unpack (expected 2)\u001B[0m\n\nArguments received by WeightedSumLayer.call():\n  • args=('<KerasTensor shape=(None, 256, 128), dtype=float32, sparse=False, name=keras_tensor>', '<KerasTensor shape=(None, 128), dtype=float32, sparse=False, name=keras_tensor_3>')\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load the data",
   "id": "89216349e5c6f335"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58801e13d855b211"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "3adc8a873389afd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5786a02b4f9821"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
