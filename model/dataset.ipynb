{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T15:43:14.261702Z",
     "start_time": "2024-10-17T15:43:14.259477Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Generation\n",
    "Our dataset is a corpus of reviews scrapped from the BGG API. <br /> \n",
    "In order to download the comments we make use of the ```bgg_corpus_service.py``` content."
   ],
   "id": "dbc6de67c270e005"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "BGG Does not directly provide a way to list all the games it has in archive therefore we used a dump created by the community (2024-08-18).",
   "id": "a4b9c9e4a84a36cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# /resources/2024-08-18.csv",
   "id": "f6c2596f30f3030c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "663364532ac221d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Custom Dataloaders Definitions\n",
    "To train the model we require a way to get elements of our dataset. I designed 3 classes for this:"
   ],
   "id": "c3a49e3e02abe587"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T15:43:22.250017Z",
     "start_time": "2024-10-17T15:43:14.262522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dataset\n",
    "\n",
    "lazy = dataset.LazyCommentDataset(\"../data/corpus.preprocessed.csv\")\n",
    "dt = dataset.CommentDataset(\"../data/corpus.preprocessed.csv\")"
   ],
   "id": "3f6f491309333bda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index        15522432\n",
      "comments    379211268\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1940304 entries, 0 to 1940425\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   comments  object\n",
      "dtypes: object(1)\n",
      "memory usage: 376.4 MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Without preprocessing on dataset: 379211268 <br />\n",
    "If the dataset is processed already: 677671688 (Twice the size) <br />"
   ],
   "id": "88fd8fecaff7c6c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T15:43:22.253055Z",
     "start_time": "2024-10-17T15:43:22.250891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dt_dataloader = DataLoader(dt, batch_size=32, shuffle=True, collate_fn=lambda x: x)\n",
    "lazy_dataloader = DataLoader(lazy, batch_size=32, shuffle=True, collate_fn=lambda x: x)"
   ],
   "id": "19a5bcbd8b3ab0ca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T15:43:22.255913Z",
     "start_time": "2024-10-17T15:43:22.253612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt_iterator = iter(dt_dataloader)\n",
    "lazy_iterator = iter(lazy_dataloader)"
   ],
   "id": "56b334fbcf82492b",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
