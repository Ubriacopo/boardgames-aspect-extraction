{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO pulisci questo file\n",
    "# https://arxiv.org/pdf/1803.09820\n",
    "# https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/"
   ],
   "id": "b94d8a5d18957ca5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T19:28:19.315204Z",
     "start_time": "2025-01-18T19:28:19.311933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "id": "40757908fc8c86f8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hands on first attempt:\n",
   "id": "6f0d71f28a41b371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": " # Without any hp tuning we just try and see how it goes.",
   "id": "ae6aa4303bfa4f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Regularization\n",
    ">We hope to learn vector representations of the most representative aspects for a review dataset.\n",
    "However, the aspect embedding matrix T may suffer from redundancy problems during training. [...] \n",
    "> The regularization term encourages orthogonality among the rows of the aspect embedding matrix T and penalizes redundancy between different aspect vectors\n",
    "> ~ Ruidan\n",
    "\n",
    "We use an Orthogonal Regulizer definition of the method can be found here: https://paperswithcode.com/method/orthogonal-regularization. <br/>\n",
    "For the code we use the default implementation provided by Keras (https://keras.io/api/layers/regularizers/)"
   ],
   "id": "a67bb8c9beca9d72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aspect Embedding Size\n",
    "The aspect embedding size is what will be inferring aspects. It is closest to representative words (?). <br />\n",
    "We have to identify 7 actual aspects (luck, bookkeeping, downtime...) but that does not mean our matrix should be limited to rows only! What size to search is a good question and should be studied (Which I may be doing later). \n",
    "\n",
    "For the first try we setup the aspect_size:\n",
    ">The optimal number of rows is problem-dependent, so it’s crucial to: <br/>\n",
    "> Start with a heuristic: Begin with 2–3x the number of aspects."
   ],
   "id": "c4957d1b3784a455"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For **aspect extraction**, which involves identifying key aspects or topics in text, the best early stopping method depends on your approach:\n",
    "\n",
    "### 1. Embedding-based Methods (e.g., Clustering Embeddings)\n",
    "- **Silhouette Score**: Measure the separation and compactness of clusters. Stop when the score stabilizes.\n",
    "- **Inertia/Distortion**: Track the sum of squared distances within clusters and stop when improvement flattens.\n",
    "- **Centroid Movement**: Stop when the change in cluster centroids across iterations is minimal.\n",
    "\n",
    "### 2. Topic Modeling (e.g., LDA)\n",
    "- **Perplexity**: Monitor the perplexity on a held-out dataset and stop when it stops decreasing significantly.\n",
    "- **Coherence Score**: Measure the semantic consistency of extracted topics and stop when it stabilizes.\n",
    "\n",
    "### 3. Autoencoder-based Aspect Extraction\n",
    "- **Reconstruction Loss**: Stop training when the validation reconstruction error no longer improves.\n",
    "\n",
    "### 4. Qualitative Evaluation (if feasible)\n",
    "- Periodically inspect extracted aspects for meaningfulness and diversity to decide on stopping.\n",
    "\n",
    "For **aspect extraction**, combining an automated metric (like coherence score or silhouette score) with manual inspection often yields the best results.\n"
   ],
   "id": "712e1c6f9ae346b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters Tuning\n",
    "To tune our parameters we use a filtered version of the 50k ds. <br>\n",
    "We filter out rows that can be found on the 200k ds."
   ],
   "id": "2fc847f0fc2c3597"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This is based on the idea that our dataset are generated with different seeds else it won't work\n",
    "large = pd.read_csv(\"../output/dataset/pre-processed/200k.preprocessed.csv\")\n",
    "small = pd.read_csv(\"../output/dataset/pre-processed/100k.preprocessed.csv\")\n",
    "tuning_set = small[~small[\"comments\"].isin(large[\"comments\"])]\n",
    "\n",
    "tuning_set.to_csv(\"../output/dataset/pre-processed/tuning.preprocessed.csv\", index=False)"
   ],
   "id": "a2fe0760d85289df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> The main goal of ABAE is to extract interpretable and meaningful aspects, which makes coherence the more aligned metric. Reconstruction error might help guide training but doesn’t guarantee that the extracted aspects are semantically useful.",
   "id": "cd4dfe8c62445d96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T19:30:32.142498Z",
     "start_time": "2025-01-18T19:28:23.295132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from core.evaluation import normalize, get_aspect_top_k_words, coherence_per_aspect\n",
    "from core.hp_tuning import ABAERandomHyperparametersSelectionWrapper\n",
    "from core.train import AbaeModelManager, AbaeModelConfiguration\n",
    "from core.dataset import PositiveNegativeCommentGeneratorDataset\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "print(\"Starting process\")\n",
    "hp_wrapper = ABAERandomHyperparametersSelectionWrapper.create()\n",
    "configurations = 15  # We try 15 different configurations\n",
    "\n",
    "seen_configurations = set()\n",
    "seen_configurations.add(\n",
    "    frozenset({\n",
    "                  # I failed on this\n",
    "                  'aspect_size': 18,\n",
    "                  'embedding_size': 300,\n",
    "                  'epochs': 15,\n",
    "                  'batch_size': 64,\n",
    "                  'learning_rate': 0.01778279410038923,\n",
    "                  'decay_rate': 0.9450000000000001,\n",
    "                  'momentum': 0.97,\n",
    "                  'negative_sample_size': 15\n",
    "              }.items()))\n",
    "\n",
    "seen_configurations.add(\n",
    "    frozenset({\n",
    "                  'aspect_size': 18,\n",
    "                  'batch_size': 64,\n",
    "                  'decay_rate': 0.9450000000000001,\n",
    "                  'embedding_size': 300,\n",
    "                  'epochs': 15,\n",
    "                  'learning_rate': 0.01778279410038923,\n",
    "                  'momentum': 0.97,\n",
    "                  'negative_sample_size': 15\n",
    "              }.items()))\n",
    "\n",
    "seen_configurations.add(\n",
    "    frozenset({\n",
    "                  \"aspect_size\": 16,\n",
    "                  \"embedding_size\": 200,\n",
    "                  \"epochs\": 12,\n",
    "                  \"batch_size\": 64,\n",
    "                  \"learning_rate\": 0.0031622776601683794,\n",
    "                  \"decay_rate\": 0.93,\n",
    "                  \"momentum\": 0.9400000000000001,\n",
    "                  \"negative_sample_size\": 15\n",
    "              }.items())\n",
    ")\n",
    "\n",
    "scores = list()\n",
    "\n",
    "corpus_file = \"../output/dataset/pre-processed/tuning.preprocessed.csv\"\n",
    "\n",
    "for i in range(configurations):\n",
    "    uuid = uuid4()\n",
    "    parameters = next(hp_wrapper)\n",
    "\n",
    "    while seen_configurations.__contains__(frozenset(parameters.items())):\n",
    "        print(f\"We already worked on configuration: {parameters}\")\n",
    "        parameters = next(hp_wrapper)  # In case we fetch the same config more than once.\n",
    "\n",
    "    print(f\"Working on configuration: {parameters}\")\n",
    "    seen_configurations.add(frozenset(parameters.items()))\n",
    "\n",
    "    run_scores = []\n",
    "    run_sores_per_aspect = []\n",
    "\n",
    "    # One epoch takes approx {~128s} on my machine. Worst case (15 epochs) we have a total of {~32m} x 3.\n",
    "    # At most a model takes 1.5 h to complete. It's a bit much!\n",
    "    for runs in range(3):\n",
    "        # Train process\n",
    "\n",
    "        ## You should keep the same embeddings model for each iteration of the same configuration.\n",
    "        # This ensures that the comparison focuses solely on the impact of the hyperparameter settings\n",
    "        # and avoids introducing additional variability from reinitializing the embeddings.\n",
    "        #\n",
    "        # Consistency in the embeddings makes your evaluation of robustness more reliable.\n",
    "        config = AbaeModelConfiguration(corpus_file=corpus_file, model_name=f\"tuning_{uuid}\", **parameters)\n",
    "        manager = AbaeModelManager(config)\n",
    "\n",
    "        vocab = manager.embedding_model.vocabulary()\n",
    "        # The dataset generation depends on the embedding model\n",
    "        ds = PositiveNegativeCommentGeneratorDataset(\n",
    "            config.corpus_file, vocabulary=vocab, negative_size=config.negative_sample_size\n",
    "        )\n",
    "\n",
    "        # Ensure that the same splits are always created.\n",
    "        # We use more point to test just to speed up.\n",
    "        # We are not accounting the possibility that the data might be unbalanced.\n",
    "        train, validation = torch.utils.data.random_split(ds, [0.75, 0.25], generator=torch.Generator().manual_seed(42))\n",
    "        print(\"Training process in progress..\")\n",
    "        results, iteration_model = manager.run_train_process(train)\n",
    "        # Coherence is not good enough. We also track reconstruction error.\n",
    "        test_dataloader = DataLoader(dataset=validation, batch_size=config.batch_size, shuffle=True)\n",
    "        evaluation_results = iteration_model.evalutate(test_dataloader)\n",
    "\n",
    "        print(results)\n",
    "        # Evaluate the model\n",
    "        # We evaluate on the relative coherence between topics.\n",
    "        print(\"Evaluating model\")\n",
    "        word_emb = normalize(iteration_model.get_layer('word_embedding').weights[0].value.data)\n",
    "\n",
    "        aspect_embeddings = normalize(iteration_model.get_layer('aspect_embedding').w)\n",
    "        print(f\"Word embeddings shape: {word_emb.shape}\")\n",
    "        inv_vocab = manager.embedding_model.model.wv.index_to_key\n",
    "\n",
    "        aspects_top_k_words = [get_aspect_top_k_words(a, word_emb, inv_vocab, top_k=50) for a in aspect_embeddings]\n",
    "\n",
    "        aspect_words = [[word[0] for word in aspect] for aspect in aspects_top_k_words]\n",
    "\n",
    "        coherence, coherence_model = coherence_per_aspect(aspect_words, ds.text_ds.loc[validation.indices], 10)\n",
    "\n",
    "        run_scores.append(coherence_model.get_coherence())\n",
    "        run_sores_per_aspect.append(coherence)\n",
    "\n",
    "        if runs == 2:\n",
    "            json.dump(dict(scores=run_scores, run_sores_per_aspect=run_sores_per_aspect, params=parameters),\n",
    "                      open(manager.output_path + \"/run_results.json\", \"w\"))\n",
    "    scores.append(dict(coherence=np.mean(run_scores), parameters=parameters))\n",
    "\n",
    "# End done.\n",
    "print(scores)"
   ],
   "id": "acbaf8a817277d6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting process\n",
      "We already worked on configuration: {'aspect_size': 18, 'embedding_size': 300, 'epochs': 15, 'batch_size': 64, 'learning_rate': 0.01778279410038923, 'decay_rate': 0.9450000000000001, 'momentum': 0.97, 'negative_sample_size': 15}\n",
      "We already worked on configuration: {'aspect_size': 16, 'embedding_size': 200, 'epochs': 12, 'batch_size': 64, 'learning_rate': 0.0031622776601683794, 'decay_rate': 0.93, 'momentum': 0.9400000000000001, 'negative_sample_size': 15}\n",
      "Working on configuration: {'aspect_size': 20, 'embedding_size': 200, 'epochs': 12, 'batch_size': 128, 'learning_rate': 0.1, 'decay_rate': 0.975, 'momentum': 0.98, 'negative_sample_size': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/83855 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2028c100269b4cb682a14d46b2357bf0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/83855 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a41d24ba989b437ca6883ab57156c5d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 119085 words, keeping 4857 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 239721 words, keeping 5207 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 359702 words, keeping 5263 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 477300 words, keeping 5274 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 598508 words, keeping 5279 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 721182 words, keeping 5279 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 838524 words, keeping 5279 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 957006 words, keeping 5280 word types\n",
      "INFO:gensim.models.word2vec:collected 5280 word types from a corpus of 1003308 raw words and 83855 sentences\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Word2Vec\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 5280 unique words (100.00% of original 5280, drops 0)', 'datetime': '2025-01-18T20:28:30.681652', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 1003308 word corpus (100.00% of original 1003308, drops 0)', 'datetime': '2025-01-18T20:28:30.682651', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 5280 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 46 most-common words\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 802044.7673554413 word corpus (79.9%% of prior 1003308)', 'datetime': '2025-01-18T20:28:30.702659', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'prepare_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceptions must derive from BaseException\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:estimated required memory for 5280 words and 200 dimensions: 11088000 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-18T20:28:30.734652', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'build_vocab'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 8 workers on 5280 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-01-18T20:28:30.734652', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 101 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH 0: training on 1003308 raw words (802149 effective words) took 0.4s, 2019937 effective words/s\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 101 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 14 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH 1: training on 1003308 raw words (801856 effective words) took 0.4s, 1941234 effective words/s\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 101 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH 2: training on 1003308 raw words (802052 effective words) took 0.4s, 1799239 effective words/s\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 101 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH 3: training on 1003308 raw words (801988 effective words) took 0.4s, 1783713 effective words/s\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 101 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 12 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 13 jobs\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH 4: training on 1003308 raw words (802096 effective words) took 0.5s, 1763015 effective words/s\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 5016540 raw words (4010141 effective words) took 2.2s, 1815949 effective words/s', 'datetime': '2025-01-18T20:28:32.943429', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'train'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=5280, vector_size=200, alpha=0.025>', 'datetime': '2025-01-18T20:28:32.943429', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname_or_handle': './output/tuning_c77dd7ea-9c6e-40d6-82c5-631544293834/embeddings.keras', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-01-18T20:28:32.944428', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'saving'}\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': './output/tuning_c77dd7ea-9c6e-40d6-82c5-631544293834/embeddings.keras', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:saved ./output/tuning_c77dd7ea-9c6e-40d6-82c5-631544293834/embeddings.keras\n",
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Das System kann die angegebene Datei nicht finden\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceptions must derive from BaseException\n",
      "Loading dataset from file: ../output/dataset/pre-processed/tuning.preprocessed.csv\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/83855 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f995d6a280441bfac701f4bda901b80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "Max sequence length is:  274 . The limit is set to 80 tokens.\n",
      "We loose information on 54 points.This is 0.06439687555900066% of the dataset.\n",
      "Padding sequences to length (80).\n",
      "Training process in progress..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 5 to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 - 116s - 237ms/step - loss: 13.2846 - max_margin_loss: 13.2328\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'evalutate'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 101\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# Coherence is not good enough. We also track reconstruction error.\u001B[39;00m\n\u001B[0;32m    100\u001B[0m test_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset\u001B[38;5;241m=\u001B[39mvalidation, batch_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 101\u001B[0m evaluation_results \u001B[38;5;241m=\u001B[39m \u001B[43miteration_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevalutate\u001B[49m(test_dataloader)\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28mprint\u001B[39m(results)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;66;03m# Evaluate the model\u001B[39;00m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# We evaluate on the relative coherence between topics.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1929\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1930\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1931\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m   1932\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1933\u001B[0m )\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Functional' object has no attribute 'evalutate'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-18T19:33:57.137425Z"
    }
   },
   "cell_type": "code",
   "source": "r = iteration_model.evaluate(test_dataloader)",
   "id": "68d080c1a3b65242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T22:01:49.900630Z",
     "start_time": "2025-01-10T22:01:49.897224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(scores)\n",
    "# [{'coherence': -13.677789412100989, 'parameters': {'aspect_size': 17, 'embedding_size': 150, 'epochs': 20, 'batch_size': 64}}] #1st config\n",
    "\"\"\"\n",
    "[{'coherence': -14.44752463324073,\n",
    "  'parameters': {'aspect_size': 16, 'embedding_size': 150, 'epochs': 15, 'batch_size': 64}},\n",
    " {'coherence': -13.02996122137577,\n",
    "  'parameters': {'aspect_size': 19, 'embedding_size': 200, 'epochs': 15, 'batch_size': 128}},\n",
    " {'coherence': -13.172903114163981,\n",
    "  'parameters': {'aspect_size': 18, 'embedding_size': 200, 'epochs': 10, 'batch_size': 128}},\n",
    " {'coherence': -13.961204280840835,\n",
    "  'parameters': {'aspect_size': 19, 'embedding_size': 200, 'epochs': 20, 'batch_size': 128}},\n",
    " {'coherence': -14.993132489678818,\n",
    "  'parameters': {'aspect_size': 16, 'embedding_size': 150, 'epochs': 5, 'batch_size': 64}},\n",
    " {'coherence': -13.23495325584567,\n",
    "  'parameters': {'aspect_size': 15, 'embedding_size': 100, 'epochs': 15, 'batch_size': 32}},\n",
    " {'coherence': -13.501908255646923,\n",
    "  'parameters': {'aspect_size': 14, 'embedding_size': 100, 'epochs': 15, 'batch_size': 32}}]\n",
    "\"\"\""
   ],
   "id": "875f68d6da388aca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'coherence': -14.44752463324073, 'parameters': {'aspect_size': 16, 'embedding_size': 150, 'epochs': 15, 'batch_size': 64}}, {'coherence': -13.02996122137577, 'parameters': {'aspect_size': 19, 'embedding_size': 200, 'epochs': 15, 'batch_size': 128}}, {'coherence': -13.172903114163981, 'parameters': {'aspect_size': 18, 'embedding_size': 200, 'epochs': 10, 'batch_size': 128}}, {'coherence': -13.961204280840835, 'parameters': {'aspect_size': 19, 'embedding_size': 200, 'epochs': 20, 'batch_size': 128}}, {'coherence': -14.993132489678818, 'parameters': {'aspect_size': 16, 'embedding_size': 150, 'epochs': 5, 'batch_size': 64}}, {'coherence': -13.23495325584567, 'parameters': {'aspect_size': 15, 'embedding_size': 100, 'epochs': 15, 'batch_size': 32}}, {'coherence': -13.501908255646923, 'parameters': {'aspect_size': 14, 'embedding_size': 100, 'epochs': 15, 'batch_size': 32}}]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Focus on learning rate",
   "id": "cf07a77d637e025"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We fix other params and now focus entirely on lr.\n",
    "# We have already a \"promising\" range defined.\n",
    "# We look in that space so we redefine lr on ABAERandomHyperparametersSelectionWrapper"
   ],
   "id": "c6f003172b40c1ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Best found model training:",
   "id": "1dea99b96f59ac5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## See if the Hp tuning really improved upon our results:\n",
    "We used SGD anda learned its parameters under the assumption that we would do better. <br>\n",
    "Let's see if it really is the case, or we just wasted time.\n",
    "\n",
    "For comparison we use Adam that has the advantage of being robust enough without parameter scouting."
   ],
   "id": "9b8089270d722ec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#todo",
   "id": "84bcef4b87f44595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T16:15:25.969691Z",
     "start_time": "2025-01-18T16:15:25.965285Z"
    }
   },
   "cell_type": "code",
   "source": "parameters",
   "id": "72ac59455a081b30",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aspect_size': 18,\n",
       " 'embedding_size': 300,\n",
       " 'epochs': 15,\n",
       " 'batch_size': 64,\n",
       " 'learning_rate': 0.01778279410038923,\n",
       " 'decay_rate': 0.9450000000000001,\n",
       " 'momentum': 0.97,\n",
       " 'negative_sample_size': 15}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T19:05:37.371461Z",
     "start_time": "2025-01-18T19:05:37.366809Z"
    }
   },
   "cell_type": "code",
   "source": "seen_configurations",
   "id": "28569958a07cac84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({('aspect_size', 16),\n",
       "            ('batch_size', 64),\n",
       "            ('decay_rate', 0.93),\n",
       "            ('embedding_size', 200),\n",
       "            ('epochs', 12),\n",
       "            ('learning_rate', 0.0031622776601683794),\n",
       "            ('momentum', 0.9400000000000001),\n",
       "            ('negative_sample_size', 15)}),\n",
       " frozenset({('aspect_size', 18),\n",
       "            ('batch_size', 64),\n",
       "            ('decay_rate', 0.9450000000000001),\n",
       "            ('embedding_size', 300),\n",
       "            ('epochs', 15),\n",
       "            ('learning_rate', 0.01778279410038923),\n",
       "            ('momentum', 0.97),\n",
       "            ('negative_sample_size', 15)}),\n",
       " frozenset({('aspect_size', 20),\n",
       "            ('batch_size', 128),\n",
       "            ('decay_rate', 0.975),\n",
       "            ('embedding_size', 200),\n",
       "            ('epochs', 12),\n",
       "            ('learning_rate', 0.1),\n",
       "            ('momentum', 0.98),\n",
       "            ('negative_sample_size', 20)})}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eb595c23e3f6a586"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
