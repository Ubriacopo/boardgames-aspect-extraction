{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:36:59.622406Z",
     "start_time": "2024-11-30T17:36:59.620300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "id": "40757908fc8c86f8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:00.915796Z",
     "start_time": "2024-11-30T17:36:59.666058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ],
   "id": "9b8a8833fcaa7e6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x740dc24e6570>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Regularization\n",
    ">We hope to learn vector representations of the most representative aspects for a review dataset.\n",
    "However, the aspect embedding matrix T may suffer from redundancy problems during training. [...] \n",
    "> The regularization term encourages orthogonality among the rows of the aspect embedding matrix T and penalizes redundancy between different aspect vectors\n",
    "> ~ Ruidan\n",
    "\n",
    "We use an Orthogonal Regulizer definition of the method can be found here: https://paperswithcode.com/method/orthogonal-regularization. <br/>\n",
    "For the code we use the default implementation provided by Keras (https://keras.io/api/layers/regularizers/)"
   ],
   "id": "a67bb8c9beca9d72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:00.921618Z",
     "start_time": "2024-11-30T17:37:00.919495Z"
    }
   },
   "cell_type": "code",
   "source": "corpus_file = \"./../data/corpus.preprocessed.csv\"  # It's this",
   "id": "d70b9004cc53f3fc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aspect Embedding Size\n",
    "The aspect embedding size is what will be inferring aspects. It is closest to representative words (?). <br />\n",
    "We have to identify 7 actual aspects (luck, bookkeeping, downtime...) but that does not mean our matrix should be limited to rows only! What size to search is a good question and should be studied (Which I may be doing later). \n",
    "\n",
    "For the first try we setup the aspect_size:\n",
    ">The optimal number of rows is problem-dependent, so it’s crucial to: <br/>\n",
    "> Start with a heuristic: Begin with 2–3x the number of aspects."
   ],
   "id": "c4957d1b3784a455"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:00.923957Z",
     "start_time": "2024-11-30T17:37:00.922230Z"
    }
   },
   "cell_type": "code",
   "source": "aspect_size = 2 * 7",
   "id": "319cff948ad5e033",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Corpus Considerations\n",
    "Should move where dataset ipynb is but:"
   ],
   "id": "94b539dcf823d1c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Setup",
   "id": "52d8be30943c43e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:04.153964Z",
     "start_time": "2024-11-30T17:37:00.924931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import core.embeddings as embeddings\n",
    "import core.utils\n",
    "\n",
    "embeddings_model = embeddings.WordEmbedding(\n",
    "    core.utils.LoadCorpusUtility(), max_vocab_size=16000, embedding_size=128,\n",
    "    target_model_file=\"./../data/word-embeddings.model\", corpus_file=corpus_file\n",
    ")\n",
    "\n",
    "aspect_embeddings_model = embeddings.AspectEmbedding(\n",
    "    aspect_size=aspect_size, embedding_size=128, base_embeddings=embeddings_model,\n",
    "    target_model_file=\"./../data/aspects-embedding.model\"\n",
    ")"
   ],
   "id": "eb3470aaa495a5cd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:04.231481Z",
     "start_time": "2024-11-30T17:37:04.161400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings_model.load_model()\n",
    "aspect_embeddings_model.load_model()"
   ],
   "id": "bfe27fa3b412d9ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2Vec object from ../data/word-embeddings.model\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '../data/word-embeddings.model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loading wv recursively from ../data/word-embeddings.model.wv.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': '../data/word-embeddings.model', 'datetime': '2024-11-30T18:37:04.229569', 'gensim': '4.3.3', 'python': '3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0]', 'platform': 'Linux-6.8.0-49-generic-x86_64-with-glibc2.39', 'event': 'loaded'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "65d6492c659ce55c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load the data",
   "id": "89216349e5c6f335"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:09.399018Z",
     "start_time": "2024-11-30T17:37:04.232177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vocabulary = embeddings_model.model.wv.key_to_index\n",
    "\n",
    "train = dataset.PositiveNegativeCommentGeneratorDataset(\n",
    "    vocabulary=vocabulary, csv_dataset_path=corpus_file, negative_size=15\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=32, shuffle=True)"
   ],
   "id": "58801e13d855b211",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spacy model.\n",
      "Loading dataset from file: ./../data/corpus.preprocessed.csv\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/50461 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cac54a1c52814f348fd0732b81ae0eca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 136 points.This is 0.2695150710449654% of the dataset.\n",
      "Padding sequences to max length (256).\n",
      "Max sequence length is:  1235  but we will limit sequences to 256 tokens.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:09.403321Z",
     "start_time": "2024-11-30T17:37:09.399781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.model import ABAEGenerator\n",
    "\n",
    "generator = ABAEGenerator(256, train.negative_size, embeddings_model, aspect_embeddings_model)"
   ],
   "id": "ea223a0ab512537",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "3adc8a873389afd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:09.405521Z",
     "start_time": "2024-11-30T17:37:09.403875Z"
    }
   },
   "cell_type": "code",
   "source": "from core import utils",
   "id": "a68c3c29b7d96160",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Why SGD: You know why! todo: Link the papers",
   "id": "2afaad25bf7cdab1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:37:09.409347Z",
     "start_time": "2024-11-30T17:37:09.406072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.get_device_name(0)"
   ],
   "id": "cc29011d02db49fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have too much data for my little PC:\n",
    "\n",
    "> Sampling: Randomly select a subset of your data that represents the overall distribution of aspects. This will help maintain diversity while reducing the size.\n",
    "Filtering: Focus on the most informative or high-quality samples. For example, if certain reviews are very short, irrelevant, or don't have useful context for aspect extraction, remove them.\n",
    "Focus on Diversity: If you reduce the data, make sure the remaining dataset is still representative of the diversity of aspects you're trying to capture."
   ],
   "id": "54caba09394445b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:53:50.256911Z",
     "start_time": "2024-11-30T17:37:09.410551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_model = generator.make_training_model()\n",
    "training_model.compile(optimizer='SGD', loss=[utils.max_margin_loss], metrics={'max_margin': utils.max_margin_loss})\n",
    "history = training_model.fit(x=train_dataloader, batch_size=32, epochs=15)"
   ],
   "id": "e02073957d81e7d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacopo/PycharmProjects/nlp-course-project/core/layer.py:126: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the core instead.\n",
      "  super(WeightedAspectEmb, self).__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m66s\u001B[0m 42ms/step - loss: 13.7152 - max_margin_loss: 13.7152\n",
      "Epoch 2/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m66s\u001B[0m 42ms/step - loss: 11.2962 - max_margin_loss: 11.2962\n",
      "Epoch 3/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 40ms/step - loss: 9.4733 - max_margin_loss: 9.4733\n",
      "Epoch 4/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 41ms/step - loss: 8.7165 - max_margin_loss: 8.7165\n",
      "Epoch 5/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 41ms/step - loss: 8.3181 - max_margin_loss: 8.3181\n",
      "Epoch 6/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 41ms/step - loss: 8.1459 - max_margin_loss: 8.1459\n",
      "Epoch 7/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 40ms/step - loss: 7.9774 - max_margin_loss: 7.9774\n",
      "Epoch 8/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 41ms/step - loss: 7.8275 - max_margin_loss: 7.8275\n",
      "Epoch 9/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m68s\u001B[0m 43ms/step - loss: 7.6478 - max_margin_loss: 7.6478\n",
      "Epoch 10/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m68s\u001B[0m 43ms/step - loss: 7.4167 - max_margin_loss: 7.4167\n",
      "Epoch 11/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 44ms/step - loss: 7.0284 - max_margin_loss: 7.0284\n",
      "Epoch 12/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 44ms/step - loss: 6.5674 - max_margin_loss: 6.5674\n",
      "Epoch 13/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 44ms/step - loss: 5.9915 - max_margin_loss: 5.9915\n",
      "Epoch 14/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 45ms/step - loss: 5.6416 - max_margin_loss: 5.6416\n",
      "Epoch 15/15\n",
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 44ms/step - loss: 5.4395 - max_margin_loss: 5.4395\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:53:50.259142Z",
     "start_time": "2024-11-30T17:53:50.257504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How to Address Issues (If Any):\n",
    "# Introduce Hard Negatives:\n",
    "# Instead of randomly selecting negative samples, use hard negatives—examples that are more challenging to distinguish from positive pairs. This keeps the max-margin loss informative and prevents the model from converging too quickly.\n",
    "\n",
    "# Regularization:\n",
    "# Apply regularization (e.g., L2 regularization) to prevent overfitting and ensure the model generalizes well.\n",
    "\n",
    "# Early Stopping:\n",
    "# If the loss plateaus and aspect quality is satisfactory, consider using early stopping to avoid unnecessary training."
   ],
   "id": "64c6ea7554d341a9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:53:50.290450Z",
     "start_time": "2024-11-30T17:53:50.259787Z"
    }
   },
   "cell_type": "code",
   "source": "training_model.save(\"./../data/abae.keras\")",
   "id": "8b3ab43c76041221",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:h5py._conv:Creating converter from 5 to 3\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Evaluation",
   "id": "b000cd79defb39bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:53:50.319369Z",
     "start_time": "2024-11-30T17:53:50.291088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load evaluation model\n",
    "inference_model = generator.make_model(\"./../data/abae.keras\")"
   ],
   "id": "fe6595f99460d942",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:54:28.237930Z",
     "start_time": "2024-11-30T17:53:50.319985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = inference_model.predict(x=train_dataloader)\n",
    "np.argmax(out[2], axis=-1)  # The associated labels"
   ],
   "id": "48815717db4ed6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1577/1577\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m38s\u001B[0m 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 0, 7, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Find aspect most representative words",
   "id": "60641b3d29be817"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:54:28.243403Z",
     "start_time": "2024-11-30T17:54:28.238565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_emb = inference_model.get_layer('word_embedding').get_weights()[0]\n",
    "word_emb = torch.from_numpy(word_emb)\n",
    "word_emb.shape"
   ],
   "id": "92373d07480df156",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12954, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:54:28.279504Z",
     "start_time": "2024-11-30T17:54:28.243962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aspect_embeddings = inference_model.get_layer('weighted_aspect_emb').W\n",
    "vocab_inv = embeddings_model.model.wv.index_to_key\n",
    "\n",
    "aspect_words = []\n",
    "aspect_index = 0\n",
    "\n",
    "for aspect in aspect_embeddings:\n",
    "    aspect = aspect.cpu()\n",
    "    # Calculate the cosine similarity of each word with the aspect\n",
    "    word_emb = word_emb / torch.linalg.norm(word_emb, dim=-1, keepdim=True)\n",
    "    aspect = aspect / torch.linalg.norm(aspect, dim=-1, keepdim=True)\n",
    "\n",
    "    similarity = word_emb.matmul(aspect.T)\n",
    "\n",
    "    numpy_similarity = similarity.detach().numpy()\n",
    "\n",
    "    ordered_words = np.argsort(numpy_similarity)[::-1]\n",
    "    desc_list = [(vocab_inv[w], numpy_similarity[w]) for w in ordered_words[:15]]\n",
    "    aspect_words.append(desc_list)\n",
    "\n",
    "    print(\"Aspect \", aspect_index)\n",
    "    for i in desc_list:\n",
    "        # hr][/i is not a valid word. meh.\n",
    "        print(\"Word: \", i[0], f\"({i[1]})\")\n",
    "\n",
    "    aspect_index += 1"
   ],
   "id": "b7202702cf2f7f51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect  0\n",
      "Word:  release (0.5447440147399902)\n",
      "Word:  buy (0.5116141438484192)\n",
      "Word:  back (0.4773868918418884)\n",
      "Word:  unlock (0.477204293012619)\n",
      "Word:  magic (0.4655134677886963)\n",
      "Word:  ffg (0.46209990978240967)\n",
      "Word:  kickstarter (0.46151912212371826)\n",
      "Word:  marvel (0.459344744682312)\n",
      "Word:  retail (0.45813944935798645)\n",
      "Word:  glad (0.4541388750076294)\n",
      "Word:  pls (0.44647061824798584)\n",
      "Word:  cosmetic (0.4373928904533386)\n",
      "Word:  copy (0.4348754286766052)\n",
      "Word:  legendary (0.43482765555381775)\n",
      "Word:  regret (0.4348164200782776)\n",
      "Aspect  1\n",
      "Word:  belive (0.7245154976844788)\n",
      "Word:  email (0.7236083745956421)\n",
      "Word:  familiarize (0.7202874422073364)\n",
      "Word:  incarnation (0.7198400497436523)\n",
      "Word:  clothe (0.719068169593811)\n",
      "Word:  tmb (0.7155524492263794)\n",
      "Word:  technically (0.7127645611763)\n",
      "Word:  preset (0.7095102071762085)\n",
      "Word:  kg (0.7089599370956421)\n",
      "Word:  rondell (0.7079117298126221)\n",
      "Word:  ppl (0.7070233821868896)\n",
      "Word:  dame (0.7059849500656128)\n",
      "Word:  erratas (0.7055681943893433)\n",
      "Word:  ot (0.7048789858818054)\n",
      "Word:  hte (0.7038723230361938)\n",
      "Aspect  2\n",
      "Word:  skilled (0.6982916593551636)\n",
      "Word:  rut (0.6949139833450317)\n",
      "Word:  combative (0.6894547939300537)\n",
      "Word:  fifth (0.688031017780304)\n",
      "Word:  suspicious (0.6866863965988159)\n",
      "Word:  summarise (0.6839203834533691)\n",
      "Word:  contention (0.6790550947189331)\n",
      "Word:  mathe (0.6789302825927734)\n",
      "Word:  contrary (0.6784725189208984)\n",
      "Word:  handicap (0.677964448928833)\n",
      "Word:  else (0.6771073341369629)\n",
      "Word:  thon (0.6763026118278503)\n",
      "Word:  disregard (0.6756355166435242)\n",
      "Word:  drown (0.6739515066146851)\n",
      "Word:  gene (0.6731894016265869)\n",
      "Aspect  3\n",
      "Word:  angst (0.4518653154373169)\n",
      "Word:  mathe (0.4456774592399597)\n",
      "Word:  lull (0.4449758529663086)\n",
      "Word:  attentive (0.44487059116363525)\n",
      "Word:  upkeep (0.44027280807495117)\n",
      "Word:  simultaneously (0.43783822655677795)\n",
      "Word:  skilled (0.4343178868293762)\n",
      "Word:  rut (0.4342578053474426)\n",
      "Word:  beginning (0.43380972743034363)\n",
      "Word:  summarise (0.4309144914150238)\n",
      "Word:  calculation (0.43076011538505554)\n",
      "Word:  decimate (0.4281756281852722)\n",
      "Word:  critical (0.4271489679813385)\n",
      "Word:  induce (0.4258180856704712)\n",
      "Word:  consideration (0.4254299998283386)\n",
      "Aspect  4\n",
      "Word:  mechanically (0.7395925521850586)\n",
      "Word:  thematic (0.7256996631622314)\n",
      "Word:  engaging (0.7094951868057251)\n",
      "Word:  elegant (0.6952482461929321)\n",
      "Word:  innovative (0.6849705576896667)\n",
      "Word:  abstract (0.6726769208908081)\n",
      "Word:  style (0.6667015552520752)\n",
      "Word:  theme (0.6659834384918213)\n",
      "Word:  nicely (0.6627437472343445)\n",
      "Word:  simplicity (0.6504080295562744)\n",
      "Word:  thinky (0.648577094078064)\n",
      "Word:  surprisingly (0.6426346302032471)\n",
      "Word:  cute (0.6402686834335327)\n",
      "Word:  cutesy (0.6397366523742676)\n",
      "Word:  blend (0.6395053267478943)\n",
      "Aspect  5\n",
      "Word:  pledge (0.5881250500679016)\n",
      "Word:  25th (0.576857328414917)\n",
      "Word:  ~ (0.5745965242385864)\n",
      "Word:  md2 (0.572848916053772)\n",
      "Word:  playmat (0.5622756481170654)\n",
      "Word:  44x63 (0.5615267753601074)\n",
      "Word:  black (0.5609537363052368)\n",
      "Word:  metal (0.5596048831939697)\n",
      "Word:  promo (0.5478048324584961)\n",
      "Word:  dark (0.5469409227371216)\n",
      "Word:  premium (0.5420743227005005)\n",
      "Word:  sleeve (0.5390489101409912)\n",
      "Word:  mayday (0.5351731181144714)\n",
      "Word:  north (0.5350816249847412)\n",
      "Word:  exp (0.5278605222702026)\n",
      "Aspect  6\n",
      "Word:  contract (0.7533861398696899)\n",
      "Word:  income (0.733350396156311)\n",
      "Word:  vp (0.7302042245864868)\n",
      "Word:  track (0.7245877981185913)\n",
      "Word:  gain (0.7081347703933716)\n",
      "Word:  bonus (0.7074660658836365)\n",
      "Word:  marker (0.7014265060424805)\n",
      "Word:  boat (0.6960002183914185)\n",
      "Word:  region (0.6936243772506714)\n",
      "Word:  food (0.6920195817947388)\n",
      "Word:  cube (0.6915662288665771)\n",
      "Word:  location (0.6874231696128845)\n",
      "Word:  money (0.6810256838798523)\n",
      "Word:  collect (0.6770788431167603)\n",
      "Word:  claim (0.6759439706802368)\n",
      "Aspect  7\n",
      "Word:  play (0.563241720199585)\n",
      "Word:  maxing (0.5241923928260803)\n",
      "Word:  edit (0.5024509429931641)\n",
      "Word:  rate (0.4789552390575409)\n",
      "Word:  11/17 (0.4773992896080017)\n",
      "Word:  session (0.4707276523113251)\n",
      "Word:  4p (0.44348227977752686)\n",
      "Word:  week (0.440207302570343)\n",
      "Word:  10 (0.438071608543396)\n",
      "Word:  update (0.4344898462295532)\n",
      "Word:  hour (0.4309106171131134)\n",
      "Word:  4/4 (0.42425668239593506)\n",
      "Word:  30 (0.41886770725250244)\n",
      "Word:  daughter (0.4180385172367096)\n",
      "Word:  3p (0.4162169396877289)\n",
      "Aspect  8\n",
      "Word:  conflict (0.4559025466442108)\n",
      "Word:  timing (0.438757061958313)\n",
      "Word:  direct (0.43573862314224243)\n",
      "Word:  economic (0.42962801456451416)\n",
      "Word:  satisfy (0.42925870418548584)\n",
      "Word:  tension (0.4263601303100586)\n",
      "Word:  generate (0.4241257905960083)\n",
      "Word:  bluff (0.41874784231185913)\n",
      "Word:  race (0.4169393479824066)\n",
      "Word:  military (0.4146558940410614)\n",
      "Word:  competition (0.41405415534973145)\n",
      "Word:  economy (0.41236376762390137)\n",
      "Word:  encourage (0.40813058614730835)\n",
      "Word:  malleable (0.40620434284210205)\n",
      "Word:  pivot (0.4061592221260071)\n",
      "Aspect  9\n",
      "Word:  keyple (0.6437544822692871)\n",
      "Word:  resolve (0.6330983638763428)\n",
      "Word:  perform (0.6057081818580627)\n",
      "Word:  income (0.6033197641372681)\n",
      "Word:  supply (0.5931459665298462)\n",
      "Word:  activation (0.5909640789031982)\n",
      "Word:  accumulate (0.5872229337692261)\n",
      "Word:  critical (0.5856596231460571)\n",
      "Word:  crucial (0.5854961276054382)\n",
      "Word:  enchanter (0.583258330821991)\n",
      "Word:  lock (0.582610011100769)\n",
      "Word:  determine (0.5801068544387817)\n",
      "Word:  consequence (0.5755595564842224)\n",
      "Word:  reward (0.5713491439819336)\n",
      "Word:  phase (0.5691577792167664)\n",
      "Aspect  10\n",
      "Word:  enought (0.4639054536819458)\n",
      "Word:  mechs (0.4528099298477173)\n",
      "Word:  cull (0.447909414768219)\n",
      "Word:  log (0.4444660544395447)\n",
      "Word:  currently (0.44291603565216064)\n",
      "Word:  chronology (0.4399208426475525)\n",
      "Word:  rumor (0.4393736720085144)\n",
      "Word:  previously (0.43861159682273865)\n",
      "Word:  wanna (0.4380771517753601)\n",
      "Word:  preset (0.43652787804603577)\n",
      "Word:  heather (0.43603402376174927)\n",
      "Word:  ham (0.43216949701309204)\n",
      "Word:  hoax (0.43075352907180786)\n",
      "Word:  finite (0.42915573716163635)\n",
      "Word:  automata (0.42695096135139465)\n",
      "Aspect  11\n",
      "Word:  3- (0.5087751150131226)\n",
      "Word:  2 (0.4878714978694916)\n",
      "Word:  disadvantage (0.4564206004142761)\n",
      "Word:  \\13\\ (0.4532138705253601)\n",
      "Word:  count (0.4319762885570526)\n",
      "Word:  variant (0.43002015352249146)\n",
      "Word:  suspect (0.42525720596313477)\n",
      "Word:  imagine (0.42429882287979126)\n",
      "Word:  minimum (0.4215738773345947)\n",
      "Word:  dueler (0.4204886555671692)\n",
      "Word:  3 (0.4171687960624695)\n",
      "Word:  alienate (0.41337770223617554)\n",
      "Word:  shaky (0.41277408599853516)\n",
      "Word:  party (0.40866589546203613)\n",
      "Word:  experienced (0.406451940536499)\n",
      "Aspect  12\n",
      "Word:  eliminate (0.6780023574829102)\n",
      "Word:  single (0.6657650470733643)\n",
      "Word:  beginning (0.6498178243637085)\n",
      "Word:  face (0.639141321182251)\n",
      "Word:  simultaneously (0.6355462074279785)\n",
      "Word:  randomly (0.6203116178512573)\n",
      "Word:  predict (0.6099243760108948)\n",
      "Word:  choose (0.6089282631874084)\n",
      "Word:  effectively (0.6066470146179199)\n",
      "Word:  happen (0.6042191982269287)\n",
      "Word:  attack (0.6015000343322754)\n",
      "Word:  cause (0.6007243990898132)\n",
      "Word:  sequence (0.5990183353424072)\n",
      "Word:  person (0.5982658863067627)\n",
      "Word:  determine (0.5977545976638794)\n",
      "Aspect  13\n",
      "Word:  pendragon (0.5009773969650269)\n",
      "Word:  check (0.4889921247959137)\n",
      "Word:  fail (0.4768734276294708)\n",
      "Word:  error (0.47563832998275757)\n",
      "Word:  tidbit (0.47560590505599976)\n",
      "Word:  nauseum (0.4742206931114197)\n",
      "Word:  dishearten (0.4710935950279236)\n",
      "Word:  fix (0.4705195128917694)\n",
      "Word:  miss (0.4659067392349243)\n",
      "Word:  impatiently (0.46543434262275696)\n",
      "Word:  live (0.46320411562919617)\n",
      "Word:  survive (0.4621725082397461)\n",
      "Word:  premature (0.461147665977478)\n",
      "Word:  stride (0.46014708280563354)\n",
      "Word:  eventually (0.4600198566913605)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41875/828010576.py:13: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
      "  similarity = word_emb.matmul(aspect.T)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate coherence\n",
    "Topical coherence measures the semantic consistency of terms grouped under a topic or aspect. It checks whether the terms frequently co-occur in similar contexts within your dataset, reflecting a meaningful grouping. For each topic (aspect), calculate pairwise co-occurrence of terms across the dataset. Terms that co-occur frequently in the same context are considered more coherent\n",
    "\n"
   ],
   "id": "f58d27ab60b7ea76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:54:28.301857Z",
     "start_time": "2024-11-30T17:54:28.280292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For each word of aspect for the aspect we calculate the coherence by AVG distance between top words\n",
    "for aspect_most_representative_words in aspect_words:\n",
    "    coherence = []\n",
    "    for word in aspect_most_representative_words:\n",
    "        w, score = word\n",
    "        for word2 in aspect_most_representative_words:\n",
    "            w2, score = word2\n",
    "            if w != w2:\n",
    "                coherence.append(embeddings_model.model.wv.similarity(w, w2))\n",
    "    # todo fai avgf cosi natualmente sbagliato  \n",
    "    print(\"Aspect i has total coherence of\", np.mean(coherence, axis=0))  # AVG"
   ],
   "id": "4beec4cd26c90a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect i has total coherence of 0.6271665\n",
      "Aspect i has total coherence of 0.8668326\n",
      "Aspect i has total coherence of 0.84780085\n",
      "Aspect i has total coherence of 0.74030197\n",
      "Aspect i has total coherence of 0.7200178\n",
      "Aspect i has total coherence of 0.8413263\n",
      "Aspect i has total coherence of 0.8098694\n",
      "Aspect i has total coherence of 0.54224765\n",
      "Aspect i has total coherence of 0.69913083\n",
      "Aspect i has total coherence of 0.7870225\n",
      "Aspect i has total coherence of 0.7779807\n",
      "Aspect i has total coherence of 0.5372712\n",
      "Aspect i has total coherence of 0.73999083\n",
      "Aspect i has total coherence of 0.65727794\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:54:28.303845Z",
     "start_time": "2024-11-30T17:54:28.302529Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c0c830cfabd1d94c",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
