{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:00.255484Z",
     "start_time": "2024-11-28T16:22:00.253228Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\"\n",
    "random_state = 281997"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "BGG Does not directly provide a way to list all the games it has in archive therefore we used a dump created by the community (2024-08-18).",
   "id": "a4b9c9e4a84a36cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Generation\n",
    "Our dataset is a corpus of reviews scrapped from the BGG API. <br /> \n",
    "In order to download the comments we make use of the ```bgg_corpus_service.py``` content."
   ],
   "id": "dbc6de67c270e005"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Subsample the data\n",
    "We should limit the number of reviews, how many? Let's look at some case studies:\n",
    "\n",
    "- Amazon Product Reviews\n",
    "Size: Varies by category, but subsets of 5,000 to 20,000 reviews are common.\n",
    "- Yelp Dataset\n",
    "Size: Typically, 8,000 to 15,000 reviews are used in research for unsupervised aspect extraction.\n",
    "- TripAdvisor Reviews\n",
    "Size: Around 5,000 to 10,000 reviews in unsupervised experiments.\n",
    "\n",
    "For unsupervised learning, 5,000–10,000 reviews is a reasonable starting point for recognizing 6 aspects. More reviews may improve diversity and robustness but come with increased computational costs.\n",
    "\n",
    "\n"
   ],
   "id": "3320e5f9231d0f54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:02.529294Z",
     "start_time": "2024-11-28T16:22:02.262699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "corpus_file = \"../data/corpus.csv\"\n",
    "sampled_corpus_file = \"../data/corpus.sampled.csv\""
   ],
   "id": "2a3c38e49670b1a9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:07:50.775554Z",
     "start_time": "2024-11-28T15:07:46.218280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "og_data = pd.read_csv(corpus_file)\n",
    "reviews_per_game = int(64000 / len(og_data.groupby([\"game_id\"]).count())) + 1\n",
    "\n",
    "print(f\"I have a total of {len(og_data.groupby([\"game_id\"]).count())} games with reviews. \"\n",
    "      f\"We want to be ~64k reviews so we take {reviews_per_game} reviews per game.\")"
   ],
   "id": "1bcc4826493661a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a total of 2220 games with reviews. We want to be ~64k reviews so we take 29 reviews per game.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:07:53.230916Z",
     "start_time": "2024-11-28T15:07:52.159765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We start by using ~64k reviews (More robustness). This is before pre-processing which might reduce the total number of reviews later.\n",
    "(\n",
    "    og_data.groupby(\"game_id\", group_keys=False)[og_data.columns]\n",
    "    .apply(lambda x: x.sample(min(len(x), reviews_per_game), random_state=random_state))\n",
    "    .to_csv(sampled_corpus_file, index=False)\n",
    ")"
   ],
   "id": "706f590b584adbab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check distribution of games",
   "id": "2b9f595bf8a9ce64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:07:54.802675Z",
     "start_time": "2024-11-28T15:07:54.684090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(sampled_corpus_file)\n",
    "data"
   ],
   "id": "6e664d235ddec991",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                comments  game_id\n",
       "0      I like the 1986 version much more than the 199...        1\n",
       "1      New edition.  It's a great political game that...        1\n",
       "2                                       Consider selling        1\n",
       "3      + Interesting, complex, classic deep game. - T...        1\n",
       "4      Just two incomplete plays. Not enough to give ...        1\n",
       "...                                                  ...      ...\n",
       "64375  今天要给小动物们找个家！ 超主观点评： 1、主题好，画风可可爱爱，规则非常简单，适合推新。如...   414317\n",
       "64376                                   Available on BGA   414317\n",
       "64377  Played on BGA.  Mostly solitaire abstract puzz...   414317\n",
       "64378                                   2025 for Amanda?   414317\n",
       "64379  Een vergelijkbaar spel met Cascadia waarbij de...   414317\n",
       "\n",
       "[64380 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>game_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like the 1986 version much more than the 199...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New edition.  It's a great political game that...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consider selling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>+ Interesting, complex, classic deep game. - T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just two incomplete plays. Not enough to give ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64375</th>\n",
       "      <td>今天要给小动物们找个家！ 超主观点评： 1、主题好，画风可可爱爱，规则非常简单，适合推新。如...</td>\n",
       "      <td>414317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64376</th>\n",
       "      <td>Available on BGA</td>\n",
       "      <td>414317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64377</th>\n",
       "      <td>Played on BGA.  Mostly solitaire abstract puzz...</td>\n",
       "      <td>414317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64378</th>\n",
       "      <td>2025 for Amanda?</td>\n",
       "      <td>414317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64379</th>\n",
       "      <td>Een vergelijkbaar spel met Cascadia waarbij de...</td>\n",
       "      <td>414317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64380 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:07:56.334545Z",
     "start_time": "2024-11-28T15:07:56.322560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.groupby([\"game_id\"]).count()\n",
    "# Each of our games has the same representation then others. The \"reviews\" should be balanced across all games.\n",
    "# We can now proceed to pre-process the data."
   ],
   "id": "43f74533b8eaa2d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         comments\n",
       "game_id          \n",
       "1              29\n",
       "3              29\n",
       "5              29\n",
       "10             29\n",
       "11             29\n",
       "...           ...\n",
       "397385         29\n",
       "397598         29\n",
       "400314         29\n",
       "410201         29\n",
       "414317         29\n",
       "\n",
       "[2220 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397385</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397598</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400314</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410201</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414317</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2220 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "The downloaded information from the BGG API might not be informative, faulty or bloated with useless information. <br>\n",
    "In order to avoid this we apply some pre-processing steps in order to filter out information we don't need, that may be entire records or some of the \n",
    "text inside a line.\n",
    "\n",
    "During the process we already make the tokenization and stemming of the text using the ```spacy```\n"
   ],
   "id": "dd77baf7691d9845"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:06.554432Z",
     "start_time": "2024-11-28T16:22:06.552427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "# Some parts of torch that are used by Spacy are deprecated, we can ignore them \n",
    "# (The new 3.8 Spacy has some little issues, so we keep it like it is for now)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ],
   "id": "64a698bac2ddfbaa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Using Spacy\n",
    "To download the model and use it with spacy:\n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ],
   "id": "ee94d5b53e9a4b3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:06.548576Z",
     "start_time": "2024-11-28T15:08:04.080506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "a27a63bb78a7956c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacopo/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/jacopo/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/jacopo/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PreProcessingService\n",
    "Class that holds the process to clean the text and produce a stemmed corpus. <br/> This will then be persisted in a file to avoid re-processing the same data."
   ],
   "id": "1e98af23ba814cc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:12.281336Z",
     "start_time": "2024-11-28T15:08:11.421353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pre_processing import PreProcessingService\n",
    "\n",
    "ps = PreProcessingService()"
   ],
   "id": "8d6e62a1a3aada51",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:13.301270Z",
     "start_time": "2024-11-28T15:08:13.299183Z"
    }
   },
   "cell_type": "code",
   "source": "demo_text = \"This is a demo text. Isn't Root just an amazing game? I love it!\"",
   "id": "2a4b2f815ea5d707",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### BGG noise removal\n",
    "BGG comments can carry metadata such as images and some pseudo-html tags. <br>\n",
    "To avoid processing those we simply remove them applying two regexes:"
   ],
   "id": "d1e697b1e80ef34e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:14.075294Z",
     "start_time": "2024-11-28T15:08:14.073138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# As defined in the PreProcessingService\n",
    "clean_tags_regex = r\"(?i)\\[(?P<tag>[A-Z]+)\\].*?\\[/\\1\\]\"\n",
    "keep_tag_content_regex = r\"\\[(?P<tag>[a-z]+)(=[^\\]]+)?\\](.*?)\\[/\\1\\]\""
   ],
   "id": "d8e102ce5c62c959",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:14.931006Z",
     "start_time": "2024-11-28T15:08:14.928285Z"
    }
   },
   "cell_type": "code",
   "source": "ps.clean_text(\"This is a test for processing [IMG]https://cf.geekdo-static.com/mbs/mb_5855_0.gif[/IMG] as content\")",
   "id": "844da63647167857",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test for processing  as content'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:15.917984Z",
     "start_time": "2024-11-28T15:08:15.914902Z"
    }
   },
   "cell_type": "code",
   "source": "ps.clean_text(\"This is a test for processing [b=323]bold[/b] as content\")",
   "id": "4f22f395bed61768",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test for processing bold as content'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Language detection\n",
    "While it of course would be amazing to have a model with multiple languages support, we are focusing on English. <br>\n",
    "To filter out foreign languages we use the ```langdetect``` library."
   ],
   "id": "13ce78a96095cb28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:17.532631Z",
     "start_time": "2024-11-28T15:08:17.513105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fast_langdetect import detect\n",
    "\n",
    "german_sentence = \"Naja, ich finde die Siedler von Catan immer noch besser\"\n",
    "print(f\"For the demo sentence: \\\"{demo_text}\\\" we detected: {detect(demo_text)['lang']}\")\n",
    "print(f\"For the demo sentence: \\\"{german_sentence}\\\" we detected: {detect(german_sentence)['lang']}\")"
   ],
   "id": "c83a85ac0f4dc4e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the demo sentence: \"This is a demo text. Isn't Root just an amazing game? I love it!\" we detected: en\n",
      "For the demo sentence: \"Naja, ich finde die Siedler von Catan immer noch besser\" we detected: de\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tokenization and lemmatization\n",
    "Using ```spacy``` we tokenize the text and then we lemmatize it. <br>"
   ],
   "id": "9d09de9d83f7803"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:18.850935Z",
     "start_time": "2024-11-28T15:08:18.837244Z"
    }
   },
   "cell_type": "code",
   "source": "ps._make_text_lemmas(demo_text)  # (Should be considered private)",
   "id": "dd3379b4e9a69b1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo', 'text', 'root', 'amazing', 'game', 'love']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Remove too narrow texts\n",
    "Comments (reviews) that are too short might not be informative. <br>\n",
    "We already remove stopwords and punctuation, so we can filter out comments that are too short but we better set a reasonable threshold (not too high). This step is done by the PreProcessingService aswell."
   ],
   "id": "2f3b1f7ff4e3d626"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T15:08:21.192273Z",
     "start_time": "2024-11-28T15:08:21.184316Z"
    }
   },
   "cell_type": "code",
   "source": "ps.pre_process(demo_text)",
   "id": "bd43f68840b97cde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demo text root amazing game love'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batch Process",
   "id": "eb8ea8a516f6e333"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:12.369293Z",
     "start_time": "2024-11-28T16:22:12.367087Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessed_corpus_file: str = \"../data/corpus.preprocessed.csv\"",
   "id": "4c9247f72399ebab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:15:59.356455Z",
     "start_time": "2024-11-28T16:10:03.220606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pre_processing import pre_process_corpus\n",
    "\n",
    "pre_process_corpus(sampled_corpus_file, preprocessed_corpus_file, False)"
   ],
   "id": "8b468bf30543713d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/64380 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c6a825811174c3d81053cd22fdeafc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "See how the dataset changed:",
   "id": "d1ac6ed6895a43c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:17:02.611881Z",
     "start_time": "2024-11-28T16:17:02.459100Z"
    }
   },
   "cell_type": "code",
   "source": "len(pd.read_csv(preprocessed_corpus_file))  # We lost 14k reviews but it is okay! (I expect to lose more)",
   "id": "edda0efd2ab7a66b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50461"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Custom Dataset Definition\n",
    "To train the model we require a way to get elements of our dataset. ```torch``` provides a way to do this by defining a custom ```Dataset``` class. <br>\n",
    "This class and later loaded into a ```DataLoader``` that will provide the batches of data to the model."
   ],
   "id": "c3a49e3e02abe587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In order to generate valid inputs for the model we have to give a numerical representation to our data. <br>\n",
    "In order to do so we use a ```WordEmbedding``` model that will give us the dictionary of the recognized words (The embeddings will be generated inside the model). <br>"
   ],
   "id": "97c7e216c29993ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:16.329177Z",
     "start_time": "2024-11-28T16:22:16.326640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_vocab_size = 16000\n",
    "embedding_size = 128\n",
    "target_embedding_model_file = \"./../data/word-embeddings.model\""
   ],
   "id": "6c98540db8a486b6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:20.415778Z",
     "start_time": "2024-11-28T16:22:16.567452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import core.utils as utils\n",
    "import core.embeddings as embeddings\n",
    "\n",
    "embeddings_model = embeddings.WordEmbedding(\n",
    "    utils.LoadCorpusUtility(), max_vocab_size=max_vocab_size, embedding_size=embedding_size,\n",
    "    target_model_file=target_embedding_model_file, corpus_file=preprocessed_corpus_file\n",
    ")"
   ],
   "id": "f3768d3e3077cd5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacopo/PycharmProjects/nlp-course-project/venv/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:20.451565Z",
     "start_time": "2024-11-28T16:22:20.416635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We require a vocabulary to map the words to indexes\n",
    "embeddings_model.load_model()\n",
    "embeddings_model.get_vocab()\n",
    "\n",
    "vocabulary = embeddings_model.model.wv.key_to_index"
   ],
   "id": "423dafa9a3a9c36b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2Vec object from ../data/word-embeddings.model\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '../data/word-embeddings.model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loading wv recursively from ../data/word-embeddings.model.wv.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': '../data/word-embeddings.model', 'datetime': '2024-11-28T17:22:20.450083', 'gensim': '4.3.3', 'python': '3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0]', 'platform': 'Linux-6.8.0-49-generic-x86_64-with-glibc2.39', 'event': 'loaded'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PositiveNegativeCommentGeneratorDataset\n",
    "Gives a sample and also returns some negative samples for contrastive learning. <br>\n"
   ],
   "id": "bbe1db3e4a470c03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:32:29.100894Z",
     "start_time": "2024-11-28T16:28:09.961420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.dataset import PositiveNegativeCommentGeneratorDataset\n",
    "\n",
    "ds = PositiveNegativeCommentGeneratorDataset(\"./../data/corpus.preprocessed.csv\", vocabulary, 10)"
   ],
   "id": "35bf3e211ffacf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spacy model.\n",
      "Loading dataset from file: ./../data/corpus.preprocessed.csv\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/50461 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06760cea357f48cd91747133dc151af2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "Padding sequences to max length (256).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PositiveNegativeCommentGeneratorDataset\n\u001B[0;32m----> 3\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[43mPositiveNegativeCommentGeneratorDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./../data/corpus.preprocessed.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocabulary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-course-project/core/dataset.py:46\u001B[0m, in \u001B[0;36mPositiveNegativeCommentGeneratorDataset.__init__\u001B[0;34m(self, csv_dataset_path, vocabulary, negative_size, max_seq_length)\u001B[0m\n\u001B[1;32m     43\u001B[0m max_found_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mlen\u001B[39m(x))\u001B[38;5;241m.\u001B[39mmax()\n\u001B[1;32m     44\u001B[0m with_lost_information \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mlen\u001B[39m(x) \u001B[38;5;241m>\u001B[39m max_seq_length)\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe loose information on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwith_lost_information\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m points.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 46\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwith_lost_information\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset)\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m100\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m% of the dataset.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPadding sequences to max length (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmax_seq_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mSeries(pre\u001B[38;5;241m.\u001B[39msequence\u001B[38;5;241m.\u001B[39mpad_sequences(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, maxlen\u001B[38;5;241m=\u001B[39mmax_seq_length)\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/pydevd.py:1201\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1198\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1201\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/pydevd.py:1216\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1213\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1215\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1216\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:22:25.178672Z",
     "start_time": "2024-11-28T16:22:25.175603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lazy_dataloader = DataLoader(ds, batch_size=32, shuffle=True)"
   ],
   "id": "6dab4b179d654a7a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:23:52.758751Z",
     "start_time": "2024-11-28T16:23:52.754860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 11  # A random index to show content and \n",
    "print(f\"Sentence at index {i} original text is: `{ds.get_text_item(i)}` (Look at [comments] property for the stripped down version)\\n \"\n",
    "      f\"It's numeric representation:\\n {ds[i][0][0]}\")"
   ],
   "id": "8da3fa5e231920ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence at index 11 original text is: `Fun, but a bit complex for my taste.` (Look at [comments] property for the stripped down version)\n",
      " It's numeric representation:\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0 3012 1540  100  252    0\n",
      "  178  172   55  212]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sequence length truncation\n",
    "The model will be trained on sequences of fixed length. <br>\n",
    "The chosen length must be reasonable, we can't just pad everything out for the same of it. <br>\n",
    "\n",
    "We want that the top 95% of the reviews are not truncated. <br>"
   ],
   "id": "2ac5649fbecf63c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We have 137 of the 50461 total reviews that are bigger than 256 tokens.\n",
    "# This is less than 1% of the total reviews. We can truncate."
   ],
   "id": "563f83c8769b8a6d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
