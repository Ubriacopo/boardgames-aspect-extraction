{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T15:36:56.533233Z",
     "start_time": "2024-11-20T15:36:56.531185Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Generation\n",
    "Our dataset is a corpus of reviews scrapped from the BGG API. <br /> \n",
    "In order to download the comments we make use of the ```bgg_corpus_service.py``` content."
   ],
   "id": "dbc6de67c270e005"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "BGG Does not directly provide a way to list all the games it has in archive therefore we used a dump created by the community (2024-08-18).",
   "id": "a4b9c9e4a84a36cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:36:56.535674Z",
     "start_time": "2024-11-20T15:36:56.534116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# /resources/2024-08-18.csv\n",
    "corpus_file = \"../data/corpus.preprocessed.csv\""
   ],
   "id": "f6c2596f30f3030c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:37:41.203151Z",
     "start_time": "2024-11-20T15:37:41.062322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import core.utils as utils\n",
    "import core.embeddings as embeddings\n",
    "\n",
    "embeddings_model = embeddings.WordEmbedding(\n",
    "    utils.LoadCorpusUtility(), max_vocab_size=10000, embedding_size=128,\n",
    "    target_model_file=\"./../data/word-embeddings.model\", corpus_file=corpus_file\n",
    ")"
   ],
   "id": "f3768d3e3077cd5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Custom Dataloaders Definitions\n",
    "To train the model we require a way to get elements of our dataset. I designed 3 classes for this:"
   ],
   "id": "c3a49e3e02abe587"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Without preprocessing on dataset: 379211268 <br />\n",
    "If the dataset is processed already: 677671688 (Twice the size) <br />"
   ],
   "id": "88fd8fecaff7c6c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PositiveNegativeCommentGeneratorDataset",
   "id": "bbe1db3e4a470c03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:37:45.092443Z",
     "start_time": "2024-11-20T15:37:42.454288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.dataset import PositiveNegativeCommentGeneratorDataset\n",
    "\n",
    "embeddings_model.load_model()\n",
    "embeddings_model.get_vocab()\n",
    "vocabulary = embeddings_model.model.wv.key_to_index\n",
    "\n",
    "ds = PositiveNegativeCommentGeneratorDataset(\"./../data/corpus.preprocessed.csv\", vocabulary, 10)"
   ],
   "id": "35bf3e211ffacf6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2Vec object from ../data/word-embeddings.model\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': '../data/word-embeddings.model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loading wv recursively from ../data/word-embeddings.model.wv.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': '../data/word-embeddings.model', 'datetime': '2024-11-20T16:37:42.477190', 'gensim': '4.3.3', 'python': '3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0]', 'platform': 'Linux-6.8.0-48-generic-x86_64-with-glibc2.39', 'event': 'loaded'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "354cfc5296dc4f93a0a73275ea9901ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T15:37:50.686539Z",
     "start_time": "2024-11-20T15:37:50.684009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "lazy_dataloader = DataLoader(ds, batch_size=32, shuffle=True, collate_fn=lambda x: x)"
   ],
   "id": "6dab4b179d654a7a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ddbba5ea8305cbd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
