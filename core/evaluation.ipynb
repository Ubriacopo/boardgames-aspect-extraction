{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:01.094304Z",
     "start_time": "2024-12-21T18:34:01.090815Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = \"torch\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a24a0908495f4bc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Kickstarter Less Dataset (256k)\n",
   "id": "d52c676c461ef740"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:10.919370Z",
     "start_time": "2024-12-21T18:34:09.618829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from train import AbaeModelConfiguration\n",
    "from core.train import AbaeModelManager\n",
    "\n",
    "config = AbaeModelConfiguration(\n",
    "    corpus_file=\"../data/processed-dataset/full/64k.preprocessed.csv\",\n",
    "    model_name=\"abae.full.64k\", aspect_size=16\n",
    ")\n",
    "\n",
    "manager = AbaeModelManager(config)"
   ],
   "id": "4af0ba69460037d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80286 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81a451ae5529411095ef64f2ed98c1c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80286 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc39b18dd7a841ad80a62fb078f100d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2Vec object from output\\abae.full.64k.embeddings.keras\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'output\\\\abae.full.64k.embeddings.keras', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loading wv recursively from output\\abae.full.64k.embeddings.keras.wv.* with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': 'output\\\\abae.full.64k.embeddings.keras', 'datetime': '2024-12-21T19:34:10.904741', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:14.394162Z",
     "start_time": "2024-12-21T18:34:14.319861Z"
    }
   },
   "cell_type": "code",
   "source": "inference_model = manager.prepare_evaluation_model()",
   "id": "a615c99f728276ec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\core\\layer.py:126: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super(WeightedAspectEmb, self).__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:15.786601Z",
     "start_time": "2024-12-21T18:34:15.782601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "#word_emb = inference_model.get_layer('word_embedding').weights[0]\n",
    "word_emb = inference_model.get_layer('word_embedding').weights[0].value.data\n",
    "#word_emb = torch.from_numpy(word_emb)\n",
    "\n",
    "word_emb.shape"
   ],
   "id": "5319f9c68c632e39",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9004, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:16.849053Z",
     "start_time": "2024-12-21T18:34:16.846203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aspect_embeddings = inference_model.get_layer('weighted_aspect_emb').W\n",
    "vocab_inv = manager.embedding_model.model.wv.index_to_key"
   ],
   "id": "b729faf80b9d3b09",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:17.364868Z",
     "start_time": "2024-12-21T18:34:17.361117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.evaluation import normalize_embedding_matrix\n",
    "\n",
    "word_emb = normalize_embedding_matrix(word_emb)\n",
    "aspect_embeddings = normalize_embedding_matrix(aspect_embeddings)"
   ],
   "id": "44b761048a98c802",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:34:18.089821Z",
     "start_time": "2024-12-21T18:34:18.014605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.evaluation import extract_top_k_words_of_aspect\n",
    "\n",
    "aspects_top_k_words = [extract_top_k_words_of_aspect(a, word_emb, vocab_inv) for a in aspect_embeddings]"
   ],
   "id": "6467c03e5c3b055d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  legendary (0.4351903200149536)\n",
      "Word:  marvel (0.42146116495132446)\n",
      "Word:  include (0.41859087347984314)\n",
      "Word:  promos (0.40995022654533386)\n",
      "Word:  universe (0.4064077138900757)\n",
      "Word:  cards (0.3850122392177582)\n",
      "Word:  expansions (0.3809184432029724)\n",
      "Word:  unmatched (0.38064125180244446)\n",
      "Word:  north (0.37879279255867004)\n",
      "Word:  expansion (0.37542006373405457)\n",
      "Word:  w/ (0.37347477674484253)\n",
      "Word:  ✓ (0.36681437492370605)\n",
      "Word:  <game_name> (0.36548852920532227)\n",
      "Word:  promo (0.36144232749938965)\n",
      "Word:  shrink (0.3540777862071991)\n",
      "Word:  american (0.3519633412361145)\n",
      "Word:  flight (0.3502519726753235)\n",
      "Word:  pledge (0.34722787141799927)\n",
      "Word:  hill (0.3468876779079437)\n",
      "Word:  premium (0.346232533454895)\n",
      "Word:  wars (0.34497418999671936)\n",
      "Word:  exp (0.339688777923584)\n",
      "Word:  cthulhu (0.33938536047935486)\n",
      "Word:  wing (0.33663520216941833)\n",
      "Word:  european (0.33345741033554077)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  factor (0.3758470118045807)\n",
      "Word:  ★ (0.35865703225135803)\n",
      "Word:  mouse (0.34216079115867615)\n",
      "Word:  horror (0.34192225337028503)\n",
      "Word:  skill (0.33342620730400085)\n",
      "Word:  deduction (0.327006459236145)\n",
      "Word:  ⬜ (0.3264622688293457)\n",
      "Word:  ⬛ (0.32595884799957275)\n",
      "Word:  cat (0.32443463802337646)\n",
      "Word:  heavily (0.3128024637699127)\n",
      "Word:  theme (0.30860334634780884)\n",
      "Word:  luck (0.30107754468917847)\n",
      "Word:  event (0.2981778681278229)\n",
      "Word:  social (0.2961808741092682)\n",
      "Word:  mitigation (0.29478514194488525)\n",
      "Word:  attack (0.2913769781589508)\n",
      "Word:  runaway (0.29131975769996643)\n",
      "Word:  tea (0.2898368239402771)\n",
      "Word:  cup (0.28578436374664307)\n",
      "Word:  evil (0.28113529086112976)\n",
      "Word:  lucky (0.27889785170555115)\n",
      "Word:  leather (0.2781541347503662)\n",
      "Word:  attacker (0.2771456837654114)\n",
      "Word:  bash (0.27712151408195496)\n",
      "Word:  wing (0.2757084369659424)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  impossible (0.6235599517822266)\n",
      "Word:  answer (0.5764040946960449)\n",
      "Word:  mistake (0.5720452070236206)\n",
      "Word:  clue (0.5603495836257935)\n",
      "Word:  correctly (0.553424060344696)\n",
      "Word:  possible (0.5436513423919678)\n",
      "Word:  adapt (0.5425494909286499)\n",
      "Word:  predict (0.5298137068748474)\n",
      "Word:  cause (0.5211902260780334)\n",
      "Word:  survive (0.518699586391449)\n",
      "Word:  eliminate (0.51806640625)\n",
      "Word:  correct (0.5150048136711121)\n",
      "Word:  paralysis (0.5078679919242859)\n",
      "Word:  deduce (0.5024728775024414)\n",
      "Word:  analysis (0.4973960518836975)\n",
      "Word:  guess (0.4945260286331177)\n",
      "Word:  constantly (0.4910178780555725)\n",
      "Word:  shot (0.48719334602355957)\n",
      "Word:  situation (0.48514682054519653)\n",
      "Word:  parse (0.4844626784324646)\n",
      "Word:  forget (0.4827207028865814)\n",
      "Word:  solution (0.4819216728210449)\n",
      "Word:  skip (0.4802326560020447)\n",
      "Word:  safe (0.47839269042015076)\n",
      "Word:  beginning (0.4762279689311981)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  position (0.46543946862220764)\n",
      "Word:  advantage (0.4476274251937866)\n",
      "Word:  careful (0.44011151790618896)\n",
      "Word:  phase (0.4395425617694855)\n",
      "Word:  occur (0.42382538318634033)\n",
      "Word:  situation (0.41339847445487976)\n",
      "Word:  beginning (0.40783169865608215)\n",
      "Word:  simultaneously (0.40415558218955994)\n",
      "Word:  resolve (0.40208953619003296)\n",
      "Word:  lead (0.4020007252693176)\n",
      "Word:  planning (0.3999873697757721)\n",
      "Word:  analysis (0.39934784173965454)\n",
      "Word:  paralysis (0.39932721853256226)\n",
      "Word:  predict (0.39816486835479736)\n",
      "Word:  key (0.39791005849838257)\n",
      "Word:  reveal (0.39569664001464844)\n",
      "Word:  consequence (0.3949849009513855)\n",
      "Word:  constant (0.3941294252872467)\n",
      "Word:  determine (0.39332693815231323)\n",
      "Word:  allow (0.3897929787635803)\n",
      "Word:  trump (0.38597729802131653)\n",
      "Word:  prepare (0.3804096281528473)\n",
      "Word:  information (0.37796124815940857)\n",
      "Word:  slowly (0.3778976798057556)\n",
      "Word:  plan (0.3775019645690918)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  plastic (0.6456001400947571)\n",
      "Word:  3d (0.6138546466827393)\n",
      "Word:  metal (0.597025454044342)\n",
      "Word:  tray (0.580610454082489)\n",
      "Word:  playmat (0.573312520980835)\n",
      "Word:  insert (0.5616588592529297)\n",
      "Word:  premium (0.5534147620201111)\n",
      "Word:  wooden (0.5433918833732605)\n",
      "Word:  etsy (0.5407212376594543)\n",
      "Word:  organizer (0.5397254824638367)\n",
      "Word:  custom (0.5354172587394714)\n",
      "Word:  matte (0.5340874791145325)\n",
      "Word:  blue (0.5339169502258301)\n",
      "Word:  mat (0.5137964487075806)\n",
      "Word:  storage (0.5108399987220764)\n",
      "Word:  sleeve (0.5032050013542175)\n",
      "Word:  cardboard (0.5018106698989868)\n",
      "Word:  printed (0.501346230506897)\n",
      "Word:  neoprene (0.49444130063056946)\n",
      "Word:  token (0.4935249984264374)\n",
      "Word:  gamegenic (0.48736631870269775)\n",
      "Word:  green (0.48341989517211914)\n",
      "Word:  ks (0.48100972175598145)\n",
      "Word:  promos (0.47919490933418274)\n",
      "Word:  sleeved (0.47893768548965454)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  knizia (0.35348591208457947)\n",
      "Word:  old (0.3399714231491089)\n",
      "Word:  remind (0.3165431320667267)\n",
      "Word:  classic (0.2993350028991699)\n",
      "Word:  deliver (0.29748058319091797)\n",
      "Word:  good (0.28856974840164185)\n",
      "Word:  <game_name> (0.2804890275001526)\n",
      "Word:  reiner (0.27671897411346436)\n",
      "Word:  magic (0.27407369017601013)\n",
      "Word:  west (0.2724944055080414)\n",
      "Word:  school (0.2684439718723297)\n",
      "Word:  games (0.2656044363975525)\n",
      "Word:  nice (0.26302310824394226)\n",
      "Word:  favourite (0.2581188380718231)\n",
      "Word:  park (0.25408557057380676)\n",
      "Word:  spatial (0.2536492347717285)\n",
      "Word:  modern (0.2498895823955536)\n",
      "Word:  conversion (0.24731789529323578)\n",
      "Word:  cute (0.24712491035461426)\n",
      "Word:  neat (0.23335692286491394)\n",
      "Word:  drafting (0.23060926795005798)\n",
      "Word:  trading (0.22828052937984467)\n",
      "Word:  economic (0.22811542451381683)\n",
      "Word:  typical (0.2269984930753708)\n",
      "Word:  network (0.22474326193332672)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  9 (0.29299718141555786)\n",
      "Word:  progression (0.280764639377594)\n",
      "Word:  update (0.2722106873989105)\n",
      "Word:  6 (0.25993481278419495)\n",
      "Word:  horrible (0.2590144872665405)\n",
      "Word:  7 (0.2552582621574402)\n",
      "Word:  8 (0.25127026438713074)\n",
      "Word:  downgrade (0.2486894279718399)\n",
      "Word:  history (0.24552948772907257)\n",
      "Word:  edit (0.23502154648303986)\n",
      "Word:  8.5 (0.23347875475883484)\n",
      "Word:  review (0.22479212284088135)\n",
      "Word:  8,5 (0.2231568992137909)\n",
      "Word:  boring (0.22203180193901062)\n",
      "Word:  like (0.218123197555542)\n",
      "Word:  7/10 (0.21200823783874512)\n",
      "Word:  reflect (0.21096545457839966)\n",
      "Word:  bland (0.21040287613868713)\n",
      "Word:  theme (0.20962673425674438)\n",
      "Word:  6.5 (0.20922833681106567)\n",
      "Word:  6/10 (0.20776624977588654)\n",
      "Word:  artwork (0.20668897032737732)\n",
      "Word:  vs. (0.20365671813488007)\n",
      "Word:  design (0.20144814252853394)\n",
      "Word:  watch (0.20097212493419647)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  fun (0.4883356988430023)\n",
      "Word:  dungeon (0.4476403295993805)\n",
      "Word:  super (0.393668532371521)\n",
      "Word:  crawl (0.36734098196029663)\n",
      "Word:  crawler (0.36016523838043213)\n",
      "Word:  monster (0.33754926919937134)\n",
      "Word:  scratch (0.33304306864738464)\n",
      "Word:  satisfying (0.3295244872570038)\n",
      "Word:  itch (0.3232535421848297)\n",
      "Word:  challenging (0.3137713670730591)\n",
      "Word:  paced (0.3125608265399933)\n",
      "Word:  puzzle (0.31192266941070557)\n",
      "Word:  logic (0.3118288218975067)\n",
      "Word:  hearted (0.2919546067714691)\n",
      "Word:  funny (0.28395822644233704)\n",
      "Word:  fast (0.2797585129737854)\n",
      "Word:  quick (0.2789709270000458)\n",
      "Word:  spatial (0.27778539061546326)\n",
      "Word:  cute (0.2776682376861572)\n",
      "Word:  race (0.27302947640419006)\n",
      "Word:  dexterity (0.27225157618522644)\n",
      "Word:  coop (0.27107420563697815)\n",
      "Word:  combo (0.2700887620449066)\n",
      "Word:  mystery (0.2657681703567505)\n",
      "Word:  thinky (0.2641904056072235)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  edit (0.47336891293525696)\n",
      "Word:  essen (0.41756653785705566)\n",
      "Word:  year (0.399960994720459)\n",
      "Word:  ago (0.38968604803085327)\n",
      "Word:  arrive (0.38282498717308044)\n",
      "Word:  update (0.38239413499832153)\n",
      "Word:  <date> (0.38077986240386963)\n",
      "Word:  sale (0.3699610233306885)\n",
      "Word:  copy (0.3698039650917053)\n",
      "Word:  rating (0.3691793382167816)\n",
      "Word:  sell (0.3603896498680115)\n",
      "Word:  6.5 (0.3589557111263275)\n",
      "Word:  hr (0.3552369177341461)\n",
      "Word:  7.0 (0.35090339183807373)\n",
      "Word:  bgg (0.3489741086959839)\n",
      "Word:  7.5 (0.3484978675842285)\n",
      "Word:  traded (0.3481421172618866)\n",
      "Word:  got (0.34729933738708496)\n",
      "Word:  own (0.3431656062602997)\n",
      "Word:  review (0.34029704332351685)\n",
      "Word:  recently (0.33819010853767395)\n",
      "Word:  currently (0.33556362986564636)\n",
      "Word:  3rd (0.33469611406326294)\n",
      "Word:  release (0.3261043131351471)\n",
      "Word:  receive (0.32440268993377686)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  manipulate (0.5069802403450012)\n",
      "Word:  gain (0.50453120470047)\n",
      "Word:  gear (0.4986531138420105)\n",
      "Word:  passenger (0.49758800864219666)\n",
      "Word:  contract (0.4972130060195923)\n",
      "Word:  income (0.4898255169391632)\n",
      "Word:  affect (0.48260051012039185)\n",
      "Word:  trigger (0.47786232829093933)\n",
      "Word:  endgame (0.477399617433548)\n",
      "Word:  technology (0.47178518772125244)\n",
      "Word:  optimize (0.4688871204853058)\n",
      "Word:  method (0.462240070104599)\n",
      "Word:  incentive (0.461922287940979)\n",
      "Word:  e.g. (0.4614730477333069)\n",
      "Word:  efficiency (0.45903080701828003)\n",
      "Word:  vary (0.4556770324707031)\n",
      "Word:  maximize (0.45475420355796814)\n",
      "Word:  currency (0.45166388154029846)\n",
      "Word:  direct (0.44898438453674316)\n",
      "Word:  flexibility (0.44574934244155884)\n",
      "Word:  vp (0.44473180174827576)\n",
      "Word:  employ (0.4441821277141571)\n",
      "Word:  increase (0.44342586398124695)\n",
      "Word:  nation (0.44325879216194153)\n",
      "Word:  strength (0.4431796967983246)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  incredible (0.4065099060535431)\n",
      "Word:  excellent (0.39760324358940125)\n",
      "Word:  wonderful (0.39621952176094055)\n",
      "Word:  great (0.38123878836631775)\n",
      "Word:  fantastic (0.3726217746734619)\n",
      "Word:  replayability (0.3658863604068756)\n",
      "Word:  amazing (0.3615887463092804)\n",
      "Word:  variability (0.3399418294429779)\n",
      "Word:  beautiful (0.33909693360328674)\n",
      "Word:  gorgeous (0.32535290718078613)\n",
      "Word:  solid (0.3216850757598877)\n",
      "Word:  rich (0.32160118222236633)\n",
      "Word:  notch (0.3212924599647522)\n",
      "Word:  8/10 (0.31530866026878357)\n",
      "Word:  decent (0.3149096965789795)\n",
      "Word:  superb (0.311195969581604)\n",
      "Word:  lovely (0.30293479561805725)\n",
      "Word:  engaging (0.30288249254226685)\n",
      "Word:  replay (0.30143994092941284)\n",
      "Word:  terrific (0.3011679947376251)\n",
      "Word:  amazingly (0.300091952085495)\n",
      "Word:  integration (0.2999672591686249)\n",
      "Word:  stunning (0.29967033863067627)\n",
      "Word:  presentation (0.2928677797317505)\n",
      "Word:  aesthetic (0.2911195456981659)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  graphic (0.5362976789474487)\n",
      "Word:  iconography (0.5222151875495911)\n",
      "Word:  overly (0.49908289313316345)\n",
      "Word:  visually (0.4893568456172943)\n",
      "Word:  elegant (0.4878850281238556)\n",
      "Word:  clean (0.483352392911911)\n",
      "Word:  fiddly (0.46058791875839233)\n",
      "Word:  intuitive (0.4505281448364258)\n",
      "Word:  ruleset (0.4494868516921997)\n",
      "Word:  visual (0.44801485538482666)\n",
      "Word:  presentation (0.447784960269928)\n",
      "Word:  mechanically (0.4364498555660248)\n",
      "Word:  sound (0.4283972382545471)\n",
      "Word:  streamlined (0.4283277988433838)\n",
      "Word:  extremely (0.42566046118736267)\n",
      "Word:  complicated (0.4252637028694153)\n",
      "Word:  somewhat (0.4251960515975952)\n",
      "Word:  albeit (0.42420774698257446)\n",
      "Word:  rulebook (0.41779351234436035)\n",
      "Word:  confusing (0.41708433628082275)\n",
      "Word:  slightly (0.4134749174118042)\n",
      "Word:  artwork (0.4119507074356079)\n",
      "Word:  elegance (0.4057110548019409)\n",
      "Word:  incredibly (0.4053470492362976)\n",
      "Word:  illustration (0.4039224684238434)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  <UNK> (0.5778184533119202)\n",
      "Word:  gift (0.4937986731529236)\n",
      "Word:  birthday (0.4477003812789917)\n",
      "Word:  250 (0.4415363073348999)\n",
      "Word:  2x (0.4345434010028839)\n",
      "Word:  uk (0.41897958517074585)\n",
      "Word:  gencon (0.4079974293708801)\n",
      "Word:  local (0.4072701930999756)\n",
      "Word:  sale (0.40154096484184265)\n",
      "Word:  receive (0.4013720750808716)\n",
      "Word:  amazon (0.3991817235946655)\n",
      "Word:  finefield (0.3986407518386841)\n",
      "Word:  donate (0.39577996730804443)\n",
      "Word:  0/1 (0.39244404435157776)\n",
      "Word:  1x (0.39195120334625244)\n",
      "Word:  2021 (0.39189717173576355)\n",
      "Word:  1/0 (0.3906727731227875)\n",
      "Word:  2018 (0.38337674736976624)\n",
      "Word:  traded (0.3781110346317291)\n",
      "Word:  0/2 (0.3774586319923401)\n",
      "Word:  2023 (0.37476035952568054)\n",
      "Word:  vfm (0.3735389709472656)\n",
      "Word:  stark (0.37323689460754395)\n",
      "Word:  46 (0.37212830781936646)\n",
      "Word:  shipping (0.37168270349502563)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  convert (0.4532470405101776)\n",
      "Word:  activate (0.44400790333747864)\n",
      "Word:  spread (0.43272969126701355)\n",
      "Word:  gather (0.42972978949546814)\n",
      "Word:  region (0.4278397560119629)\n",
      "Word:  station (0.4200967252254486)\n",
      "Word:  connect (0.41673919558525085)\n",
      "Word:  dig (0.4159243106842041)\n",
      "Word:  meeple (0.41547873616218567)\n",
      "Word:  place (0.4123845398426056)\n",
      "Word:  grab (0.41165393590927124)\n",
      "Word:  stack (0.41163164377212524)\n",
      "Word:  city (0.41078829765319824)\n",
      "Word:  collect (0.41064977645874023)\n",
      "Word:  train (0.40975067019462585)\n",
      "Word:  construct (0.40735378861427307)\n",
      "Word:  pyramid (0.40711724758148193)\n",
      "Word:  planet (0.4061315059661865)\n",
      "Word:  tech (0.40331435203552246)\n",
      "Word:  structure (0.40304720401763916)\n",
      "Word:  disk (0.402325838804245)\n",
      "Word:  island (0.40138211846351624)\n",
      "Word:  rail (0.401268869638443)\n",
      "Word:  technology (0.4007323682308197)\n",
      "Word:  build (0.4005466103553772)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  young (0.5110191106796265)\n",
      "Word:  alike (0.5104610919952393)\n",
      "Word:  gamer (0.5092489719390869)\n",
      "Word:  parent (0.5091879963874817)\n",
      "Word:  casual (0.5071526169776917)\n",
      "Word:  mood (0.48902150988578796)\n",
      "Word:  adult (0.4791896939277649)\n",
      "Word:  hobby (0.46925240755081177)\n",
      "Word:  child (0.45786723494529724)\n",
      "Word:  evening (0.4554024338722229)\n",
      "Word:  friend (0.44155871868133545)\n",
      "Word:  crowd (0.4376337230205536)\n",
      "Word:  boardgame (0.4359794557094574)\n",
      "Word:  willing (0.4205743074417114)\n",
      "Word:  laugh (0.41901734471321106)\n",
      "Word:  friendly (0.4162948727607727)\n",
      "Word:  audience (0.41623833775520325)\n",
      "Word:  gaming (0.4135932922363281)\n",
      "Word:  hardcore (0.41134577989578247)\n",
      "Word:  absolute (0.40969690680503845)\n",
      "Word:  request (0.4067157208919525)\n",
      "Word:  heavy (0.40529459714889526)\n",
      "Word:  regularly (0.40299344062805176)\n",
      "Word:  perfect (0.39995458722114563)\n",
      "Word:  interested (0.3975663185119629)\n",
      "\n",
      "Given aspect most representative words are:\n",
      "Word:  players (0.6110565662384033)\n",
      "Word:  60 (0.5877384543418884)\n",
      "Word:  120 (0.5808404088020325)\n",
      "Word:  min (0.559714674949646)\n",
      "Word:  minutes (0.5593966841697693)\n",
      "Word:  2–4 (0.5363349914550781)\n",
      "Word:  2 (0.5297719240188599)\n",
      "Word:  ♥ (0.5288703441619873)\n",
      "Word:  90 (0.5261919498443604)\n",
      "Word:  180 (0.5256302952766418)\n",
      "Word:  14 (0.5252522826194763)\n",
      "Word:  best (0.5213305950164795)\n",
      "Word:  45 (0.5184600353240967)\n",
      "Word:  t (0.5176173448562622)\n",
      "Word:  4 (0.5161181092262268)\n",
      "Word:  p (0.515658974647522)\n",
      "Word:  w (0.5142961144447327)\n",
      "Word:  1 (0.5113027095794678)\n",
      "Word:  ❦ (0.506692111492157)\n",
      "Word:  1–4 (0.5044089555740356)\n",
      "Word:  35 (0.502764880657196)\n",
      "Word:  5p (0.5025696754455566)\n",
      "Word:  5 (0.4979822337627411)\n",
      "Word:  | (0.49434372782707214)\n",
      "Word:  m (0.4891057014465332)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![title](./../resources/umass.png)\n",
   "id": "c35ff70d0f15833d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset generation",
   "id": "b6bbdc3d8587ddd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T18:55:50.010650Z",
     "start_time": "2024-12-21T18:55:48.951268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dataset\n",
    "\n",
    "vocabulary = manager.embedding_model.model.wv.key_to_index\n",
    "ds = dataset.PositiveNegativeCommentGeneratorDataset(\n",
    "    vocabulary=vocabulary, csv_dataset_path=\"../data/processed-dataset/full/64k.preprocessed.csv\", negative_size=15\n",
    ")"
   ],
   "id": "9455357c1b446cee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file: ../data/processed-dataset/full/64k.preprocessed.csv\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/80286 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13ff9f907ce747c2a48c1a28ad5356b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "Max sequence length is:  206 . The limit is set to 256 tokens.\n",
      "Padding sequences to length (256).\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T19:26:31.859267Z",
     "start_time": "2024-12-21T18:55:51.166421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from core.evaluation import coherence\n",
    "\n",
    "print(manager.embedding_model.model.wv.index_to_key[13])\n",
    "# todo pass indexwords\n",
    "for i in range(len(aspects_top_k_words)):\n",
    "    i_th_aspect_top_k = aspects_top_k_words[i][0:10]\n",
    "    word_indexes = list(map(lambda x: x[2], i_th_aspect_top_k))\n",
    "    print(word_indexes)\n",
    "    print(coherence(word_indexes, ds))"
   ],
   "id": "41b7a4f894b6ba59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lot\n",
      "[tensor(1099, device='cuda:0'), tensor(986, device='cuda:0'), tensor(152, device='cuda:0'), tensor(1749, device='cuda:0'), tensor(1247, device='cuda:0'), tensor(1082, device='cuda:0'), tensor(2420, device='cuda:0'), tensor(1468, device='cuda:0'), tensor(1991, device='cuda:0'), tensor(49, device='cuda:0')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m word_indexes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;241m2\u001B[39m], i_th_aspect_top_k))\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(word_indexes)\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcoherence\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword_indexes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mds\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\core\\evaluation.py:40\u001B[0m, in \u001B[0;36mcoherence\u001B[1;34m(top_n_words, corpus)\u001B[0m\n\u001B[0;32m     38\u001B[0m document_frequency_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m top_n_words:\n\u001B[1;32m---> 40\u001B[0m     document_frequency_values[w] \u001B[38;5;241m=\u001B[39m \u001B[43mdocument_frequency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Exponential complexity. We can optimize this.\u001B[39;00m\n\u001B[0;32m     43\u001B[0m document_co_frequency_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\core\\evaluation.py:61\u001B[0m, in \u001B[0;36mdocument_frequency\u001B[1;34m(a, corpus)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdocument_frequency\u001B[39m(a: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mint\u001B[39m, corpus: PositiveNegativeCommentGeneratorDataset) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m---> 61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcorpus\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mvalue_counts()\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4790\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4791\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4799\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4800\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4915\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4916\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4918\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4922\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m-> 4924\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\core\\evaluation.py:61\u001B[0m, in \u001B[0;36mdocument_frequency.<locals>.<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdocument_frequency\u001B[39m(a: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mint\u001B[39m, corpus: PositiveNegativeCommentGeneratorDataset) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m---> 61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m corpus\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: a \u001B[38;5;129;01min\u001B[39;00m x)\u001B[38;5;241m.\u001B[39mvalue_counts()\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4.4. Word2vec Coherence Score\n",
    "[https://www.baeldung.com/cs/topic-modeling-coherence-score#4-word2vec-coherence-score"
   ],
   "id": "4f1ae0bad6256629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cd183c0812b5d507",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
