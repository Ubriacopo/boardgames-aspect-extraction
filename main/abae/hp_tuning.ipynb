{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://www.reddit.com/r/computervision/comments/kfhc3u/how_does_one_fine_tune_cnn_hyperparameter_when/\n",
    "# Guarda tipo di genetic algorithms (YOLO)\n",
    "# Tuning hyperparameters in the context of large datasets can be a problem. I should investigate further."
   ],
   "id": "fa8ce45f0db7e5d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T07:10:05.049146Z",
     "start_time": "2025-03-17T07:10:04.544492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "from uuid import uuid4\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from main.hp_tuning import UniqueParametersConfigFsGenerator, RandomTunableOffsetParameter, \\\n",
    "    RandomTunableDiscreteParameter\n",
    "\n",
    "seed = 2077  # Wake up samurai\n",
    "config_path = \"./output/config\"\n",
    "config_gen = UniqueParametersConfigFsGenerator(patience=100, seen_configurations_path=config_path)\n",
    "\n",
    "# Parameters definition:\n",
    "embedding_sizes = [100, 200, 300, 400]\n",
    "config_gen.add_parameter('embedding_size', RandomTunableDiscreteParameter(values_list=embedding_sizes, seed=seed))\n",
    "config_gen.add_parameter('aspect_size', RandomTunableOffsetParameter(value_range=(7, 20), step=1, seed=seed))\n",
    "# config_gen.add_parameter('negative_sample_size', RandomTunableOffsetParameter(value_range=(10, 20), step=5, seed=seed))\n",
    "config_gen.add_parameter('epochs', RandomTunableOffsetParameter(value_range=(7, 15), step=2, seed=seed))\n",
    "\n",
    "np.random.seed(seed)\n",
    "learning_rates = (10 ** np.random.uniform(-5, -2, 10)).tolist()\n",
    "\n",
    "print(\"Possible learning rates are: \")\n",
    "pprint(learning_rates)\n",
    "\n",
    "config_gen.add_parameter(\"learning_rate\", RandomTunableDiscreteParameter(values_list=learning_rates, seed=seed))\n",
    "config_gen.add_parameter(\"batch_size\", RandomTunableDiscreteParameter(values_list=[128, 256, 512, 1024], seed=seed))"
   ],
   "id": "16119bbf7a6617e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible learning rates are: \n",
      "[0.00034307925427065264,\n",
      " 1.528848384756386e-05,\n",
      " 0.0009812379995669137,\n",
      " 2.7095598297631782e-05,\n",
      " 0.007306153347321277,\n",
      " 0.002043186796816812,\n",
      " 0.0006166794665094792,\n",
      " 0.0055237549202012005,\n",
      " 0.0022376672226856378,\n",
      " 0.0020646784735470726]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I'd love to make K-fold CV but for time constraints it is just not viable. <br>\n",
    "Since the dataset is big enough we resort to the classic validation set."
   ],
   "id": "1573323b47027e2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T07:10:05.073151Z",
     "start_time": "2025-03-17T07:10:05.070152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "logging.disable()\n",
    "logging.disable(logging.DEBUG)\n",
    "logging.disable(logging.INFO)"
   ],
   "id": "5845a49b1f9a04c0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-17T07:10:05.096489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from main.abae.model_manager import ABAEManager\n",
    "from main.abae.config import ABAEManagerConfig\n",
    "import pandas as pd\n",
    "\n",
    "corpus = pd.read_csv(\"../dataset/output/default/pre_processed.310k.csv\")\n",
    "split_dataset = np.array_split(corpus, 4)\n",
    "\n",
    "validation_split = split_dataset[0]  # On what to compute the validation metrics 25% of ds for validation\n",
    "train = pd.concat([split_dataset[index] for index in range(len(split_dataset)) if index != 0])\n",
    "\n",
    "results = []\n",
    "\n",
    "file_path = \"./output/config/abae_configurations_results.json\"\n",
    "if Path(file_path).is_file():\n",
    "    results = results + json.load(open(file_path))\n",
    "\n",
    "# This script can be re-run as often as desired as the history is persisted\n",
    "for i in range(20):  # How many different configurations we want to see\n",
    "    config = next(config_gen)\n",
    "    run_id = uuid4()\n",
    "\n",
    "    print(f\"Running configuration = {config} ({i + 1}/10)\")\n",
    "\n",
    "    abae_config = ABAEManagerConfig.from_configuration(f\"{run_id}\", config)\n",
    "    abae_manager = ABAEManager.from_scratch(abae_config, train, override=True)\n",
    "\n",
    "    # Now we train:\n",
    "    history, _ = abae_manager.train(train, verbose=2)\n",
    "    # Evaluation with inverse order to avoid re-computing the aspects\n",
    "    run_result = abae_manager.evaluate([20, 10, 5, 3], validation_split)\n",
    "    run_result['history'] = history.history['loss']\n",
    "    run_result['config'] = config\n",
    "\n",
    "    results.append(run_result)\n",
    "    json.dump(results, open(file_path, 'w'))"
   ],
   "id": "99dc10de89aa072b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's analyze the results:",
   "id": "c5f80f93a8b79008"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = \"./output/config/abae_configurations_results.json\"\n",
    "pd.DataFrame(json.load(open(file_path)))"
   ],
   "id": "be094694a25d3d84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.DataFrame(json.load(open(file_path)))\n",
    "structured_data = {'cv_coh': [], 'npmi_coh': [], 'top': [], 'max_margin_loss': [], 'id': [],\n",
    "                   'plot_npmi_coh': [], 'embedding_size': [], 'aspect_size': [], 'learning_rate': [], 'batch_size': [],\n",
    "                   'epochs': []}\n",
    "for index, row in data.iterrows():\n",
    "    for i in [3, 10, 25]:\n",
    "        structured_data['id'].append(row['id'])\n",
    "\n",
    "        structured_data['embedding_size'].append(row['config']['embedding_size'])\n",
    "        structured_data['aspect_size'].append(row['config']['aspect_size'])\n",
    "        structured_data['learning_rate'].append(row['config']['learning_rate'])\n",
    "        structured_data['batch_size'].append(row['config']['batch_size'])\n",
    "        structured_data['epochs'].append(row['config']['epochs'])\n",
    "        structured_data['cv_coh'].append(row['cv_coh'][str(i)])\n",
    "        structured_data['npmi_coh'].append(row['npmi_coh'][str(i)])\n",
    "        structured_data['plot_npmi_coh'].append(row['npmi_coh'][str(i)] + 1)\n",
    "        structured_data['top'].append(i)\n",
    "        structured_data['max_margin_loss'].append(row['max_margin_loss'][1])\n",
    "\n",
    "data = pd.DataFrame(structured_data)"
   ],
   "id": "f4618b5c7c8230d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.groupby(['id']).sum()",
   "id": "d113ff7a1450d130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    data, x=\"max_margin_loss\", y=\"cv_coh\", symbol=\"top\", color='id',\n",
    "    size='plot_npmi_coh',\n",
    "    hover_data=['npmi_coh', 'embedding_size', 'aspect_size', 'epochs', 'learning_rate', 'batch_size'],\n",
    "    title='Hyperparameter Tuning Results',\n",
    ")\n",
    "fig.show()"
   ],
   "id": "512708929f5698ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The default proposed model parameters for ABAE seem to be fitting for our domain as well\n",
    "# We take the default one and"
   ],
   "id": "8b01b709c7732a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# todo valuta se guardare 537398ce-4642-4e83-8073-ee795b63f1c1 che ha top3 pirma di top 25\n",
    "configs = ['31479139-17f6-4f6d-aa8b-494cbc8f183b', '3f192c54-6623-48a7-b01b-2d5019dad186']"
   ],
   "id": "3671a852807d49e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1cef812ff517c244"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.parallel_categories(\n",
    "    data.groupby(['id']).mean(), color='max_margin_loss',\n",
    "    dimensions=['learning_rate', 'batch_size', 'aspect_size', 'embedding_size', 'epochs'],\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "a5cc60770ea6c142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "62be5de3e13b9b52",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
