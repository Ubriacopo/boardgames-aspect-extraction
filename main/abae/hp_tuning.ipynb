{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# https://www.reddit.com/r/computervision/comments/kfhc3u/how_does_one_fine_tune_cnn_hyperparameter_when/\n",
    "# Guarda tipo di genetic algorithms (YOLO)\n",
    "# Tuning hyperparameters in the context of large datasets can be a problem. I should investigate further."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T16:23:38.867325Z",
     "start_time": "2025-03-12T16:23:36.886638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "from uuid import uuid4\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from main.hp_tuning import UniqueParametersConfigFsGenerator, RandomTunableOffsetParameter, \\\n",
    "    RandomTunableDiscreteParameter\n",
    "\n",
    "seed = 1408\n",
    "config_path = \"./output/config\"\n",
    "config_gen = UniqueParametersConfigFsGenerator(patience=10, seen_configurations_path=config_path)\n",
    "\n",
    "# Parameters definition:\n",
    "embedding_sizes = [70, 100, 160, 250, 340, 430]\n",
    "config_gen.add_parameter('embedding_size', RandomTunableDiscreteParameter(values_list=embedding_sizes, seed=seed))\n",
    "config_gen.add_parameter('aspect_size', RandomTunableOffsetParameter(value_range=(7, 20), step=2, seed=seed))\n",
    "config_gen.add_parameter('negative_sample_size', RandomTunableOffsetParameter(value_range=(8, 20), step=2, seed=seed))\n",
    "config_gen.add_parameter('epochs', RandomTunableOffsetParameter(value_range=(5, 15), step=2, seed=seed))\n",
    "\n",
    "np.random.seed(seed)\n",
    "learning_rates = (10 ** np.random.uniform(-5, -3, 10)).tolist()\n",
    "\n",
    "print(\"Possible learning rates are: \")\n",
    "pprint(learning_rates)\n",
    "\n",
    "config_gen.add_parameter(\"learning_rate\", RandomTunableDiscreteParameter(values_list=learning_rates, seed=seed))\n",
    "config_gen.add_parameter(\"batch_size\", RandomTunableDiscreteParameter(values_list=[64, 128, 256, 512, 1024], seed=seed))"
   ],
   "id": "70f5e33eb12cdf47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible learning rates are: \n",
      "[2.8335370004797548e-05,\n",
      " 1.0333211138769892e-05,\n",
      " 0.0004913561444308656,\n",
      " 0.00033015898389246787,\n",
      " 1.1870243521834267e-05,\n",
      " 0.00021625668297372376,\n",
      " 0.00043384811744330364,\n",
      " 0.000198692415919008,\n",
      " 1.2053368306353077e-05,\n",
      " 1.598254695812495e-05]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I'd love to make K-fold CV but for time constraints it is just not viable. <br>\n",
    "Since the dataset is big enough we resort to the classic validation set."
   ],
   "id": "8ade87e75e8b035"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from main.abae.dataset import PositiveNegativeABAEDataset\n",
    "from main.abae.evaluation import ABAEEvaluationProcessor\n",
    "from main.abae.model_manager import ABAEManager\n",
    "from main.abae.config import ABAEManagerConfig\n",
    "import pandas as pd\n",
    "\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.csv\"\n",
    "corpus = pd.read_csv(corpus_path)\n",
    "\n",
    "split_dataset = np.array_split(corpus, 4)\n",
    "\n",
    "validation_split = split_dataset[0]  # On what to compute the validation metrics 25% of ds for validation\n",
    "train = pd.concat([split_dataset[index] for index in range(len(split_dataset)) if index != 0])\n",
    "\n",
    "results = []\n",
    "n_folds = 5\n",
    "\n",
    "tops = [3, 10, 25]\n",
    "\n",
    "# This script can be re-run as often as desired as the history is persisted\n",
    "for i in range(10):  # How many different configurations we want to see\n",
    "    config = next(config_gen)\n",
    "    run_id = uuid4()\n",
    "\n",
    "    print(f\"Running configuration = {config} ({i + 1}/10)\")\n",
    "    run_result = dict(config=config, cv_coh={t: [] for t in tops}, npmi_coh={t: [] for t in tops}, max_margin_loss=[])\n",
    "    abae_config = ABAEManagerConfig.from_configuration(f\"{run_id}\", config)\n",
    "    abae_manager = ABAEManager.from_scratch(abae_config, train, override=True)\n",
    "\n",
    "    # Now we train:\n",
    "    abae_manager.train(train)\n",
    "\n",
    "    # Now for evaluation\n",
    "    # Max margin loss:\n",
    "    vocabulary = abae_manager.generator.emb_model.vocabulary()\n",
    "    max_seq_len = abae_config.max_seq_len\n",
    "    negative_sample_size = abae_config.negative_sample_size\n",
    "    eval_ds = PositiveNegativeABAEDataset(validation_split, vocabulary, max_seq_len, negative_sample_size)\n",
    "\n",
    "    model = abae_manager.get_compiled_model(refresh=False)\n",
    "    run_result['max_margin_loss'] = model.evaluate(DataLoader(eval_ds, batch_size=abae_config.batch_size))\n",
    "\n",
    "    # Coherence metrics evaluation:\n",
    "    processor = ABAEEvaluationProcessor(\n",
    "        abae_manager, validation_split['comments'].swifter.apply(lambda x: x.split(' '))\n",
    "    )\n",
    "    run_result['silhouette_score'] = processor.silhouette_score()\n",
    "\n",
    "    for top in tops:\n",
    "        run_result['cv_coh'][top].append({top: processor.c_v_coherence_model(top_n=top).get_coherence()})\n",
    "        run_result['npmi_coh'][top].append({top: processor.c_npmi_coherence_model(top_n=top).get_coherence()})\n"
   ],
   "id": "e8e684f9df523167",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m134/287\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m3:58\u001B[0m 2s/step - loss: 4.6203 - max_margin_loss: 4.6190"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's analyze the results:",
   "id": "2f8135fd1eadbfc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "26595eb49b7e200b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
