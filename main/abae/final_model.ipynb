{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T14:52:08.120413Z",
     "start_time": "2025-03-21T14:52:01.591682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Base imports to avoid headaches\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from main.abae.config import ABAEManagerConfig\n",
    "import json\n",
    "import pandas as pd\n",
    "from main.abae.model_manager import ABAEManager"
   ],
   "id": "3e521bb599ab26b2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T14:52:11.523904Z",
     "start_time": "2025-03-21T14:52:11.520863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Base corpus references for file\n",
    "corpus = \"../dataset/output/default/pre_processed.310k.csv\"\n",
    "test_corpus_path = \"../dataset/output/default/pre_processed.310k.test.csv\""
   ],
   "id": "8e0e028abe346faf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T14:52:11.994528Z",
     "start_time": "2025-03-21T14:52:11.990527Z"
    }
   },
   "source": "# Now that I did some hyperparameters tuning we try a model and see the results",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T14:52:13.377717Z",
     "start_time": "2025-03-21T14:52:13.361922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Results of hyperparameter tuning are stored here\n",
    "file_path = \"./output/config/abae_configurations_results.json\"\n",
    "\n",
    "configs = [\n",
    "    pd.DataFrame(json.load(open(file_path))).at[11, 'config'],\n",
    "    pd.DataFrame(json.load(open(file_path))).at[20, 'config'],\n",
    "\n",
    "    # These two perform worse but have a lower variance which might result in a more robust solution\n",
    "    pd.DataFrame(json.load(open(file_path))).at[14, 'config'],\n",
    "    pd.DataFrame(json.load(open(file_path))).at[15, 'config'],\n",
    "]"
   ],
   "id": "b0748100697178fa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T14:54:58.626073Z",
     "start_time": "2025-03-21T14:54:58.622813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runs = []\n",
    "# Create runs configurations\n",
    "for i in range(len(configs)):\n",
    "    config = ABAEManagerConfig.from_configuration(f\"final_full{i}\", configs[i])\n",
    "    runs.append(dict(config=config, results=[], model=None))"
   ],
   "id": "785e54a273cafec8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-21T14:54:59.420209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the runs\n",
    "tops = list(range(1, 30))  # Measure more infos to see the trend\n",
    "tops.reverse()\n",
    "\n",
    "for run in runs:\n",
    "    manager = ABAEManager.from_config(run[\"config\"], corpus, override=True)\n",
    "    manager.train(df=corpus, verbose=2)  # 2 Is epoch only\n",
    "\n",
    "    run['results'] = manager.evaluate(tops=tops, test_corpus=test_corpus_path)\n",
    "    run['model'] = manager.get_compiled_model(load_existing=True)  # Load the compiled model\n",
    "\n",
    "    pprint(run['results'])  # Show run results"
   ],
   "id": "5cb567f1ef9fef07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/233384 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43f7326e29204f37a56109b5bbe76552"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n",
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Das System kann die angegebene Datei nicht finden\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Aspect embedding model\n",
      "\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/233384 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6e590a088594a0aac161bbfa94aa2a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 5614(2.4054776677064407% of ds).\n",
      "Generating a new compiled model from scratch\n",
      "Training is starting:\n",
      "Epoch 1/9\n",
      "912/912 - 259s - 284ms/step - loss: 5.5125 - max_margin_loss: 5.5109\n",
      "Epoch 2/9\n",
      "912/912 - 259s - 284ms/step - loss: 4.1676 - max_margin_loss: 4.1667\n",
      "Epoch 3/9\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "[pprint(run['results']) for run in runs]  # Show run results",
   "id": "602377db7e9e555"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compare results\n",
    "structured_data = {'config': [], 'coherence': [], 'top': []}\n",
    "config_num = 1\n",
    "for run in runs:\n",
    "    print(f\"Results for run {run['config']}:\\n {run['results']}\")\n",
    "    print(f\"Overall AVG: {np.mean(run['results'])} and VAR: {np.var(run['results'])}\")\n",
    "\n",
    "    for coherence, top in zip(run['results']['coherence'], run['results']['top']):\n",
    "        structured_data['config'].append(str(config_num))  # Id for color\n",
    "\n",
    "        structured_data['coherence'].append(coherence)\n",
    "        structured_data['top'].append(top)\n",
    "\n",
    "    config_num += 1"
   ],
   "id": "dede5b1a2c477985"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.DataFrame(structured_data)\n",
    "\n",
    "# Plot the moving coherence\n",
    "px.line(data, x=\"top\", y=\"coherence\", color='config', title='Hyperparameter Tuning Results').show()"
   ],
   "id": "cbcdc8e514ed5483"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now see if we can map aspects to best ones:",
   "id": "eaf23d1368cbb435"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "best = 2",
   "id": "5f2b5b994be0c3b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "manager = ABAEManager.from_config(runs[best], corpus)\n",
    "manager.get_compiled_model(load_existing=True)\n",
    "ev_processor = manager.make_ev_processor(test_corpus_path)\n",
    "\n",
    "# Get the aspect words to map\n",
    "aspects = ev_processor.get_aspects(20)"
   ],
   "id": "fcd384883534c62a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "aspects",
   "id": "f8294aad40a66c61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It somehow is weird that the 80k model performs much better, let's make a comparison:",
   "id": "e4e5996c606b329f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Fai 80k e fai test su ds di test da 300k dopo aver tolto elementi del 80k train",
   "id": "4662caeb2eb5b32a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ora hai fatto il confronto ma modello Ã¨ migliore? Guardiamo coherence per topic\n",
    "# Si scopre data is unbalanced e ci sono schemi difficili da riconoscere\n",
    "# Se non li usiamo per il task e consideriamo coerente tutto cio in miscellanea il nostro modello\n",
    "# potremmo volerlo pesare solo su labeling pertinente"
   ],
   "id": "6b1e0b92816e2ee4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2319f66f5436a7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
