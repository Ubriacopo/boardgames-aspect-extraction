{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "Unlike LDA we should not toy too much with the sentence structure as ABAE uses word embeddings and needs the sequence information to weight the terms based on the surrounding context. One question remains:\n",
    "\n",
    "**Should we work on sentence level or full reviews? Let's try a first simple comparison**"
   ],
   "id": "46ac0985d60cd3fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Full-reviews",
   "id": "f13e2df2d7eeb181"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from main.abae.model_manager import ABAEManagerConfig, ABAEDefaultManagerFactory\n",
    "\n",
    "corpus = \"../dataset/output/default/pre_processed.80k.csv\"\n",
    "default_config = ABAEManagerConfig(model_name=\"abae_default_ds\", corpus_file_path=corpus)\n",
    "abae_manager = ABAEDefaultManagerFactory().factory_method(default_config)"
   ],
   "id": "5f30777edd24e42d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history, _ = abae_manager.train(corpus)\n",
    "model = abae_manager.get_compiled_model(refresh=False)"
   ],
   "id": "c055cfa1aa1053f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m474/474\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m100s\u001B[0m 211ms/step - loss: 4.6942 - max_margin_loss: 4.6932\n",
      "Epoch 12/15\n",
      "\u001B[1m474/474\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m98s\u001B[0m 206ms/step - loss: 4.6925 - max_margin_loss: 4.6915\n",
      "Epoch 13/15\n",
      "\u001B[1m474/474\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m96s\u001B[0m 202ms/step - loss: 4.6794 - max_margin_loss: 4.6784\n",
      "Epoch 14/15\n",
      "\u001B[1m474/474\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m99s\u001B[0m 208ms/step - loss: 4.6635 - max_margin_loss: 4.6625\n",
      "Epoch 15/15\n",
      "\u001B[1m474/474\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m100s\u001B[0m 210ms/step - loss: 4.6614 - max_margin_loss: 4.6604\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Latest run result:\n",
    "```\n",
    "Max Margin loss: [4.6614, 4.6604]\n",
    "```"
   ],
   "id": "7ee41fbe415dd82e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T23:45:48.003732Z",
     "start_time": "2025-03-09T23:45:47.996180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluation import ABAEEvaluationProcessor\n",
    "\n",
    "inv_vocab = abae_manager.generator.emb_model.model.wv.index_to_key\n",
    "processor = ABAEEvaluationProcessor.generate_for_model(model, inv_vocab)"
   ],
   "id": "66708df238ace366",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T00:00:53.668186Z",
     "start_time": "2025-03-10T00:00:04.619902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main.abae.dataset import PositiveNegativeABAEDataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_corpus_path = \"../dataset/output/default/pre_processed.80k.test.csv\"\n",
    "df = pd.read_csv(test_corpus_path)\n",
    "\n",
    "npmi_coh = processor.c_npmi_coherence_model(top_n=10, ds=df['comments'].apply(lambda x: x.split(' ')))\n",
    "npmi_coherence = npmi_coh.get_coherence()\n",
    "\n",
    "cv_coh = processor.c_v_coherence_model(top_n=100, ds=df['comments'].apply(lambda x: x.split(' ')))\n",
    "cv_coherence = cv_coh.get_coherence()\n",
    "\n",
    "\n",
    "vocabulary = abae_manager.generator.emb_model.vocabulary()\n",
    "max_seq_len = default_config.max_seq_len\n",
    "negative_sample_size = default_config.negative_sample_size\n",
    "test_ds = PositiveNegativeABAEDataset(df, vocabulary, max_seq_len, negative_sample_size)\n",
    "\n",
    "res = model.evaluate(DataLoader(test_ds, batch_size=default_config.batch_size))\n",
    "print(f\"Max margin reconstruction result: {res}\")"
   ],
   "id": "30792c404f010064",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n",
      "INFO:gensim.corpora.dictionary:adding document #10000 to Dictionary<12053 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...>\n",
      "INFO:gensim.corpora.dictionary:adding document #20000 to Dictionary<16753 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...>\n",
      "INFO:gensim.corpora.dictionary:built Dictionary<16850 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...> from 20213 documents (total 390827 corpus positions)\n",
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Dictionary\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<16850 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...> from 20213 documents (total 390827 corpus positions)\", 'datetime': '2025-03-10T01:00:04.936508', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator<processes=15, batch_size=64> to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:1 batches submitted to accumulate stats from 64 documents (805 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:2 batches submitted to accumulate stats from 128 documents (1532 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:3 batches submitted to accumulate stats from 192 documents (2291 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:4 batches submitted to accumulate stats from 256 documents (3235 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:5 batches submitted to accumulate stats from 320 documents (4103 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:6 batches submitted to accumulate stats from 384 documents (5102 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:7 batches submitted to accumulate stats from 448 documents (5630 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:8 batches submitted to accumulate stats from 512 documents (6392 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:9 batches submitted to accumulate stats from 576 documents (6909 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:10 batches submitted to accumulate stats from 640 documents (7588 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:11 batches submitted to accumulate stats from 704 documents (8327 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:12 batches submitted to accumulate stats from 768 documents (9037 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:13 batches submitted to accumulate stats from 832 documents (9442 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:14 batches submitted to accumulate stats from 896 documents (9839 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:15 batches submitted to accumulate stats from 960 documents (10301 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:16 batches submitted to accumulate stats from 1024 documents (11084 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:17 batches submitted to accumulate stats from 1088 documents (11735 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:18 batches submitted to accumulate stats from 1152 documents (12677 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:19 batches submitted to accumulate stats from 1216 documents (13244 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:20 batches submitted to accumulate stats from 1280 documents (13960 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:21 batches submitted to accumulate stats from 1344 documents (14449 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:22 batches submitted to accumulate stats from 1408 documents (14899 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:23 batches submitted to accumulate stats from 1472 documents (15525 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:24 batches submitted to accumulate stats from 1536 documents (16380 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:25 batches submitted to accumulate stats from 1600 documents (16815 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:26 batches submitted to accumulate stats from 1664 documents (17577 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:27 batches submitted to accumulate stats from 1728 documents (17970 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:28 batches submitted to accumulate stats from 1792 documents (18497 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:29 batches submitted to accumulate stats from 1856 documents (18885 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:30 batches submitted to accumulate stats from 1920 documents (19414 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:31 batches submitted to accumulate stats from 1984 documents (20169 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:32 batches submitted to accumulate stats from 2048 documents (21033 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:33 batches submitted to accumulate stats from 2112 documents (21569 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:34 batches submitted to accumulate stats from 2176 documents (22671 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:35 batches submitted to accumulate stats from 2240 documents (23210 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:36 batches submitted to accumulate stats from 2304 documents (24093 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:37 batches submitted to accumulate stats from 2368 documents (24704 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:38 batches submitted to accumulate stats from 2432 documents (25291 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:39 batches submitted to accumulate stats from 2496 documents (25845 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:40 batches submitted to accumulate stats from 2560 documents (26318 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:41 batches submitted to accumulate stats from 2624 documents (27053 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:42 batches submitted to accumulate stats from 2688 documents (27755 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:43 batches submitted to accumulate stats from 2752 documents (28479 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:44 batches submitted to accumulate stats from 2816 documents (29113 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:45 batches submitted to accumulate stats from 2880 documents (29859 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:46 batches submitted to accumulate stats from 2944 documents (30678 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:47 batches submitted to accumulate stats from 3008 documents (31424 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:48 batches submitted to accumulate stats from 3072 documents (31914 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:49 batches submitted to accumulate stats from 3136 documents (32442 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:50 batches submitted to accumulate stats from 3200 documents (33013 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:51 batches submitted to accumulate stats from 3264 documents (33400 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:52 batches submitted to accumulate stats from 3328 documents (34418 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:53 batches submitted to accumulate stats from 3392 documents (35008 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:54 batches submitted to accumulate stats from 3456 documents (35554 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:55 batches submitted to accumulate stats from 3520 documents (35988 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:56 batches submitted to accumulate stats from 3584 documents (36732 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:57 batches submitted to accumulate stats from 3648 documents (37675 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:58 batches submitted to accumulate stats from 3712 documents (38268 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:59 batches submitted to accumulate stats from 3776 documents (38931 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:60 batches submitted to accumulate stats from 3840 documents (39926 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:61 batches submitted to accumulate stats from 3904 documents (40618 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:62 batches submitted to accumulate stats from 3968 documents (41131 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:63 batches submitted to accumulate stats from 4032 documents (42051 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:64 batches submitted to accumulate stats from 4096 documents (42924 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:65 batches submitted to accumulate stats from 4160 documents (43624 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:66 batches submitted to accumulate stats from 4224 documents (44054 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:67 batches submitted to accumulate stats from 4288 documents (44588 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:68 batches submitted to accumulate stats from 4352 documents (45329 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:69 batches submitted to accumulate stats from 4416 documents (46054 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:70 batches submitted to accumulate stats from 4480 documents (46750 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:71 batches submitted to accumulate stats from 4544 documents (47687 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:72 batches submitted to accumulate stats from 4608 documents (48357 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:73 batches submitted to accumulate stats from 4672 documents (48883 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:74 batches submitted to accumulate stats from 4736 documents (49965 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:75 batches submitted to accumulate stats from 4800 documents (50633 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:76 batches submitted to accumulate stats from 4864 documents (51144 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:77 batches submitted to accumulate stats from 4928 documents (51853 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:78 batches submitted to accumulate stats from 4992 documents (52245 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:79 batches submitted to accumulate stats from 5056 documents (52878 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:80 batches submitted to accumulate stats from 5120 documents (53475 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:81 batches submitted to accumulate stats from 5184 documents (54340 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:82 batches submitted to accumulate stats from 5248 documents (55061 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:83 batches submitted to accumulate stats from 5312 documents (56140 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:84 batches submitted to accumulate stats from 5376 documents (56700 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:85 batches submitted to accumulate stats from 5440 documents (57146 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:86 batches submitted to accumulate stats from 5504 documents (57919 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:87 batches submitted to accumulate stats from 5568 documents (58529 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:88 batches submitted to accumulate stats from 5632 documents (59507 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:89 batches submitted to accumulate stats from 5696 documents (60135 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:90 batches submitted to accumulate stats from 5760 documents (60663 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:91 batches submitted to accumulate stats from 5824 documents (61265 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:92 batches submitted to accumulate stats from 5888 documents (62268 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:93 batches submitted to accumulate stats from 5952 documents (62769 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:94 batches submitted to accumulate stats from 6016 documents (63220 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:95 batches submitted to accumulate stats from 6080 documents (64077 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:96 batches submitted to accumulate stats from 6144 documents (64731 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:97 batches submitted to accumulate stats from 6208 documents (65713 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:98 batches submitted to accumulate stats from 6272 documents (66358 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:99 batches submitted to accumulate stats from 6336 documents (67227 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:100 batches submitted to accumulate stats from 6400 documents (67903 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:101 batches submitted to accumulate stats from 6464 documents (68574 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:102 batches submitted to accumulate stats from 6528 documents (69261 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:103 batches submitted to accumulate stats from 6592 documents (69862 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:104 batches submitted to accumulate stats from 6656 documents (70593 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:105 batches submitted to accumulate stats from 6720 documents (71067 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:106 batches submitted to accumulate stats from 6784 documents (71861 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:107 batches submitted to accumulate stats from 6848 documents (72326 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:108 batches submitted to accumulate stats from 6912 documents (72838 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:109 batches submitted to accumulate stats from 6976 documents (73750 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:110 batches submitted to accumulate stats from 7040 documents (74322 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:111 batches submitted to accumulate stats from 7104 documents (75222 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:112 batches submitted to accumulate stats from 7168 documents (75929 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:113 batches submitted to accumulate stats from 7232 documents (76599 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:114 batches submitted to accumulate stats from 7296 documents (77297 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:115 batches submitted to accumulate stats from 7360 documents (77881 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:116 batches submitted to accumulate stats from 7424 documents (78601 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:117 batches submitted to accumulate stats from 7488 documents (79464 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:118 batches submitted to accumulate stats from 7552 documents (80248 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:119 batches submitted to accumulate stats from 7616 documents (81346 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:120 batches submitted to accumulate stats from 7680 documents (81699 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:121 batches submitted to accumulate stats from 7744 documents (82506 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:122 batches submitted to accumulate stats from 7808 documents (83285 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:123 batches submitted to accumulate stats from 7872 documents (84038 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:124 batches submitted to accumulate stats from 7936 documents (84855 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:125 batches submitted to accumulate stats from 8000 documents (85601 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:126 batches submitted to accumulate stats from 8064 documents (85985 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:127 batches submitted to accumulate stats from 8128 documents (86613 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:128 batches submitted to accumulate stats from 8192 documents (87168 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:129 batches submitted to accumulate stats from 8256 documents (87638 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:130 batches submitted to accumulate stats from 8320 documents (88186 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:131 batches submitted to accumulate stats from 8384 documents (89007 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:132 batches submitted to accumulate stats from 8448 documents (89300 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:133 batches submitted to accumulate stats from 8512 documents (89890 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:134 batches submitted to accumulate stats from 8576 documents (90944 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:135 batches submitted to accumulate stats from 8640 documents (91450 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:136 batches submitted to accumulate stats from 8704 documents (92033 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:137 batches submitted to accumulate stats from 8768 documents (92426 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:138 batches submitted to accumulate stats from 8832 documents (93396 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:139 batches submitted to accumulate stats from 8896 documents (94265 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:140 batches submitted to accumulate stats from 8960 documents (94709 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:141 batches submitted to accumulate stats from 9024 documents (95329 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:142 batches submitted to accumulate stats from 9088 documents (95844 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:143 batches submitted to accumulate stats from 9152 documents (96655 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:144 batches submitted to accumulate stats from 9216 documents (97113 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:145 batches submitted to accumulate stats from 9280 documents (97766 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:146 batches submitted to accumulate stats from 9344 documents (98450 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:147 batches submitted to accumulate stats from 9408 documents (99007 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:148 batches submitted to accumulate stats from 9472 documents (99772 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:149 batches submitted to accumulate stats from 9536 documents (100240 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:150 batches submitted to accumulate stats from 9600 documents (100713 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:151 batches submitted to accumulate stats from 9664 documents (101532 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:152 batches submitted to accumulate stats from 9728 documents (103066 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:153 batches submitted to accumulate stats from 9792 documents (103595 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:154 batches submitted to accumulate stats from 9856 documents (103963 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:155 batches submitted to accumulate stats from 9920 documents (104547 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:156 batches submitted to accumulate stats from 9984 documents (105534 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:157 batches submitted to accumulate stats from 10048 documents (106256 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:158 batches submitted to accumulate stats from 10112 documents (107340 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:159 batches submitted to accumulate stats from 10176 documents (107946 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:160 batches submitted to accumulate stats from 10240 documents (108734 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:161 batches submitted to accumulate stats from 10304 documents (109220 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:162 batches submitted to accumulate stats from 10368 documents (109949 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:163 batches submitted to accumulate stats from 10432 documents (110471 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:164 batches submitted to accumulate stats from 10496 documents (111255 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:165 batches submitted to accumulate stats from 10560 documents (111728 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:166 batches submitted to accumulate stats from 10624 documents (112170 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:167 batches submitted to accumulate stats from 10688 documents (112727 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:168 batches submitted to accumulate stats from 10752 documents (113462 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:169 batches submitted to accumulate stats from 10816 documents (114114 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:170 batches submitted to accumulate stats from 10880 documents (114643 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:171 batches submitted to accumulate stats from 10944 documents (115270 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:172 batches submitted to accumulate stats from 11008 documents (115764 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:173 batches submitted to accumulate stats from 11072 documents (116237 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:174 batches submitted to accumulate stats from 11136 documents (116810 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:175 batches submitted to accumulate stats from 11200 documents (117248 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:176 batches submitted to accumulate stats from 11264 documents (117642 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:177 batches submitted to accumulate stats from 11328 documents (118275 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:178 batches submitted to accumulate stats from 11392 documents (119017 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:179 batches submitted to accumulate stats from 11456 documents (119518 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:180 batches submitted to accumulate stats from 11520 documents (119979 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:181 batches submitted to accumulate stats from 11584 documents (120561 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:182 batches submitted to accumulate stats from 11648 documents (121586 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:183 batches submitted to accumulate stats from 11712 documents (122139 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:184 batches submitted to accumulate stats from 11776 documents (122548 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:185 batches submitted to accumulate stats from 11840 documents (123275 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:186 batches submitted to accumulate stats from 11904 documents (123778 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:187 batches submitted to accumulate stats from 11968 documents (124612 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:188 batches submitted to accumulate stats from 12032 documents (125353 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:189 batches submitted to accumulate stats from 12096 documents (125840 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:190 batches submitted to accumulate stats from 12160 documents (126765 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:191 batches submitted to accumulate stats from 12224 documents (127420 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:192 batches submitted to accumulate stats from 12288 documents (127786 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:193 batches submitted to accumulate stats from 12352 documents (128392 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:194 batches submitted to accumulate stats from 12416 documents (129038 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:195 batches submitted to accumulate stats from 12480 documents (129820 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:196 batches submitted to accumulate stats from 12544 documents (130396 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:197 batches submitted to accumulate stats from 12608 documents (131202 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:198 batches submitted to accumulate stats from 12672 documents (131829 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:199 batches submitted to accumulate stats from 12736 documents (132376 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:200 batches submitted to accumulate stats from 12800 documents (133209 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:201 batches submitted to accumulate stats from 12864 documents (133908 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:202 batches submitted to accumulate stats from 12928 documents (134629 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:203 batches submitted to accumulate stats from 12992 documents (135009 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:204 batches submitted to accumulate stats from 13056 documents (135563 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:205 batches submitted to accumulate stats from 13120 documents (136144 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:206 batches submitted to accumulate stats from 13184 documents (136957 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:207 batches submitted to accumulate stats from 13248 documents (137523 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:208 batches submitted to accumulate stats from 13312 documents (138290 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:209 batches submitted to accumulate stats from 13376 documents (138697 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:210 batches submitted to accumulate stats from 13440 documents (139321 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:211 batches submitted to accumulate stats from 13504 documents (139842 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:212 batches submitted to accumulate stats from 13568 documents (140394 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:213 batches submitted to accumulate stats from 13632 documents (140828 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:214 batches submitted to accumulate stats from 13696 documents (141397 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:215 batches submitted to accumulate stats from 13760 documents (142495 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:216 batches submitted to accumulate stats from 13824 documents (142917 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:217 batches submitted to accumulate stats from 13888 documents (143327 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:218 batches submitted to accumulate stats from 13952 documents (144144 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:219 batches submitted to accumulate stats from 14016 documents (144611 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:220 batches submitted to accumulate stats from 14080 documents (145585 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:221 batches submitted to accumulate stats from 14144 documents (146553 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:222 batches submitted to accumulate stats from 14208 documents (147092 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:223 batches submitted to accumulate stats from 14272 documents (147699 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:224 batches submitted to accumulate stats from 14336 documents (148244 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:225 batches submitted to accumulate stats from 14400 documents (148831 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:226 batches submitted to accumulate stats from 14464 documents (149388 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:227 batches submitted to accumulate stats from 14528 documents (150059 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:228 batches submitted to accumulate stats from 14592 documents (150741 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:229 batches submitted to accumulate stats from 14656 documents (151229 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:230 batches submitted to accumulate stats from 14720 documents (151745 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:231 batches submitted to accumulate stats from 14784 documents (152404 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:232 batches submitted to accumulate stats from 14848 documents (152902 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:233 batches submitted to accumulate stats from 14912 documents (153369 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:234 batches submitted to accumulate stats from 14976 documents (154008 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:235 batches submitted to accumulate stats from 15040 documents (154541 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:236 batches submitted to accumulate stats from 15104 documents (155035 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:237 batches submitted to accumulate stats from 15168 documents (155573 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:238 batches submitted to accumulate stats from 15232 documents (156150 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:239 batches submitted to accumulate stats from 15296 documents (156410 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:240 batches submitted to accumulate stats from 15360 documents (157083 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:241 batches submitted to accumulate stats from 15424 documents (157781 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:242 batches submitted to accumulate stats from 15488 documents (158671 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:243 batches submitted to accumulate stats from 15552 documents (159449 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:244 batches submitted to accumulate stats from 15616 documents (160236 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:245 batches submitted to accumulate stats from 15680 documents (161398 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:246 batches submitted to accumulate stats from 15744 documents (161814 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:247 batches submitted to accumulate stats from 15808 documents (162405 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:248 batches submitted to accumulate stats from 15872 documents (163608 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:249 batches submitted to accumulate stats from 15936 documents (164531 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:250 batches submitted to accumulate stats from 16000 documents (165206 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:251 batches submitted to accumulate stats from 16064 documents (165875 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:252 batches submitted to accumulate stats from 16128 documents (167079 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:253 batches submitted to accumulate stats from 16192 documents (167747 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:254 batches submitted to accumulate stats from 16256 documents (168584 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:255 batches submitted to accumulate stats from 16320 documents (169346 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:256 batches submitted to accumulate stats from 16384 documents (170070 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:257 batches submitted to accumulate stats from 16448 documents (170696 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:258 batches submitted to accumulate stats from 16512 documents (171226 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:259 batches submitted to accumulate stats from 16576 documents (171852 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:260 batches submitted to accumulate stats from 16640 documents (172515 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:261 batches submitted to accumulate stats from 16704 documents (173091 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:262 batches submitted to accumulate stats from 16768 documents (173593 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:263 batches submitted to accumulate stats from 16832 documents (173959 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:264 batches submitted to accumulate stats from 16896 documents (174552 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:265 batches submitted to accumulate stats from 16960 documents (175357 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:266 batches submitted to accumulate stats from 17024 documents (175958 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:267 batches submitted to accumulate stats from 17088 documents (176435 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:268 batches submitted to accumulate stats from 17152 documents (176870 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:269 batches submitted to accumulate stats from 17216 documents (177505 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:270 batches submitted to accumulate stats from 17280 documents (177837 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:271 batches submitted to accumulate stats from 17344 documents (178682 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:272 batches submitted to accumulate stats from 17408 documents (179111 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:273 batches submitted to accumulate stats from 17472 documents (179538 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:274 batches submitted to accumulate stats from 17536 documents (180353 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:275 batches submitted to accumulate stats from 17600 documents (181021 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:276 batches submitted to accumulate stats from 17664 documents (181519 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:277 batches submitted to accumulate stats from 17728 documents (182168 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:278 batches submitted to accumulate stats from 17792 documents (182904 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:279 batches submitted to accumulate stats from 17856 documents (183675 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:280 batches submitted to accumulate stats from 17920 documents (184521 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:281 batches submitted to accumulate stats from 17984 documents (185278 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:282 batches submitted to accumulate stats from 18048 documents (185861 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:283 batches submitted to accumulate stats from 18112 documents (186397 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:284 batches submitted to accumulate stats from 18176 documents (187178 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:285 batches submitted to accumulate stats from 18240 documents (187588 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:286 batches submitted to accumulate stats from 18304 documents (188163 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:287 batches submitted to accumulate stats from 18368 documents (188721 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:288 batches submitted to accumulate stats from 18432 documents (189561 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:289 batches submitted to accumulate stats from 18496 documents (190427 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:290 batches submitted to accumulate stats from 18560 documents (191251 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:291 batches submitted to accumulate stats from 18624 documents (191967 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:292 batches submitted to accumulate stats from 18688 documents (192571 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:293 batches submitted to accumulate stats from 18752 documents (193449 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:294 batches submitted to accumulate stats from 18816 documents (194048 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:295 batches submitted to accumulate stats from 18880 documents (194393 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:296 batches submitted to accumulate stats from 18944 documents (195147 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:297 batches submitted to accumulate stats from 19008 documents (195887 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:298 batches submitted to accumulate stats from 19072 documents (196932 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:299 batches submitted to accumulate stats from 19136 documents (197619 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:300 batches submitted to accumulate stats from 19200 documents (198113 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:301 batches submitted to accumulate stats from 19264 documents (198969 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:302 batches submitted to accumulate stats from 19328 documents (199624 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:303 batches submitted to accumulate stats from 19392 documents (200288 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:304 batches submitted to accumulate stats from 19456 documents (200976 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:305 batches submitted to accumulate stats from 19520 documents (201995 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:306 batches submitted to accumulate stats from 19584 documents (202465 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:307 batches submitted to accumulate stats from 19648 documents (203161 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:308 batches submitted to accumulate stats from 19712 documents (203830 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:309 batches submitted to accumulate stats from 19776 documents (204504 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:310 batches submitted to accumulate stats from 19840 documents (205044 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:311 batches submitted to accumulate stats from 19904 documents (205702 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:312 batches submitted to accumulate stats from 19968 documents (206502 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:313 batches submitted to accumulate stats from 20032 documents (207062 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:314 batches submitted to accumulate stats from 20096 documents (207657 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:315 batches submitted to accumulate stats from 20160 documents (208462 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:316 batches submitted to accumulate stats from 20224 documents (208910 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:15 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 238372 virtual documents\n",
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n",
      "INFO:gensim.corpora.dictionary:adding document #10000 to Dictionary<12053 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...>\n",
      "INFO:gensim.corpora.dictionary:adding document #20000 to Dictionary<16753 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...>\n",
      "INFO:gensim.corpora.dictionary:built Dictionary<16850 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...> from 20213 documents (total 390827 corpus positions)\n",
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Dictionary\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<16850 unique tokens: ['<game_name>', 'abstract', 'add', 'art', 'bad']...> from 20213 documents (total 390827 corpus positions)\", 'datetime': '2025-03-10T01:00:19.548746', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator<processes=15, batch_size=64> to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:15 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 32406 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab08ead9bbcd43648d97fa8f578a3c0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 464(2.295552367288379% of ds).\n",
      "\u001B[1m158/158\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 120ms/step - loss: 4.7868 - max_margin_loss: 4.7858\n",
      "Max margin reconstruction result: [4.745960235595703, 4.744936943054199]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T00:00:53.680702Z",
     "start_time": "2025-03-10T00:00:53.676190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"NPMI coherence: {npmi_coherence}\")\n",
    "print(f\"CV score: {cv_coherence}\")\n",
    "print(f\"Max margin reconstruction result: {res}\")"
   ],
   "id": "d8250e17409f3d17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPMI coherence: -0.23037988688672537\n",
      "CV score: 0.5646751917101251\n",
      "Max margin reconstruction result: [4.745960235595703, 4.744936943054199]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results of the latest run:\n",
    "```\n",
    "NPMI coherence: -0.23037988688672537\n",
    "CV score: 0.5646751917101251\n",
    "Max margin reconstruction result: [4.745960235595703, 4.744936943054199]\n",
    "```"
   ],
   "id": "90204b1de20cae27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T00:06:05.974481Z",
     "start_time": "2025-03-10T00:06:05.939496Z"
    }
   },
   "cell_type": "code",
   "source": "list(processor.extract_top_k_words(10, 10))",
   "id": "3837729525676adb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('instruction', tensor(0.6540, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('manual', tensor(0.6516, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('page', tensor(0.6307, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('solution', tensor(0.6230, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('reference', tensor(0.5907, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('query', tensor(0.5859, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('vague', tensor(0.5815, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('wiki', tensor(0.5806, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('decipher', tensor(0.5799, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('rulebook', tensor(0.5764, device='cuda:0', grad_fn=<SelectBackward0>))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sentence-split reviews",
   "id": "9eaaec47b2c6b0dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from main.abae.model_manager import ABAEManagerConfig, ABAEDefaultManagerFactory\n",
    "\n",
    "corpus = \"../dataset/output/default_sentences/pre_processed.80k.csv\"\n",
    "default_config = ABAEManagerConfig(model_name=\"abae_sent_ds\", corpus_file_path=corpus)\n",
    "abae_manager = ABAEDefaultManagerFactory().factory_method(default_config)"
   ],
   "id": "c10bc1217fb36896",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history, _ = abae_manager.train(corpus)\n",
    "model = abae_manager.get_compiled_model(refresh=False)"
   ],
   "id": "ae5e6bcfbe29d3f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T16:17:02.919954Z",
     "start_time": "2025-03-10T16:17:02.914943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print history\n",
    "history.history"
   ],
   "id": "1ba664e2c444d34f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [8.786524772644043,\n",
       "  5.993138313293457,\n",
       "  5.584963321685791,\n",
       "  5.477548122406006,\n",
       "  5.42295503616333,\n",
       "  5.371152877807617,\n",
       "  5.343845844268799,\n",
       "  5.310521125793457,\n",
       "  5.257896423339844,\n",
       "  5.230459690093994,\n",
       "  5.210410118103027,\n",
       "  5.190746307373047,\n",
       "  5.181276321411133,\n",
       "  5.164516448974609,\n",
       "  5.154855728149414],\n",
       " 'max_margin_loss': [8.780280113220215,\n",
       "  5.991584777832031,\n",
       "  5.584194660186768,\n",
       "  5.476739883422852,\n",
       "  5.423596382141113,\n",
       "  5.369997978210449,\n",
       "  5.3439788818359375,\n",
       "  5.3094024658203125,\n",
       "  5.2574005126953125,\n",
       "  5.22948694229126,\n",
       "  5.208757400512695,\n",
       "  5.1898369789123535,\n",
       "  5.179889678955078,\n",
       "  5.1640849113464355,\n",
       "  5.154535293579102]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T16:18:43.428406Z",
     "start_time": "2025-03-10T16:18:43.423145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.functional import normalize\n",
    "\n",
    "inv_vocab = abae_manager.generator.emb_model.model.wv.index_to_key\n",
    "word_embeddings = model.get_layer('word_embedding').weights[0].value.data\n",
    "word_embeddings = normalize(word_embeddings, dim=-1)\n",
    "aspect_embeddings = model.get_layer('weighted_aspect_embedding_2').w\n",
    "aspect_embeddings = normalize(aspect_embeddings, dim=-1)\n",
    "processor = ABAEEvaluationProcessor(word_embeddings, aspect_embeddings, inv_vocab)"
   ],
   "id": "95901247f5d5867f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T16:17:22.015561Z",
     "start_time": "2025-03-10T16:17:21.948461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from evaluation import ABAEEvaluationProcessor\n",
    "\n",
    "inv_vocab = abae_manager.generator.emb_model.model.wv.index_to_key\n",
    "processor = ABAEEvaluationProcessor.generate_for_model(model, inv_vocab)"
   ],
   "id": "ca1dc98730b4200c",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: weighted_aspect_embedding. Existing layers are: ['positive', 'word_embedding', 'attention', 'weight', 'negative', 'sentence_aspect', 'average_1', 'weighted_aspect_embedding_2', 'max_margin'].",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ABAEEvaluationProcessor\n\u001B[0;32m      3\u001B[0m inv_vocab \u001B[38;5;241m=\u001B[39m abae_manager\u001B[38;5;241m.\u001B[39mgenerator\u001B[38;5;241m.\u001B[39memb_model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mwv\u001B[38;5;241m.\u001B[39mindex_to_key\n\u001B[1;32m----> 4\u001B[0m processor \u001B[38;5;241m=\u001B[39m \u001B[43mABAEEvaluationProcessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_for_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minv_vocab\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\main\\abae\\evaluation.py:65\u001B[0m, in \u001B[0;36mABAEEvaluationProcessor.generate_for_model\u001B[1;34m(model, inverse_vocabulary)\u001B[0m\n\u001B[0;32m     63\u001B[0m word_embeddings \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_layer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mword_embedding\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mweights[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;241m.\u001B[39mdata\n\u001B[0;32m     64\u001B[0m word_embeddings \u001B[38;5;241m=\u001B[39m normalize(word_embeddings, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 65\u001B[0m aspect_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweighted_aspect_embedding\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mw\n\u001B[0;32m     66\u001B[0m aspect_embeddings \u001B[38;5;241m=\u001B[39m normalize(aspect_embeddings, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ABAEEvaluationProcessor(word_embeddings, aspect_embeddings, inverse_vocabulary)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\models\\model.py:208\u001B[0m, in \u001B[0;36mModel.get_layer\u001B[1;34m(self, name, index)\u001B[0m\n\u001B[0;32m    206\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m layer\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m name:\n\u001B[0;32m    207\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m layer\n\u001B[1;32m--> 208\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    209\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo such layer: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Existing layers are: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    210\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(layer\u001B[38;5;241m.\u001B[39mname\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mlayer\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    211\u001B[0m     )\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProvide either a layer name or layer index at `get_layer`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    214\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: No such layer: weighted_aspect_embedding. Existing layers are: ['positive', 'word_embedding', 'attention', 'weight', 'negative', 'sentence_aspect', 'average_1', 'weighted_aspect_embedding_2', 'max_margin']."
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T16:19:40.394100Z",
     "start_time": "2025-03-10T16:18:45.980003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main.abae.dataset import PositiveNegativeABAEDataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_corpus_path = \"../dataset/output/default_sentences/pre_processed.80k.test.csv\"\n",
    "df = pd.read_csv(test_corpus_path)\n",
    "\n",
    "npmi_coh = processor.c_npmi_coherence_model(top_n=10, ds=df['comments'].apply(lambda x: x.split(' ')))\n",
    "npmi_coherence = npmi_coh.get_coherence()\n",
    "\n",
    "cv_coh = processor.c_v_coherence_model(top_n=100, ds=df['comments'].apply(lambda x: x.split(' ')))\n",
    "cv_coherence = cv_coh.get_coherence()\n",
    "\n",
    "\n",
    "vocabulary = abae_manager.generator.emb_model.vocabulary()\n",
    "max_seq_len = default_config.max_seq_len\n",
    "negative_sample_size = default_config.negative_sample_size\n",
    "test_ds = PositiveNegativeABAEDataset(df, vocabulary, max_seq_len, negative_sample_size)\n",
    "\n",
    "res = model.evaluate(DataLoader(test_ds, batch_size=default_config.batch_size))\n",
    "print(f\"Max margin reconstruction result: {res}\")"
   ],
   "id": "58dba7abedb96e83",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n",
      "INFO:gensim.corpora.dictionary:adding document #10000 to Dictionary<7608 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...>\n",
      "INFO:gensim.corpora.dictionary:adding document #20000 to Dictionary<10781 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...>\n",
      "INFO:gensim.corpora.dictionary:built Dictionary<11509 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...> from 22796 documents (total 176244 corpus positions)\n",
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Dictionary\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<11509 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...> from 22796 documents (total 176244 corpus positions)\", 'datetime': '2025-03-10T17:18:46.204925', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator<processes=15, batch_size=64> to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:69 batches submitted to accumulate stats from 4416 documents (-5342 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:100 batches submitted to accumulate stats from 6400 documents (-7899 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:243 batches submitted to accumulate stats from 15552 documents (-19721 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:261 batches submitted to accumulate stats from 16704 documents (-20754 virtual)\n",
      "INFO:gensim.topic_coherence.text_analysis:15 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 41546 virtual documents\n",
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary<0 unique tokens: []>\n",
      "INFO:gensim.corpora.dictionary:adding document #10000 to Dictionary<7608 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...>\n",
      "INFO:gensim.corpora.dictionary:adding document #20000 to Dictionary<10781 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...>\n",
      "INFO:gensim.corpora.dictionary:built Dictionary<11509 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...> from 22796 documents (total 176244 corpus positions)\n",
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Dictionary\n",
      "INFO:gensim.utils:Dictionary lifecycle event {'msg': \"built Dictionary<11509 unique tokens: ['hide', 'like', 'multiple', 'possible', 'traitor']...> from 22796 documents (total 176244 corpus positions)\", 'datetime': '2025-03-10T17:19:01.934517', 'gensim': '4.3.3', 'python': '3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'created'}\n",
      "INFO:gensim.topic_coherence.probability_estimation:using ParallelWordOccurrenceAccumulator<processes=15, batch_size=64> to estimate probabilities from sliding windows\n",
      "INFO:gensim.topic_coherence.text_analysis:15 accumulators retrieved from output queue\n",
      "INFO:gensim.topic_coherence.text_analysis:accumulated word occurrence stats for 22936 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b9f4698cfb84bf884ff3c1bf00795ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 2(0.008773469029654327% of ds).\n",
      "\u001B[1m179/179\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 126ms/step - loss: 5.2631 - max_margin_loss: 5.2623\n",
      "Max margin reconstruction result: [5.261548042297363, 5.262136936187744]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T16:19:40.406364Z",
     "start_time": "2025-03-10T16:19:40.401112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"NPMI coherence: {npmi_coherence}\")\n",
    "print(f\"CV score: {cv_coherence}\")\n",
    "print(f\"Max margin reconstruction result: {res}\")"
   ],
   "id": "e0b23cc4f4af5458",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPMI coherence: -0.3117940799781337\n",
      "CV score: 0.6031670887985386\n",
      "Max margin reconstruction result: [5.261548042297363, 5.262136936187744]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results for the run:\n",
    "```\n",
    "NPMI coherence: -0.3117940799781337\n",
    "CV score: 0.6031670887985386\n",
    "Max margin reconstruction result: [5.261548042297363, 5.262136936187744]\n",
    "```"
   ],
   "id": "ef92f28f17f7dd15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T16:20:32.005303Z",
     "start_time": "2025-03-10T16:20:31.973265Z"
    }
   },
   "cell_type": "code",
   "source": "list(processor.extract_top_k_words(11, 10))",
   "id": "a4ef0f210ec47ab4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('instruction', tensor(0.7166, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('rule', tensor(0.7164, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('rulebook', tensor(0.7001, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('manual', tensor(0.6964, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('forum', tensor(0.6304, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('faq', tensor(0.6292, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('language', tensor(0.5814, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('booklet', tensor(0.5774, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('iconography', tensor(0.5654, device='cuda:0', grad_fn=<SelectBackward0>)),\n",
       " ('rules', tensor(0.5641, device='cuda:0', grad_fn=<SelectBackward0>))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I know that doing a  comparison on a single run is not that meaningful. <br>\n",
    "I could do k-CV to estimate the expected model loss to get a valid analysis. <br>\n",
    "But for the sake of the experiment we consider this good enough."
   ],
   "id": "b78cbae13b203c37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the future work and as one by the proposed ABAE paper we won't be splitting up reviews in sentences but use the full review as the model does not increase much if not done like this.",
   "id": "5b4c80db434e5d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d6545417958061a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
