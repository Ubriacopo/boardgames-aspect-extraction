{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T18:32:31.914990Z",
     "start_time": "2025-03-15T18:32:24.215079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "# Required imports.\n",
    "from main.abae.config import ABAEManagerConfig\n",
    "from main.abae.model_manager import ABAEManager"
   ],
   "id": "92a992781ca00086",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In case we want to avoid the long gibberish by gensim on Word2Vec or other stuff:",
   "id": "9670a5d3901d7f7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T18:32:31.932636Z",
     "start_time": "2025-03-15T18:32:31.928507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "logging.disable()\n",
    "logging.disable(logging.DEBUG)\n",
    "logging.disable(logging.INFO)"
   ],
   "id": "2f908b9c3058b5c9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's make a first attempt on the various pre-processing pipelines:",
   "id": "510c606905805814"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Full-reviews\n",
    "Try to run the procedure on the default implementation of the pipeline. Default as it was thought to be a simple version for ABAE specifically."
   ],
   "id": "f13e2df2d7eeb181"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "Unlike LDA we should not toy too much with the sentence structure as ABAE uses word embeddings and needs the sequence information to weight the terms based on the surrounding context. One question remains:\n",
    "\n",
    "**Should we work on sentence level or full reviews? Let's try a first simple comparison**"
   ],
   "id": "46ac0985d60cd3fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T18:38:40.918650Z",
     "start_time": "2025-03-15T18:32:32.632274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_path = \"../dataset/output/default/pre_processed.80k.csv\"\n",
    "test_corpus_path = \"../dataset/output/default/pre_processed.80k.test.csv\"\n",
    "\n",
    "manager = ABAEManager.from_scratch(ABAEManagerConfig('default', epochs=1), corpus_path, override=True)\n",
    "manager.train(corpus_path, verbose=2)\n",
    "res = manager.evaluate([25, 10, 3], test_corpus_path=test_corpus_path)"
   ],
   "id": "1a9724ba75af1d16",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/60640 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "478e2fcf6a0e40eab8beb3a133a59a0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n",
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Das System kann die angegebene Datei nicht finden\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\jacop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Aspect embedding model\n",
      "\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/60640 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50ec0424fff644c8a3a7288af642fb83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 1340(2.2097625329815305% of ds).\n",
      "Generating a new compiled model from scratch\n",
      "Training is starting:\n",
      "474/474 - 96s - 204ms/step - loss: 8.2529 - max_margin_loss: 8.2499\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8d7db42a39e4a41874f293c17fafcda"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 464(2.295552367288379% of ds).\n",
      "\u001B[1m158/158\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 175ms/step - loss: 6.0666 - max_margin_loss: 6.0652\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e86cb353566d466b97ceea3be3b5c0b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 464(2.295552367288379% of ds).\n",
      "\u001B[1m40/40\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa0f8afedf73415a95d4a12df3efa58a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "473c7fca4e744f87a6e8ebbb68dc50dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be7dea1f68574f02bf11496ad72afb53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20213 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e654a702ae834bf0899d3c380222fa59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\swifter\\swifter.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, func, convert_dtype, args, **kwds)\u001B[0m\n\u001B[0;32m    318\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mERRORS_TO_HANDLE\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# if can't vectorize, estimate time to pandas apply\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    319\u001B[0m             \u001B[0mwrapped\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_wrapped_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconvert_dtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconvert_dtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 320\u001B[1;33m             \u001B[0mtimed\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtimeit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwrapped\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mN_REPEATS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    321\u001B[0m             \u001B[0msample_proc_est\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtimed\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mN_REPEATS\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\main\\abae\\evaluation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m         \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'comments'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mswifter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m' '\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6297\u001B[0m         \u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6298\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6299\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'Series' object has no attribute 'split'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m manager \u001B[38;5;241m=\u001B[39m ABAEManager\u001B[38;5;241m.\u001B[39mfrom_scratch(ABAEManagerConfig(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), corpus_path, override\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m manager\u001B[38;5;241m.\u001B[39mtrain(corpus_path, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mmanager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_corpus_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_corpus_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\main\\abae\\model_manager.py:146\u001B[0m, in \u001B[0;36mABAEManager.evaluate\u001B[1;34m(self, tops, test_corpus_path)\u001B[0m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m top \u001B[38;5;129;01min\u001B[39;00m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m    145\u001B[0m     results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnpmi_coh\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(ev_processor\u001B[38;5;241m.\u001B[39mc_npmi_coherence_model(top_n\u001B[38;5;241m=\u001B[39mtop)\u001B[38;5;241m.\u001B[39mget_coherence())\n\u001B[1;32m--> 146\u001B[0m     results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcv_coh\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(\u001B[43mev_processor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_v_coherence_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtop_n\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mget_coherence())\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\main\\abae\\evaluation.py:81\u001B[0m, in \u001B[0;36mABAEEvaluationProcessor.c_v_coherence_model\u001B[1;34m(self, top_n, aspects)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aspects \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(aspects) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(aspects[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m<\u001B[39m top_n:\n\u001B[0;32m     80\u001B[0m     aspects \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__prepare_aspects(top_n)\n\u001B[1;32m---> 81\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcomments\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mswifter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m dictionary \u001B[38;5;241m=\u001B[39m corpora\u001B[38;5;241m.\u001B[39mDictionary(df\u001B[38;5;241m.\u001B[39mto_list())\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m CoherenceModel(topics\u001B[38;5;241m=\u001B[39maspects, texts\u001B[38;5;241m=\u001B[39mdf, dictionary\u001B[38;5;241m=\u001B[39mdictionary, coherence\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc_v\u001B[39m\u001B[38;5;124m'\u001B[39m, topn\u001B[38;5;241m=\u001B[39mtop_n)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\swifter\\swifter.py:320\u001B[0m, in \u001B[0;36mSeriesAccessor.apply\u001B[1;34m(self, func, convert_dtype, args, **kwds)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ERRORS_TO_HANDLE:  \u001B[38;5;66;03m# if can't vectorize, estimate time to pandas apply\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrapped_apply(func, convert_dtype\u001B[38;5;241m=\u001B[39mconvert_dtype, args\u001B[38;5;241m=\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m--> 320\u001B[0m     timed \u001B[38;5;241m=\u001B[39m \u001B[43mtimeit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwrapped\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumber\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN_REPEATS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    321\u001B[0m     sample_proc_est \u001B[38;5;241m=\u001B[39m timed \u001B[38;5;241m/\u001B[39m N_REPEATS\n\u001B[0;32m    322\u001B[0m     est_apply_duration \u001B[38;5;241m=\u001B[39m sample_proc_est \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_SAMPLE_SIZE \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nrows\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\timeit.py:237\u001B[0m, in \u001B[0;36mtimeit\u001B[1;34m(stmt, setup, timer, number, globals)\u001B[0m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtimeit\u001B[39m(stmt\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass\u001B[39m\u001B[38;5;124m\"\u001B[39m, setup\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass\u001B[39m\u001B[38;5;124m\"\u001B[39m, timer\u001B[38;5;241m=\u001B[39mdefault_timer,\n\u001B[0;32m    235\u001B[0m            number\u001B[38;5;241m=\u001B[39mdefault_number, \u001B[38;5;28mglobals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    236\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 237\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mTimer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstmt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msetup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\timeit.py:180\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    178\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 180\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<timeit-src>:6\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer, _stmt)\u001B[0m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\swifter\\swifter.py:227\u001B[0m, in \u001B[0;36mSeriesAccessor._wrapped_apply.<locals>.wrapped\u001B[1;34m()\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m():\n\u001B[1;32m--> 227\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m suppress_stdout_stderr_logging():\n\u001B[0;32m    228\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_obj\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_SAMPLE_INDEX]\u001B[38;5;241m.\u001B[39mapply(func, convert_dtype\u001B[38;5;241m=\u001B[39mconvert_dtype, args\u001B[38;5;241m=\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\swifter\\base.py:35\u001B[0m, in \u001B[0;36msuppress_stdout_stderr_logging\u001B[1;34m()\u001B[0m\n\u001B[0;32m     33\u001B[0m logging\u001B[38;5;241m.\u001B[39mdisable(logging\u001B[38;5;241m.\u001B[39mCRITICAL)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 35\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdevnull\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fnull:\n\u001B[0;32m     36\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m redirect_stderr(fnull) \u001B[38;5;28;01mas\u001B[39;00m err, redirect_stdout(fnull) \u001B[38;5;28;01mas\u001B[39;00m out:\n\u001B[0;32m     37\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m (err, out)\n",
      "File \u001B[1;32m<frozen codecs>:186\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, errors)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Latest run result:\n",
    "```\n",
    "Max Margin loss: [4.6614, 4.6604]\n",
    "```"
   ],
   "id": "7ee41fbe415dd82e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results of the latest run:\n",
    "```\n",
    "NPMI coherence: -0.23037988688672537\n",
    "CV score: 0.5646751917101251\n",
    "Max margin reconstruction result: [4.745960235595703, 4.744936943054199]\n",
    "```"
   ],
   "id": "90204b1de20cae27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sentence-split reviews",
   "id": "9eaaec47b2c6b0dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:50:59.810523Z",
     "start_time": "2025-03-15T17:25:02.229534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_path = \"../dataset/output/default_sentences/pre_processed.80k.csv\"\n",
    "test_corpus_path = \"../dataset/output/default_sentences/pre_processed.80k.test.csv\"\n",
    "\n",
    "manager = ABAEManager.from_scratch(ABAEManagerConfig('sentence_default'), corpus_path)\n",
    "manager.train(corpus_path, verbose=2)\n",
    "res = manager.evaluate([25, 10, 3], test_corpus_path=test_corpus_path)\n",
    "pprint(res)"
   ],
   "id": "ba5daef7089707a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/68390 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "770dfed31f374e39a4133bf448c4560a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n",
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Aspect embedding model\n",
      "\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/68390 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ada220fb20446238d76c8b77d065df9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 8(0.011697616610615587% of ds).\n",
      "Generating a new compiled model from scratch\n",
      "Training is starting:\n",
      "Epoch 1/15\n",
      "535/535 - 94s - 176ms/step - loss: 8.4488 - max_margin_loss: 8.4433\n",
      "Epoch 2/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.8622 - max_margin_loss: 5.8595\n",
      "Epoch 3/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.5061 - max_margin_loss: 5.5040\n",
      "Epoch 4/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.4072 - max_margin_loss: 5.4060\n",
      "Epoch 5/15\n",
      "535/535 - 94s - 175ms/step - loss: 5.3547 - max_margin_loss: 5.3538\n",
      "Epoch 6/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.3132 - max_margin_loss: 5.3120\n",
      "Epoch 7/15\n",
      "535/535 - 93s - 175ms/step - loss: 5.2834 - max_margin_loss: 5.2830\n",
      "Epoch 8/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.2589 - max_margin_loss: 5.2584\n",
      "Epoch 9/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.2448 - max_margin_loss: 5.2442\n",
      "Epoch 10/15\n",
      "535/535 - 93s - 175ms/step - loss: 5.2273 - max_margin_loss: 5.2276\n",
      "Epoch 11/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.2114 - max_margin_loss: 5.2100\n",
      "Epoch 12/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.1911 - max_margin_loss: 5.1903\n",
      "Epoch 13/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.1855 - max_margin_loss: 5.1859\n",
      "Epoch 14/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.1731 - max_margin_loss: 5.1719\n",
      "Epoch 15/15\n",
      "535/535 - 93s - 174ms/step - loss: 5.1664 - max_margin_loss: 5.1652\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c83135956faa4ee381a5a8bb5b209b0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 2(0.008773469029654327% of ds).\n",
      "\u001B[1m179/179\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 126ms/step - loss: 5.2406 - max_margin_loss: 5.2399\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e97056ff8de54e33b6c73a87693673bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 2(0.008773469029654327% of ds).\n",
      "\u001B[1m45/45\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7b04979547e4968b0d7f9d8c941dc82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0104a4e5132a408a8fa56cccbdbc8703"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbfd524ab52543c286823d2db5f07612"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a07304aa3a44c6bbc630c9a25ae6f06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9fdf880b9e649c0bd2ae9f993a462ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/22796 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dc6bad0b38a4499aa65899331c30f75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv_coh': [0.6656065043812275, 0.4116552201333862, 0.251877270410466],\n",
      " 'loss': [5.250680923461914, 5.257223606109619],\n",
      " 'npmi_coh': [-0.36774750155270663, -0.3153002812427124, -0.26334968605114956],\n",
      " 'silhouette_score': 0.102481075,\n",
      " 'top': [25, 10, 3]}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43d2e8c667978b14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Results for the run:\n",
    "```\n",
    "{\n",
    "    'cv_coh': [0.6656065043812275, 0.4116552201333862, 0.251877270410466],\n",
    "    'loss': [5.250680923461914, 5.257223606109619],\n",
    "    'npmi_coh': [-0.36774750155270663, -0.3153002812427124, -0.26334968605114956],\n",
    "    'silhouette_score': 0.102481075,\n",
    "    'top': [25, 10, 3]\n",
    "}\n",
    "```"
   ],
   "id": "ef92f28f17f7dd15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I know that doing a  comparison on a single run is not that meaningful. <br>\n",
    "I could do k-CV to estimate the expected model loss to get a valid analysis. <br>\n",
    "But for the sake of the experiment we consider this good enough."
   ],
   "id": "b78cbae13b203c37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NOUN only\n",
    "I expect this to utterly fail in the task as we loose sentence structure which ABAE sounds to be abusing. <br>\n",
    "Being based on word2vec embeddings this kind of pre-processing should be harmful I suppose."
   ],
   "id": "45effeec64f11cdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:51:00.945403Z",
     "start_time": "2025-03-15T17:50:59.822545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main.lda.pre_processing import extract_pos_ds\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Creating the __noun filtered ds:\")\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.80k.csv\"\n",
    "store_path = \"../dataset/output/pos_tagged/pre_processed.80k.noun_only.csv\"\n",
    "extract_pos_ds(pd.read_csv(corpus_path)['comments'], \"__noun\", store_path)\n",
    "print(\"ds created under: \" + store_path)\n",
    "\n",
    "print(\"Creating the __noun filtered test ds:\")\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.80k.test.csv\"\n",
    "store_path = \"../dataset/output/pos_tagged/pre_processed.80k.noun_only.test.csv\"\n",
    "extract_pos_ds(pd.read_csv(corpus_path)['comments'], \"__noun\", store_path)\n",
    "print(\"ds created under: \" + store_path)"
   ],
   "id": "86ec4d3d3c01530c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the __noun filtered ds:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/60701 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "312f6c9017ba4032a71db92b14e073f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/60701 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45de47fd5d6d4d139785baed72f11d2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds created under: ../dataset/output/pos_tagged/pre_processed.80k.noun_only.csv\n",
      "Creating the __noun filtered test ds:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20234 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "830d69bd535142e88ae2ee6a303ce9ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/20234 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdf88491887a46d9a7d70f3aa097b98c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds created under: ../dataset/output/pos_tagged/pre_processed.80k.noun_only.test.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T18:15:17.989785Z",
     "start_time": "2025-03-15T17:51:00.962429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.80k.noun_only.csv\"\n",
    "test_corpus_path = \"../dataset/output/pos_tagged/pre_processed.80k.noun_only.test.csv\"\n",
    "\n",
    "manager = ABAEManager.from_scratch(ABAEManagerConfig('noun_only'), corpus_path)\n",
    "manager.train(corpus_path, verbose=2)\n",
    "res = manager.evaluate([25, 10, 3], test_corpus_path=test_corpus_path)\n",
    "pprint(res)"
   ],
   "id": "1122e985147b038b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/51995 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f969e2dd717f4db68633e108198bd28a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n",
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Aspect embedding model\n",
      "\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/51995 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec3d0ce40af14bdea179c510f05f4370"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 191(0.3673430137513222% of ds).\n",
      "Generating a new compiled model from scratch\n",
      "Training is starting:\n",
      "Epoch 1/15\n",
      "407/407 - 87s - 215ms/step - loss: 9.2331 - max_margin_loss: 9.2253\n",
      "Epoch 2/15\n",
      "407/407 - 87s - 214ms/step - loss: 6.1523 - max_margin_loss: 6.1503\n",
      "Epoch 3/15\n",
      "407/407 - 87s - 215ms/step - loss: 5.5531 - max_margin_loss: 5.5498\n",
      "Epoch 4/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.3794 - max_margin_loss: 5.3780\n",
      "Epoch 5/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.3169 - max_margin_loss: 5.3172\n",
      "Epoch 6/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.2779 - max_margin_loss: 5.2781\n",
      "Epoch 7/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.2507 - max_margin_loss: 5.2489\n",
      "Epoch 8/15\n",
      "407/407 - 88s - 215ms/step - loss: 5.2140 - max_margin_loss: 5.2137\n",
      "Epoch 9/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1959 - max_margin_loss: 5.1929\n",
      "Epoch 10/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1816 - max_margin_loss: 5.1794\n",
      "Epoch 11/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1662 - max_margin_loss: 5.1653\n",
      "Epoch 12/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1528 - max_margin_loss: 5.1513\n",
      "Epoch 13/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1413 - max_margin_loss: 5.1434\n",
      "Epoch 14/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1309 - max_margin_loss: 5.1302\n",
      "Epoch 15/15\n",
      "407/407 - 87s - 214ms/step - loss: 5.1245 - max_margin_loss: 5.1224\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fa67d5e5d484af5ad9d4119bda36a8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 87(0.4906107257655219% of ds).\n",
      "\u001B[1m139/139\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 114ms/step - loss: 5.2149 - max_margin_loss: 5.2139\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab39d5233f064e64b626ac0808ae7270"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 87(0.4906107257655219% of ds).\n",
      "\u001B[1m35/35\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dabd0eff6a5d483882a131e4dc67409c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08efeed4831e487d8a3d54796639664f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4f0e13f09234789a7caf5f4dc639392"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5cb1de897c054399be07b65df1b30d4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60be586cf77440dc9c02cca93c58f350"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/17733 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16c644917b574c438ea8c07f89b45144"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv_coh': [0.5739321482932984, 0.4025111788642886, 0.31520862742842437],\n",
      " 'loss': [5.2081732749938965, 5.2088541984558105],\n",
      " 'npmi_coh': [-0.32037251659264615, -0.25705158206567535, -0.22708324414003458],\n",
      " 'silhouette_score': 0.055043943,\n",
      " 'top': [25, 10, 3]}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the future work and as one by the proposed ABAE paper we won't be splitting up reviews in sentences but use the full review as the model does not increase much if not done like this.",
   "id": "5b4c80db434e5d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Results of HP tuning",
   "id": "d6cadc1254bf9f0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T18:38:48.135965Z",
     "start_time": "2025-03-15T18:38:48.131620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Best tuning configurations\n",
    "configs = ['31479139-17f6-4f6d-aa8b-494cbc8f183b', '3f192c54-6623-48a7-b01b-2d5019dad186']\n",
    "results = json.load(open(\"./output/config/abae_configurations_results.json\"))\n",
    "configs = list(map(lambda x: x['config'], filter(lambda x: x['id'] in configs, results)))"
   ],
   "id": "7d6545417958061a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run on configs",
   "id": "cb2dc40b0e17a261"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:11:21.521281300Z",
     "start_time": "2025-03-16T13:43:48.257145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = \"../dataset/output/default/pre_processed.310k.csv\"\n",
    "test_corpus_path = \"../dataset/output/default/pre_processed.310k.test.csv\"\n",
    "\n",
    "best_config = ABAEManagerConfig.from_configuration('abae_best_0', configs[0])\n",
    "best_config.epochs = 15 # Forcing more epochs\n",
    "\n",
    "print(f\"Running on configuration: {best_config}\")\n",
    "manager = ABAEManager.from_scratch(best_config, corpus, override=True)\n",
    "manager.train(corpus_path, verbose=2)\n",
    "\n",
    "res = manager.evaluate([25, 10, 3], test_corpus_path=test_corpus_path)\n",
    "pprint(res)"
   ],
   "id": "f3f4556c51300ccd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABAEManagerConfig(name='abae_best_0', max_seq_len=80, negative_sample_size=20, embedding_size=160, aspect_size=11, min_word_count=5, max_vocab_size=None, batch_size=128, epochs=15, learning_rate=0.0018970757777381207, output_folder='./output')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/233384 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3abe08b5d87499f8d87ab3992d463ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n",
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Aspect embedding model\n",
      "\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/60640 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "890e15910a1c4a3b9427ab726a05d3ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 1340(2.2097625329815305% of ds).\n",
      "Generating a new compiled model from scratch\n",
      "Training is starting:\n",
      "Epoch 1/15\n",
      "474/474 - 103s - 217ms/step - loss: 7.7257 - max_margin_loss: 7.7229\n",
      "Epoch 2/15\n",
      "474/474 - 110s - 233ms/step - loss: 6.0067 - max_margin_loss: 6.0058\n",
      "Epoch 3/15\n",
      "474/474 - 153s - 322ms/step - loss: 5.8656 - max_margin_loss: 5.8645\n",
      "Epoch 4/15\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:42:09.560930Z",
     "start_time": "2025-03-16T13:27:05.276022Z"
    }
   },
   "cell_type": "code",
   "source": "manager.train(corpus_path, verbose=2)",
   "id": "1bb80add7deb2656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/60640 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93ed676ebb6e419b8af69aa9ea090d02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 1340(2.2097625329815305% of ds).\n",
      "Training is starting:\n",
      "Epoch 1/9\n",
      "474/474 - 104s - 220ms/step - loss: 5.6769 - max_margin_loss: 5.6759\n",
      "Epoch 2/9\n",
      "474/474 - 104s - 219ms/step - loss: 5.6702 - max_margin_loss: 5.6689\n",
      "Epoch 3/9\n",
      "474/474 - 99s - 210ms/step - loss: 5.6443 - max_margin_loss: 5.6431\n",
      "Epoch 4/9\n",
      "474/474 - 98s - 208ms/step - loss: 5.6512 - max_margin_loss: 5.6498\n",
      "Epoch 5/9\n",
      "474/474 - 98s - 206ms/step - loss: 5.6344 - max_margin_loss: 5.6331\n",
      "Epoch 6/9\n",
      "474/474 - 95s - 201ms/step - loss: 5.6245 - max_margin_loss: 5.6230\n",
      "Epoch 7/9\n",
      "474/474 - 99s - 210ms/step - loss: 5.6235 - max_margin_loss: 5.6220\n",
      "Epoch 8/9\n",
      "474/474 - 101s - 213ms/step - loss: 5.6273 - max_margin_loss: 5.6258\n",
      "Epoch 9/9\n",
      "474/474 - 102s - 215ms/step - loss: 5.6131 - max_margin_loss: 5.6119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.src.callbacks.history.History at 0x1867160e570>,\n",
       " <Functional name=functional_6, built=True>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:27:03.222148Z",
     "start_time": "2025-03-16T13:24:51.460222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = \"../dataset/output/default/pre_processed.310k.csv\"\n",
    "\n",
    "best_config = ABAEManagerConfig.from_configuration(\"abae_best_0\", configs[0])\n",
    "print(best_config)\n",
    "\n",
    "abae_manager = ABAEManager.from_scratch(best_config, corpus)\n",
    "# Train\n",
    "\n",
    "history, _ = abae_manager.train(corpus)\n",
    "model = abae_manager.get_compiled_model(refresh=False)"
   ],
   "id": "d374624e109b9a6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABAEManagerConfig(name='abae_best_0', max_seq_len=80, negative_sample_size=20, embedding_size=160, aspect_size=11, min_word_count=5, max_vocab_size=None, batch_size=128, epochs=9, learning_rate=0.0018970757777381207, output_folder='./output')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/233384 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "985b31f2a3cc4195812b40820d118dd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the existing found model as requested in path ./output/abae_best_0/abae_best_0.aspect_embeddings.model\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/233384 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b2aa471b96c498a94af2b8c34dbb586"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length calculation in progress...\n",
      "We loose information on 5614(2.4054776677064407% of ds).\n",
      "Generating a new compiled model from scratch\n",
      "Training is starting:\n",
      "Epoch 1/9\n",
      "\u001B[1m 388/1824\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m2:07\u001B[0m 89ms/step - loss: 9.7315 - max_margin_loss: 9.7294"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m abae_manager \u001B[38;5;241m=\u001B[39m ABAEManager\u001B[38;5;241m.\u001B[39mfrom_scratch(best_config, corpus)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Train\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m history, _ \u001B[38;5;241m=\u001B[39m \u001B[43mabae_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m model \u001B[38;5;241m=\u001B[39m abae_manager\u001B[38;5;241m.\u001B[39mget_compiled_model(refresh\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\main\\abae\\model_manager.py:112\u001B[0m, in \u001B[0;36mABAEManager.train\u001B[1;34m(self, df, verbose)\u001B[0m\n\u001B[0;32m    108\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m    109\u001B[0m     dataset\u001B[38;5;241m=\u001B[39mds, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc\u001B[38;5;241m.\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(num_cores \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m), pin_memory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    110\u001B[0m )\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining is starting:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 112\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__train_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Every epoch the model is persisted on the FS. (tmp)\u001B[39;49;00m\n\u001B[0;32m    114\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# ModelCheckpoint(filepath=f\"./tmp/ckpt/{self.c.name}.keras\", monitor='max_margin_loss'),\u001B[39;49;00m\n\u001B[0;32m    115\u001B[0m \u001B[43m    \u001B[49m\u001B[43mMetricAboveThresholdStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_margin_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_from_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# It for sure is bad\u001B[39;49;00m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mMetricAboveThresholdStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_margin_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_from_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_margin_loss\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_from_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmin\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__train_model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconsidered_path)\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_inference_model(refresh\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:257\u001B[0m, in \u001B[0;36mTorchTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    253\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, data \u001B[38;5;129;01min\u001B[39;00m epoch_iterator:\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;66;03m# Callbacks\u001B[39;00m\n\u001B[0;32m    255\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m--> 257\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Callbacks\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:117\u001B[0m, in \u001B[0;36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001B[39;00m\n\u001B[0;32m    116\u001B[0m data \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:76\u001B[0m, in \u001B[0;36mTorchTrainer.train_step\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe model does not have any trainable weights.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:493\u001B[0m, in \u001B[0;36mTrainer.compute_metrics\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compile_metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    492\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compile_metrics\u001B[38;5;241m.\u001B[39mupdate_state(y, y_pred, sample_weight)\n\u001B[1;32m--> 493\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_metrics_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:507\u001B[0m, in \u001B[0;36mTrainer.get_metrics_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    505\u001B[0m return_metrics \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetrics:\n\u001B[1;32m--> 507\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mmetric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    508\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    509\u001B[0m         return_metrics\u001B[38;5;241m.\u001B[39mupdate(result)\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\metrics\\reduction_metrics.py:156\u001B[0m, in \u001B[0;36mMean.result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresult\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivide_no_nan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtotal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    158\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\ops\\numpy.py:5985\u001B[0m, in \u001B[0;36mdivide_no_nan\u001B[1;34m(x1, x2)\u001B[0m\n\u001B[0;32m   5983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors((x1, x2)):\n\u001B[0;32m   5984\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DivideNoNan()\u001B[38;5;241m.\u001B[39msymbolic_call(x1, x2)\n\u001B[1;32m-> 5985\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivide_no_nan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\keras\\src\\backend\\torch\\numpy.py:1538\u001B[0m, in \u001B[0;36mdivide_no_nan\u001B[1;34m(x1, x2)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x2, (\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mfloat\u001B[39m)):\n\u001B[0;32m   1537\u001B[0m     x2 \u001B[38;5;241m=\u001B[39m convert_to_tensor(x2)\n\u001B[1;32m-> 1538\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mwhere(x2 \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivide\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx2\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history.history",
   "id": "270aaff24abe77bd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
