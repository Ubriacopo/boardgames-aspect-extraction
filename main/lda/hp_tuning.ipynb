{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What hyperparameters to tune:\n",
    "Take a look here:\n",
    "> https://stats.stackexchange.com/questions/349761/reasonable-hyperparameter-range-for-latent-dirichlet-allocation\n",
    "\n",
    "So our go to are:\n",
    "- Topics number\n",
    "- alpha: Document-Topic Density\n",
    "- beta: Word-Topic Density\n"
   ],
   "id": "c4ee426affe89711"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parameters definition",
   "id": "257c06fc04e01be9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T07:01:53.911791Z",
     "start_time": "2025-03-12T07:01:53.904293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main.hp_tuning import UniqueParametersConfigFsGenerator, RandomTunableOffsetParameter\n",
    "\n",
    "seed = 1408\n",
    "config_path = \"./output/config\"\n",
    "\n",
    "config_generator = UniqueParametersConfigFsGenerator(patience=100, seen_configurations_path=config_path,\n",
    "                                                     seen_configurations_filename=\"seen_configurations.noun_only.json\")\n",
    "\n",
    "# The amount of topics we want to look for\n",
    "# Topics are by far the most relevant parameter to tune, alpha and beta will come later maybe:\n",
    "config_generator.add_parameter('topics', RandomTunableOffsetParameter(value_range=(7, 72), step=5, seed=seed))"
   ],
   "id": "e2e43afc1b23b676",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T07:01:54.009210Z",
     "start_time": "2025-03-12T07:01:54.006312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# config_generator.add_parameter('alpha', RandomTunableOffsetParameter(value_range=(0.005, 1.0), step=0.5, seed=seed))\n",
    "# config_generator.add_parameter('beta', RandomTunableDiscreteParameter(values_list=beta, seed=seed))"
   ],
   "id": "7e05c4bbba698e2e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T07:01:55.144752Z",
     "start_time": "2025-03-12T07:01:54.452528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = pd.read_csv(\"../dataset/output/pos_tagged/pre_processed.310k.noun_only.csv\")\n",
    "folds = np.array_split(corpus, 5)"
   ],
   "id": "23d97f28f3f6d874",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-12T07:01:55.151761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from gensim.models import CoherenceModel\n",
    "from main.lda.model import LdaGeneratorConfig, LdaModelGenerator\n",
    "\n",
    "results = []\n",
    "n_folds = 5\n",
    "# This script can be re-run as often as desired as the history is persisted\n",
    "for i in range(10):  # How many different configurations we want to see\n",
    "\n",
    "    config = next(config_generator)\n",
    "    if config is None:\n",
    "        break  # We could not find a new configuration in patience time\n",
    "\n",
    "    print(f\"Running configuration = {config} ({i + 1}/10)\")\n",
    "    tops = [3, 10, 25]\n",
    "    run_result = dict(\n",
    "        config=config, cv_coh={top: [] for top in tops}, npmi_coh={top: [] for top in tops}, perplexity=[]\n",
    "    )\n",
    "    for k in range(n_folds):  # K-fold CV\n",
    "        # Build the correct data splits\n",
    "        validation_split = folds[k]  # On what to compute the validation metrics\n",
    "        train = pd.concat([folds[index] for index in range(len(folds)) if index != k])\n",
    "        print(f\"Running fold = {k}\")\n",
    "        model, dictionary = LdaModelGenerator(LdaGeneratorConfig().from_dict(config)).make_model(train)\n",
    "        print(\"Model generation over, evaluating...\")\n",
    "        # Validation part\n",
    "        texts = validation_split['comments'].apply(lambda x: x.split(' '))\n",
    "        # Metrics tracking\n",
    "\n",
    "        perplexity = model.log_perplexity(texts.apply(lambda x: dictionary.doc2bow(x)).tolist())\n",
    "\n",
    "        run_result['perplexity'].append(perplexity)\n",
    "\n",
    "        cv_coh_values = []\n",
    "        npmi_coh_values = []\n",
    "\n",
    "        for top in [3, 10, 25]:\n",
    "            cv_coh = CoherenceModel(model, texts=texts, coherence='c_v', topn=top)\n",
    "            npmi_coh = CoherenceModel(model, texts=texts, coherence='c_npmi', topn=top)\n",
    "            run_result['cv_coh'][top].append(cv_coh.get_coherence())\n",
    "            run_result['npmi_coh'][top].append(npmi_coh.get_coherence())\n",
    "\n",
    "    results.append(run_result)\n",
    "\n",
    "\n",
    "results_path = \"./output/config/hp_tuning_results.noun_only.json\"\n",
    "if Path(results_path).is_file():\n",
    "    existing_res = json.load(open(\"./output/config/hp_tuning_results.noun_only.json\"))\n",
    "    results = results + existing_res\n",
    "json.dump(results, open(results_path, 'w'))"
   ],
   "id": "a4143ded00c9a8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ddcb68b97ca4ce6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from main.hp_tuning import UniqueParametersConfigFsGenerator, RandomTunableOffsetParameter\n",
    "\n",
    "seed = 1408\n",
    "config_path = \"./output/config\"\n",
    "\n",
    "config_generator = UniqueParametersConfigFsGenerator(patience=100, seen_configurations_path=config_path,\n",
    "                                                     seen_configurations_filename=\"seen_configurations.noun_only_sentence.json\")\n",
    "\n",
    "# The amount of topics we want to look for\n",
    "# Topics are by far the most relevant parameter to tune, alpha and beta will come later maybe:\n",
    "config_generator.add_parameter('topics', RandomTunableOffsetParameter(value_range=(7, 72), step=5, seed=seed))"
   ],
   "id": "7cdd0dba88401644",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = pd.read_csv(\"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.noun_only.csv\")\n",
    "folds = np.array_split(corpus, 5)"
   ],
   "id": "13c9761cb4b9d529",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from gensim.models import CoherenceModel\n",
    "from main.lda.model import LdaGeneratorConfig, LdaModelGenerator\n",
    "\n",
    "results = []\n",
    "n_folds = 5\n",
    "# This script can be re-run as often as desired as the history is persisted\n",
    "for i in range(10):  # How many different configurations we want to see\n",
    "\n",
    "    config = next(config_generator)\n",
    "    if config is None:\n",
    "        break  # We could not find a new configuration in patience time\n",
    "\n",
    "    print(f\"Running configuration = {config} ({i + 1}/10)\")\n",
    "    tops = [3, 10, 25]\n",
    "    run_result = dict(\n",
    "        config=config, cv_coh={top: [] for top in tops}, npmi_coh={top: [] for top in tops}, perplexity=[]\n",
    "    )\n",
    "    for k in range(n_folds):  # K-fold CV\n",
    "        # Build the correct data splits\n",
    "        validation_split = folds[k]  # On what to compute the validation metrics\n",
    "        train = pd.concat([folds[index] for index in range(len(folds)) if index != k])\n",
    "        print(f\"Running fold = {k}\")\n",
    "        model, dictionary = LdaModelGenerator(LdaGeneratorConfig().from_dict(config)).make_model(train)\n",
    "        print(\"Model generation over, evaluating...\")\n",
    "        # Validation part\n",
    "        texts = validation_split['comments'].apply(lambda x: x.split(' '))\n",
    "        # Metrics tracking\n",
    "\n",
    "        perplexity = model.log_perplexity(texts.apply(lambda x: dictionary.doc2bow(x)).tolist())\n",
    "\n",
    "        run_result['perplexity'].append(perplexity)\n",
    "\n",
    "        cv_coh_values = []\n",
    "        npmi_coh_values = []\n",
    "\n",
    "        for top in [3, 10, 25]:\n",
    "            cv_coh = CoherenceModel(model, texts=texts, coherence='c_v', topn=top)\n",
    "            npmi_coh = CoherenceModel(model, texts=texts, coherence='c_npmi', topn=top)\n",
    "            run_result['cv_coh'][top].append(cv_coh.get_coherence())\n",
    "            run_result['npmi_coh'][top].append(npmi_coh.get_coherence())\n",
    "\n",
    "    results.append(run_result)\n",
    "\n",
    "\n",
    "results_path = \"./output/config/hp_tuning_results.noun_only_sent.json\"\n",
    "if Path(results_path).is_file():\n",
    "    existing_res = json.load(open(\"./output/config/hp_tuning_results.noun_only_sent.json\"))\n",
    "    results = results + existing_res\n",
    "json.dump(results, open(results_path, 'w'))"
   ],
   "id": "acf39f6ccf7c8042",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3ab125632733f851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T06:59:51.443290Z",
     "start_time": "2025-03-12T00:11:17.385415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main.hp_tuning import UniqueParametersConfigFsGenerator, RandomTunableOffsetParameter\n",
    "\n",
    "seed = 1408\n",
    "config_path = \"./output/config\"\n",
    "\n",
    "config_generator = UniqueParametersConfigFsGenerator(patience=100, seen_configurations_path=config_path,\n",
    "                                                     seen_configurations_filename=\"seen_configurations.default_sentence.json\")\n",
    "\n",
    "# The amount of topics we want to look for\n",
    "# Topics are by far the most relevant parameter to tune, alpha and beta will come later maybe:\n",
    "config_generator.add_parameter('topics', RandomTunableOffsetParameter(value_range=(7, 72), step=5, seed=seed))"
   ],
   "id": "d1e7b55736f27ce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous configurations from: ./output/config/seen_configurations.default_sentence.json\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T06:59:51.443290Z",
     "start_time": "2025-03-12T00:11:18.256880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "corpus = pd.read_csv(\"../dataset/output/default_sentences/pre_processed.310k.csv\")\n",
    "folds = np.array_split(corpus, 5)"
   ],
   "id": "5161f2bb27b6c7f3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\nlp-course-project\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T06:59:51.455305Z",
     "start_time": "2025-03-12T00:15:03.929739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from gensim.models import CoherenceModel\n",
    "from main.lda.model import LdaGeneratorConfig, LdaModelGenerator\n",
    "\n",
    "#todo fn cosi non divento scemo su file\n",
    "results = []\n",
    "n_folds = 5\n",
    "# This script can be re-run as often as desired as the history is persisted\n",
    "for i in range(10):  # How many different configurations we want to see\n",
    "\n",
    "    config = next(config_generator)\n",
    "    if config is None:\n",
    "        break  # We could not find a new configuration in patience time\n",
    "\n",
    "    print(f\"Running configuration = {config} ({i + 1}/10)\")\n",
    "    tops = [3, 10, 25]\n",
    "    run_result = dict(\n",
    "        config=config, cv_coh={top: [] for top in tops}, npmi_coh={top: [] for top in tops}, perplexity=[]\n",
    "    )\n",
    "    for k in range(n_folds):  # K-fold CV\n",
    "        # Build the correct data splits\n",
    "        validation_split = folds[k]  # On what to compute the validation metrics\n",
    "        train = pd.concat([folds[index] for index in range(len(folds)) if index != k])\n",
    "        print(f\"Running fold = {k}\")\n",
    "        model, dictionary = LdaModelGenerator(LdaGeneratorConfig().from_dict(config)).make_model(train)\n",
    "        print(\"Model generation over, evaluating...\")\n",
    "        # Validation part\n",
    "        texts = validation_split['comments'].apply(lambda x: x.split(' '))\n",
    "        # Metrics tracking\n",
    "\n",
    "        perplexity = model.log_perplexity(texts.apply(lambda x: dictionary.doc2bow(x)).tolist())\n",
    "\n",
    "        run_result['perplexity'].append(perplexity)\n",
    "\n",
    "        cv_coh_values = []\n",
    "        npmi_coh_values = []\n",
    "\n",
    "        for top in [3, 10, 25]:\n",
    "            cv_coh = CoherenceModel(model, texts=texts, coherence='c_v', topn=top)\n",
    "            npmi_coh = CoherenceModel(model, texts=texts, coherence='c_npmi', topn=top)\n",
    "            run_result['cv_coh'][top].append(cv_coh.get_coherence())\n",
    "            run_result['npmi_coh'][top].append(npmi_coh.get_coherence())\n",
    "\n",
    "    results.append(run_result)\n",
    "\n",
    "results_path = \"./output/config/hp_tuning_results.default_sentence.json\"\n",
    "if Path(results_path).is_file():\n",
    "    existing_res = json.load(open(\"./output/config/hp_tuning_results.default_sentence.json\"))\n",
    "    results = results + existing_res\n",
    "json.dump(results, open(results_path, 'w'))"
   ],
   "id": "885f118066cb2dab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running configuration = {'topics': 14} (1/10)\n",
      "Running fold = 0\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/187117 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a71cf726d26466f8cc318d3f0aad273"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation over, evaluating...\n",
      "Running fold = 1\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/187117 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ac0b513bd10497ea6dd1b680893d48b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation over, evaluating...\n",
      "Running fold = 2\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/187118 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58ce1bbb6f474a5f898eff2f352262b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation over, evaluating...\n",
      "Running fold = 3\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/187118 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc1092fa41344e7fbf1073f7bd5a4a0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation over, evaluating...\n",
      "Running fold = 4\n",
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/187118 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59bcd8341424483880486862c4aa4011"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation over, evaluating...\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "52edd5abd5e9c074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#todo fix\n",
    "# https://www.kaggle.com/code/vijaylokithrr/topic-modelling#7)-Hyperparameter-Tuning\n",
    "plt.figure(figsize=(20, 7))\n",
    "ax = sns.lineplot(x=num_topics, y=hyper_para_coherence, label=\"topic coherences\")\n",
    "ax.axes.set_title('Coherence per Number of Topics', fontsize=25)\n",
    "ax.set_ylabel('Coherence', fontsize=20)\n",
    "ax.set_xlabel('Number of Topics', fontsize=20)\n",
    "plt.show()"
   ],
   "id": "ce1f2c39ad00080e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
