{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pre Processing Step\n",
    "We want to process the data for LDA like:\n",
    "- Keep NOUNS only as they are the elements that mostly hold aspect value\n",
    "- Split reviews in sentences (Avoid topic modelling in a too broad sense) (https://aclanthology.org/N10-1122.pdf)"
   ],
   "id": "a35a9dbedf4c1227"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:55:54.617769Z",
     "start_time": "2025-03-15T10:55:54.611306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main.lda.config import LdaGeneratorConfig\n",
    "import pandas as pd\n",
    "# Required imports for the coming cells\n",
    "from model import LdaModelGenerator\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def run_procedure(corpus_path: str, test_ds_path: str, config: LdaGeneratorConfig):\n",
    "    stop_words = ['game', 'play', '<game_name>']\n",
    "    lda, dictionary = LdaModelGenerator(config, stop_words).make_model(corpus_path)\n",
    "\n",
    "    # Evaluate the model\n",
    "    split_texts = pd.read_csv(test_ds_path)['comments'].apply(lambda x: x.split(' '))\n",
    "    results = dict(cv_coh=[], npmi_coh=[], topn=[3, 10, 25])\n",
    "    results['perplexity'] = lda.log_perplexity(split_texts.apply(lambda x: dictionary.doc2bow(x)).tolist())\n",
    "\n",
    "    for topn in results['topn']:\n",
    "        cv_model = CoherenceModel(lda, texts=split_texts, coherence='c_v', topn=topn)\n",
    "        npmi_model = CoherenceModel(lda, texts=split_texts, coherence='c_npmi', topn=topn)\n",
    "        results['cv_coh'].append(cv_model.get_coherence())\n",
    "        results['npmi_coh'].append(npmi_model.get_coherence())\n",
    "\n",
    "    print(\n",
    "        f\"Model perplexity: {results['perplexity']}\\n\"\n",
    "        f\"With topn = {results['topn']} we have: \\n\"\n",
    "        f\" - CV coherence: {results['cv_coh']}\\n\"\n",
    "        f\" - NPMI coherence: {results['npmi_coh']}\\n\"\n",
    "    )\n",
    "\n",
    "    return results, lda, dictionary\n"
   ],
   "id": "3a9c91b52269ff28",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# LDA does not benefit from repeated words among many documents. So we should clean them as they are stopwords.\n",
    "corpus_path = \"../dataset/output/default_sentences/pre_processed.310k.csv\"\n",
    "ds = pd.read_csv(corpus_path)['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "dictionary = corpora.Dictionary(ds)\n",
    "doc_frequency = {}\n",
    "\n",
    "for index in range(len(dictionary)):\n",
    "    doc_frequency[dictionary.get(index)] = len(ds[[dictionary.get(index) in x for x in ds]])"
   ],
   "id": "5406811c9420470f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame.from_dict(doc_frequency, orient='index')[0].map(lambda x: x / len(ds)).sort_values(ascending=False)",
   "id": "212c68cf6e52eaa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Are 'game'(40%), 'play'(20%) and '\\<game_name\\>'(11%) stopwords? <br>\n",
    "For sure 'game' is! What about the other two? I believe they bring no context.\n",
    "We remove them!"
   ],
   "id": "b9dfc237972f91b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stop_words = ['game', 'play', '<game_name>']\n",
    "\n",
    "corpus_path = \"../dataset/output/default_sentences/pre_processed.310k.csv\"\n",
    "default_config = LdaGeneratorConfig(name=\"default\")\n",
    "lda, dictionary = LdaModelGenerator(default_config, stop_words).make_model(corpus_path)"
   ],
   "id": "2aa7b0116e0c43b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "\n",
    "test_ds = pd.read_csv(\"../dataset/output/default_sentences/pre_processed.310k.test.csv\")\n",
    "\n",
    "# For the c_v model\n",
    "texts = test_ds['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "topn = 10  # For the coherence evaluation.\n",
    "cv_coh = CoherenceModel(lda, texts=texts, coherence='c_v', topn=topn)\n",
    "npmi_coh = CoherenceModel(lda, texts=texts, coherence='c_npmi', topn=topn)"
   ],
   "id": "f9a61e1c9b169cc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Model perplexity: {lda.log_perplexity(texts.apply(lambda x: dictionary.doc2bow(x)).tolist())}\\n\"\n",
    "    f\"With topn = {topn} we have: \\n\"\n",
    "    f\" - CV coherence: {cv_coh.get_coherence()}\\n\"\n",
    "    f\" - NPMI coherence: {npmi_coh.get_coherence()}: \\n\"\n",
    "    \"CV coherence per topic:\"\n",
    ")\n",
    "cv_coh.get_coherence_per_topic()"
   ],
   "id": "815b2a1053bc44f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lda.show_topics(20, 20)",
   "id": "8d4d75f514b899ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### POS: Nouns only",
   "id": "e013653480138e4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we check if the NOUN only approach works better. <br>\n",
    "Take nouns only of the POS tagged ds:"
   ],
   "id": "d8f49c0af29f8aea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pre_processing import extract_pos_ds\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Creating the __noun filtered ds:\")\n",
    "corpus_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.csv\"\n",
    "store_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.noun_only.csv\"\n",
    "extract_pos_ds(pd.read_csv(corpus_path)['comments'], \"__noun\", store_path)\n",
    "print(\"ds created under: \" + store_path)\n",
    "\n",
    "print(\"Creating the __noun filtered test ds:\")\n",
    "corpus_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.test.csv\"\n",
    "store_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.noun_only.test.csv\"\n",
    "extract_pos_ds(pd.read_csv(corpus_path)['comments'], \"__noun\", store_path)\n",
    "print(\"ds created under: \" + store_path)"
   ],
   "id": "95e8ae97d92200ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This logic is translated in:\n",
    "from pre_processing import extract_pos_ds"
   ],
   "id": "bdcec0c3fb98361b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "\n",
    "# LDA does not benefit from repeated words among many documents. So we should clean them as they are stopwords.\n",
    "corpus_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.noun_only.csv\"\n",
    "ds = pd.read_csv(corpus_path)['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "count_dictionary = corpora.Dictionary(ds)\n",
    "doc_frequency = {}\n",
    "\n",
    "for index in range(len(count_dictionary)):\n",
    "    doc_frequency[count_dictionary.get(index)] = len(ds[[count_dictionary.get(index) in x for x in ds]])\n",
    "\n",
    "pd.DataFrame.from_dict(doc_frequency, orient='index')[0].map(lambda x: x / len(ds))"
   ],
   "id": "222b28d85e8ccc9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Default approach on the sentences only to avoid global topic recognition\n",
    "from model import LdaModelGenerator, LdaGeneratorConfig\n",
    "\n",
    "stop_words = ['game', 'play', '<game_name>']\n",
    "corpus_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.noun_only.csv\"\n",
    "default_config = LdaGeneratorConfig(name=\"default\")\n",
    "noun_lda, noun_dictionary = LdaModelGenerator(default_config, stop_words).make_model(corpus_path)"
   ],
   "id": "f9df263278dfa910",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "\n",
    "test_corpus_path = \"../dataset/output/pos_tagged_sentence_level/pre_processed.310k.noun_only.test.csv\"\n",
    "test_ds = pd.read_csv(test_corpus_path)\n",
    "\n",
    "# For the c_v model\n",
    "texts = test_ds['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "topn = 10  # For the coherence evaluation.\n",
    "cv_coh = CoherenceModel(noun_lda, texts=texts, coherence='c_v', topn=topn)\n",
    "npmi_coh = CoherenceModel(noun_lda, texts=texts, coherence='c_npmi', topn=topn)"
   ],
   "id": "566acb41ec0c1b3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Model perplexity: {noun_lda.log_perplexity(texts.apply(lambda x: noun_dictionary.doc2bow(x)).tolist())}\\n\"\n",
    "    f\"With topn = {topn} we have: \\n\"\n",
    "    f\" - CV coherence: {cv_coh.get_coherence()}\\n\"\n",
    "    f\" - NPMI coherence: {npmi_coh.get_coherence()}: \\n\"\n",
    "    \"CV coherence per topic:\"\n",
    ")\n",
    "cv_coh.get_coherence_per_topic()"
   ],
   "id": "9c9bab0bd34495c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "noun_lda.show_topics(20, 20)",
   "id": "73ce133dcd2932c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now the model has high coherence which is good but are the extracted aspects good?\n",
    "# Probably not."
   ],
   "id": "b13c0365f1829d5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda, texts.apply(lambda x: dictionary.doc2bow(x)).tolist(), dictionary)\n",
    "vis"
   ],
   "id": "f91adb9e1517424b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(noun_lda, texts.apply(lambda x: noun_dictionary.doc2bow(x)).tolist(), noun_dictionary)\n",
    "vis"
   ],
   "id": "185dceffd38d7093",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Topic 1 identifies Downtime for example. Yet it also does crash with maybe with bookkeeping.\n",
    "# We have to better tune the parameters to check if we can create better communities"
   ],
   "id": "d89207b3b6d1d036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Following the experiments I decided to follow the path of nouns only composition document. <br>\n",
    "The hyperparameters tuning is now the next step."
   ],
   "id": "dc28f583a2fd8bda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Noun only on sentences model performs way worse, let's see if going for non LocalLDA but focusing on NOUNS only is viable:",
   "id": "b9ed9f3ca3aae72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pre_processing import extract_pos_ds\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Creating the __noun filtered ds:\")\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.csv\"\n",
    "store_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.csv\"\n",
    "extract_pos_ds(pd.read_csv(corpus_path)['comments'], \"__noun\", store_path)\n",
    "print(\"ds created under: \" + store_path)\n",
    "\n",
    "print(\"Creating the __noun filtered test ds:\")\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.test.csv\"\n",
    "store_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.test.csv\"\n",
    "extract_pos_ds(pd.read_csv(corpus_path)['comments'], \"__noun\", store_path)\n",
    "print(\"ds created under: \" + store_path)"
   ],
   "id": "808f7c9f395a9428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Default approach on the sentences only to avoid global topic recognition\n",
    "from model import LdaModelGenerator, LdaGeneratorConfig\n",
    "\n",
    "stop_words = ['game', 'play', '<game_name>']\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.csv\"\n",
    "default_config = LdaGeneratorConfig(name='default')\n",
    "noun_lda, noun_dictionary = LdaModelGenerator(default_config, stop_words).make_model(corpus_path)"
   ],
   "id": "e937faded71be6ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "\n",
    "test_corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.test.csv\"\n",
    "test_ds = pd.read_csv(test_corpus_path)\n",
    "\n",
    "# For the c_v model\n",
    "texts = test_ds['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "topn = 10  # For the coherence evaluation.\n",
    "cv_coh = CoherenceModel(noun_lda, texts=texts, coherence='c_v', topn=topn)\n",
    "npmi_coh = CoherenceModel(noun_lda, texts=texts, coherence='c_npmi', topn=topn)"
   ],
   "id": "587b44b262fdb43b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Model perplexity: {noun_lda.log_perplexity(texts.apply(lambda x: noun_dictionary.doc2bow(x)).tolist())}\\n\"\n",
    "    f\"With topn = {topn} we have: \\n\"\n",
    "    f\" - CV coherence: {cv_coh.get_coherence()}\\n\"\n",
    "    f\" - NPMI coherence: {npmi_coh.get_coherence()}: \\n\"\n",
    "    \"CV coherence per topic:\"\n",
    ")\n",
    "cv_coh.get_coherence_per_topic()"
   ],
   "id": "8d7f6d617cede592",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(noun_lda, texts.apply(lambda x: noun_dictionary.doc2bow(x)).tolist(), noun_dictionary)\n",
    "vis"
   ],
   "id": "fafda9679c0afe84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tuned best found K values\n",
    "Hyperparameters tuning yielded on average the following best topics:\n",
    "- Default sentences: [10]\n",
    "- NOUN only full review: [7, 12]"
   ],
   "id": "d7b1b08fb4120c52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Default sentences:",
   "id": "ddabed2d8530f344"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Default approach on the sentences only to avoid global topic recognition\n",
    "from model import LdaModelGenerator\n",
    "from main.lda.config import LdaGeneratorConfig\n",
    "\n",
    "stop_words = ['game', 'play', '<game_name>']\n",
    "\n",
    "corpus_path = \"../dataset/output/default_sentences/pre_processed.310k.csv\"\n",
    "config = LdaGeneratorConfig(name=\"sentences_k_10\", topics=10)\n",
    "lda, dictionary = LdaModelGenerator(config, stop_words).make_model(corpus_path)"
   ],
   "id": "4c6e4e1f17dc89c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "\n",
    "test_ds = pd.read_csv(\"../dataset/output/default_sentences/pre_processed.310k.test.csv\")\n",
    "\n",
    "# For the c_v model\n",
    "texts = test_ds['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "perplexity = lda.log_perplexity(texts.apply(lambda x: dictionary.doc2bow(x)).tolist())\n",
    "results = dict(cv_coh=[], npmi_coh=[], topn=[3, 10, 25], perplexity=perplexity)\n",
    "\n",
    "for topn in results['topn']:\n",
    "    cv_coh = CoherenceModel(lda, texts=texts, coherence='c_v', topn=topn)\n",
    "    npmi_coh = CoherenceModel(lda, texts=texts, coherence='c_npmi', topn=topn)\n",
    "    results['cv_coh'].append(cv_coh.get_coherence())\n",
    "    results['npmi_coh'].append(npmi_coh.get_coherence())"
   ],
   "id": "af3492d0449f869f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# todo save lda model",
   "id": "a21a018bdb7fcb95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Model perplexity: {results['perplexity']}\\n\"\n",
    "    f\"With topn = {results['topn']} we have: \\n\"\n",
    "    f\" - CV coherence: {results['cv_coh']}\\n\"\n",
    "    f\" - NPMI coherence: {results['npmi_coh']}\\n\"\n",
    ")"
   ],
   "id": "fe3dab3f73d77287",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualize the result:",
   "id": "dc9eb4086158a790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda, texts.apply(lambda x: dictionary.doc2bow(x)).tolist(), dictionary)\n",
    "vis"
   ],
   "id": "5ed3e2549bafa8af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9673de2c0d0f2e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NOUNs only",
   "id": "27772875aab16a38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # Default approach on the sentences only to avoid global topic recognition\n",
    "from model import LdaModelGenerator\n",
    "from main.lda.config import LdaGeneratorConfig\n",
    "\n",
    "stop_words = ['game', 'play', '<game_name>']\n",
    "\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.csv\"\n",
    "config = LdaGeneratorConfig(name=\"sentences_k_10\", topics=12)\n",
    "lda, dictionary = LdaModelGenerator(config, stop_words).make_model(corpus_path)"
   ],
   "id": "b41c269b44ea8fc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import pandas as pd\n",
    "\n",
    "test_ds = pd.read_csv(\"../dataset/output/pos_tagged/pre_processed.310k.noun_only.test.csv\")\n",
    "\n",
    "# For the c_v model\n",
    "texts = test_ds['comments'].apply(lambda x: x.split(' '))\n",
    "\n",
    "perplexity = lda.log_perplexity(texts.apply(lambda x: dictionary.doc2bow(x)).tolist())\n",
    "results = dict(cv_coh=[], npmi_coh=[], topn=[3, 10, 25], perplexity=perplexity)\n",
    "\n",
    "for topn in results['topn']:\n",
    "    cv_coh = CoherenceModel(lda, texts=texts, coherence='c_v', topn=topn)\n",
    "    npmi_coh = CoherenceModel(lda, texts=texts, coherence='c_npmi', topn=topn)\n",
    "    results['cv_coh'].append(cv_coh.get_coherence())\n",
    "    results['npmi_coh'].append(npmi_coh.get_coherence())"
   ],
   "id": "92d2557878dc607c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Model perplexity: {results['perplexity']}\\n\"\n",
    "    f\"With topn = {results['topn']} we have: \\n\"\n",
    "    f\" - CV coherence: {results['cv_coh']}\\n\"\n",
    "    f\" - NPMI coherence: {results['npmi_coh']}\\n\"\n",
    ")"
   ],
   "id": "ad31a0b114e529e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda, texts.apply(lambda x: dictionary.doc2bow(x)).tolist(), dictionary)\n",
    "vis"
   ],
   "id": "2c784a77bd2332c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:59:21.257050Z",
     "start_time": "2025-03-15T10:55:57.697333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run for K = 7\n",
    "corpus_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.csv\"\n",
    "test_ds_path = \"../dataset/output/pos_tagged/pre_processed.310k.noun_only.test.csv\"\n",
    "res, lda, dictionary = run_procedure(corpus_path, test_ds_path, LdaGeneratorConfig(name=\"sentences_k_7\", topics=12))\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda, texts.apply(lambda x: dictionary.doc2bow(x)).tolist(), dictionary)\n",
    "vis"
   ],
   "id": "6523f08995672ff0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating numeric representation for each word of ds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pandas Apply:   0%|          | 0/195789 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a93ac322ade44a2ba607da74e40c363"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model perplexity: -8.208558033118516\n",
      "With topn = [3, 10, 25] we have: \n",
      " - CV coherence: [0.7180530229398828, 0.6123247263225092, 0.5880882077576267]\n",
      " - NPMI coherence: [0.05778951271585514, 0.023637662956389766, 0.005265168985537204]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m res, lda, dictionary \u001B[38;5;241m=\u001B[39m run_procedure(corpus_path, test_ds_path, LdaGeneratorConfig(name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msentences_k_7\u001B[39m\u001B[38;5;124m\"\u001B[39m, topics\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m12\u001B[39m))\n\u001B[0;32m      6\u001B[0m pyLDAvis\u001B[38;5;241m.\u001B[39menable_notebook()\n\u001B[1;32m----> 7\u001B[0m vis \u001B[38;5;241m=\u001B[39m gensimvis\u001B[38;5;241m.\u001B[39mprepare(lda, \u001B[43mtexts\u001B[49m\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: dictionary\u001B[38;5;241m.\u001B[39mdoc2bow(x))\u001B[38;5;241m.\u001B[39mtolist(), dictionary)\n\u001B[0;32m      8\u001B[0m vis\n",
      "\u001B[1;31mNameError\u001B[0m: name 'texts' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8434975b2d1d4bfa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
